\chapter{Lecture 1}
Here we go.

\subsection{Course Overview and Logistics}
Some administrative things.
OH are Monday, Fridays 1:45 to 2:45, Wednesdays 12:45-1:45 in Evans 811.

\textbf{Textbook}: an introduction to functional analysis by Conway.
We will be talking about operators on Hilbert spaces, and more generally, Banach spaces, and Frechet spaces (defined by a countable numer of seminomrs).

\begin{remark}
    Let $\mathcal{H}$ be a Hilbert space, then the dual space $\mathcal{H}^*$ is itself. $\mathcal{H}=\mathcal{H}^*$.    
    Hilbert spaces are the best spaces to work with. They are self-dual, and identified with themslves.
\end{remark}
Then in the next section, we will look at groups, motivated by their actions on Banach spaces, connected with Fourier transforms. 


\subsection{Motivation}
Let $X$ be a compact Hausdorff space. Let $C(X)=\{f:X\to\R, f \text{ continuous}\} $ be the algebra of continuous functions on $X$ mapping in to $\R$ or $\mathbb{C}$.
Define the norm as the sup norm $\|\cdot\|_{L^\infty}$.

We will develop the spectral theorem of operators on the Hilbert space, i..e self-adjoint operators can be diagonalized.

If $T$ is a self-adjoint operator on a Hilbert space, then we take the product of $T$ (polynomials of $T$), let $C^*(T, I_\mathcal{H})$ be the sub-algebra of operators generated by $T$ and $I$ the identity operator, then take the closure, i.e. making it closed in the operator norm.

\begin{remark}
    The $*$ is to remind us, $T$ is self-adjoint and when you take the adjoint and generate with it, it gets back into the same space.
\end{remark}

\begin{proposition}
    We have the next two algebra isomorphic to each other.
    \begin{equation}
        C^*(T, I_\mathcal{H})\cong C(X)
    \end{equation}
\end{proposition}
This is what we are aiminig for. We can generalize this even further to finitely many self-adjoint operators, in some sense, we are diagonalizing finitely many operators at the same time. If $T_1,..., T_n$ is a collection of self-adjoint operators on $\mathcal{H}$, and such all commute with each other, then we also have
\begin{equation}
    C^*(T_1,..., T_n, I_\mathcal{H})\cong C(X)
\end{equation}

\subsection{Groups}

Let $G$ be a group, $B$ be a Banach space, for example, groups of automorphisms. Let
\begin{equation*} 
    Aut(B)=\{T:  T \text{is isometric, onto, invertible on } B\}
\end{equation*}

\begin{definition}
    Suppose that $\alpha$ is a group homomorphisms, and $\alpha: G\to Aut(B)$, is called a representation on $B$ or an action of the group $G$ on $B$.
\end{definition}


Then we can consider the subalgebra $\mathcal{L}(B)$, consisting of the bounded linear operators on $B$, generated by
\begin{equation*}
    \{\alpha_x:x\in G\}
\end{equation*}
\begin{remark}
    The identity on $G$ should be mapped into the identity operator on $B$, hence no need to include it.
\end{remark}

Elements of the form $\Sigma_{z_x}\alpha_x, z_x\in\mathbb{C}$, (where $\Sigma$ is a finite sum.)

Let's introduce,
$f\in C_c(G)$ are functions with compact support and in discrete groups, imply they are of finite support.

\begin{equation*}
    \sum_{x\in G}f(x)\alpha_x=\alpha_f
\end{equation*}
note for except finitely many $x$, $f(x)=0$.

Let $f,g\in C_c(G)$, then for 
\begin{equation*}
    \alpha_f\alpha_g=(\sum f(x)\alpha_x)(\sum g(y)\alpha_y)=\sum_{x,y}f(x)g(y)\alpha_x\alpha_y=\sum_{x,y}f(x)g(y)\alpha_{xy}
\end{equation*}
The last inequality follows from $\alpha$ being a group homomorphism. And the sums are finite hence are able to exchange the orders.
We further have,
\begin{equation*}
    \alpha_f\alpha_g=\sum_x\sum_yf(x)g(x^{-1}y)\alpha_y=\sum (f\ast g)(y)\alpha_y
\end{equation*}
where we define $f\ast g(y)=\sum f(x)g(x^{-1}y)$ as the convolution operator.


We get
\begin{equation*}
    \alpha_f\alpha_g=\alpha_{f\ast g}
\end{equation*}
This is how we define convolution on $C_c(G)$
Notice we have, by $\|\alpha_x\|=1$,
\begin{equation*}
    \|\alpha_f\|=\|\sum f(x)\alpha_x\|\leq\sum|f(x)|\|\alpha_x\|=\sum|f(x)|=l^1(f)=\|f\|_{l^1}
\end{equation*}
It is therefore, easy to check

\begin{equation*}
    \|f\ast g\|_{l^1}\leq\|f\|_{l^1}\|g\|_{l^1}
\end{equation*}
We get $l^1(G)$ is an algebra with ??

For $G$ commutative, it is easily connected with the Fourier transform.

Consider $l^2(G)$ with the counting measure on the group. For $x\in G$, let $\xi\in l^2(G)$ define $\alpha_x\xi(y)=\xi(x^{-1}y), \alpha_x$ being unitary.
$l^1(G)$ acts on operators in $l^2(G)$ via $\alpha$.


If $G$ is commutative, then we have
\begin{equation*}
    \overline{\alpha_{l^1(G)}}\cong C(X)
\end{equation*}
where $X$ is some compact space.
Note that $C_c(G)$ operators on $l^2(G)$, and $\|\alpha_f\|\leq\|f\|_{l^1}$.

\newpage
\section{Lecture 2}
Let's do some math.

Let $X$ be a Hausdorff compact space, and let $C(X)$ denote the space of continuous functions defined on $X$. This is an algebra. You can multiply them, associatively and commutatively. We equip it with a norm $\|\cdot\|_{L^\infty}$. Note $X$, by assumption, is a normal space, you could have continuous functions mapped to 1 on one subset, 0 to the other subset. Hence there are many elements from $C(X)$.

\begin{definition}[Normed Algebra]
    Let $\mathcal{A}$ be an algebra on $\R$ or $\mathbb{C}$, is a normed algebra if it has a norm $\| \|$, as a vector space, such that for for $a,b\in\mathcal{A}$, we have
    \begin{equation*}
        \|ab\|\leq\|a\|\|b\|
    \end{equation*}
    The above is called submultiplicity.
\end{definition}
\begin{definition}[Banach Algebra]
    A Banach Algebra is a normed algebra that is complete in the metric space from the norm.
\end{definition}


Given $x\in X$, define $\varphi_x: C(X)\to\mathbb{C}$ the evaluation map such that
\begin{equation*}
    \varphi_x(f)=f(x)
\end{equation*}

$\varphi_x$ is an algebra homomorphisms between $C(X)\to\R$ or $C(X)\to\mathbb{C}$. This simply implies
\begin{equation*}
    \varphi_x(f+g)=(f+g)(x)=f(x)+g(x), \varphi_x(fg)=(fg)(x)=f(x)g(x)
\end{equation*}

We now make the note that, $C(X)$ has an identity element, which is the constant function $1$, under multiplication. Hence $C(X)$ is a unital algebra. Note that $\varphi_x$ defined above is a unital homomorphism, meaning that it sends identity to identity.

Note $\varphi_x$ is also a multiplicative linear functional, also unital.

\begin{proposition}
    Every multiplicative linear functional on $C(X)$ is of the form $\varphi_x$ for some $x\in X$.
\end{proposition}
\begin{proof}
    Main Claim: given a multiplicative linear functional $\varphi$, there exists a point $x_0$ and if we have some $f\in C(X)$, we have $\varphi(f)=0$, then we have $f(x_0)=0$. To prove this claim, we need compactness. Suppose the contrary of the claim. Suppose that for each $x\in X$, there is an $f_x\in C(X)$ such that $f(x)\neq 0$, but $\varphi(f)=0$.

    Set $g_x=\overline{f}_xf_x$, then we have $g_x(x)>0$, but $\varphi(g_x)=\varphi(f_x)\varphi(\overline{f}_x)=0$, then there is an open set $O_x$ such that $x\in O_x$, and $g_x(y)>0$ for all $y\in O_x$. Now by compactness, there is $x_1, ..., x_n$ such that $X=\bigcup_{j=1}^nO_{x_j}$, let $g=g_{x_1}+... g_{x_n}$, then we have $g(y)>0$ for all $y\in X$, and $\varphi(g)=0$. Note that $g$ is a continuous function, and $g$ is invertible, and also $re(\frac{1}{g})\in C(X)$, but we also have
    \begin{equation*}
        \varphi \left(g\cdot\frac{1}{g}\right)=1
    \end{equation*}
    Hence we've reached a contradiction.
    Then there exists $x_0\in X$ such that if $\varphi(f)=0$, this means $f(x_0)=0$. For any $f$, consider $f-\varphi(f)\cdot 1$, apply $\varphi$, we have
    \begin{equation*}
        \varphi(f-\varphi(f)\cdot 1)=0, \text{ this implies there exists } x_0, \text{ such that } (f-\varphi(f)1)(x_0)=0
    \end{equation*}
    This implies $f(x_0)=\varphi(f)$ which implies $\varphi(f)=\varphi_{x_0}(f)$.
\end{proof}

For any unital commutative algebra $\mathcal{A}$ and let $\widehat{\mathcal{A}}$ be the set of unital homomorphisms of $\mathcal{A}$ into the field.

For $\mathcal{A}=C(X)$, and $\varphi\in\widehat{\mathcal{A}}$. 
\begin{definition}
    For any unital commutative algebra $\mathcal{A}$ and let $\widehat{\mathcal{A}}$ be the set of unital homomorphisms of $\mathcal{A}$ into the field.
\end{definition}
\begin{remark}
    We have $|\varphi(f)|\leq\|\varphi\|\|f\|_{L^\infty}$, since $\varphi$ is unital, we have $\|\varphi\|=1$.
\end{remark}

Thss is not always true for normed algebra,
Let
\begin{equation*}
    \mathcal{A}:= Poly\subset C([0,1])
\end{equation*}
We define $\varphi(p)=p(2)$, $p$ is a polynomial. This is not continuous, nor is the $\|\varphi\|=1$.


\begin{proposition}
    If $\mathcal{A}$ is a unital commutative Banach algebra, and if $\phi\in\widehat{\mathcal{A}}$, then we have $\|\varphi\|=1$.
\end{proposition}

The word ``unital'' is key here.

\begin{proposition}
    Let $\mathcal{A}$ be a unital Banach algebra (not necessarily commutative), then if $a\in\mathcal{A}$, and $\|a\|< 1$, then we have
    \begin{equation*}
        1_\mathcal{A}-a \text{ is invertible in } \mathcal{A}
    \end{equation*}
\end{proposition}
\begin{proof}
    For this, we use completeness.
    $\frac{1}{1-a}=?\sum_{n=0}^\infty a^n, a^0=1_\mathcal{A}$
    You could look at the partial sums. $S_m=\sum_{n=0}^ma^n$, you want to show that $\{S_m\}$ is a Cauchy sequence, and use completeness of Banach algebras. $\lim_{m\to\infty}S_m=\frac{1}{1-a}$.
    
    To prove this is a cauchy sequence:
    \begin{equation*}
        \|S_n-S_m\|=\|\sum_{j=m+1}^na^j\|\leq\sum_{m+1}^n\|a^j\|\leq\sum_{m+1}^n\|a\|^j
    \end{equation*}
    And the fact that $\|a\|< 1$, we have the sum bounded by $\epsilon$, hence $\{S_n\}$ is a Cauchy sequence. Let $b=\sum_{n=0}^\infty a^n$, we want to show that $b(1-a)=1$.
    \begin{equation*}
        b(1-a)=\lim_{n\to\infty}{S_n}(1-a)=\lim_{n\to\infty}\left(\sum_{n=0}^\infty a^n\right)(1-a)=\lim_{n\to\infty}(1-a^{n+1})=1
    \end{equation*}
    The last inequality follows from $\|a^{n+1}\|\leq\|a\|^{n+1}\to 0$.
\end{proof}


\section{Lecture 3}
We now begin.

Let $\mathcal{A}$ be a unital Banach algebra, and if $a\in\mathcal{A}$ and $\|a\|<1$, then we have $(1-a)$ has an inverse and if $\mathcal{A}=\mathcal{B}(B)$, where $B$ is some Banach space, then $T\in\mathcal{A}$, and $\|T\|<1$, then we have
\begin{equation*}
    (1-T)^{-1}=\sum T^n
\end{equation*} 

The above is called the Newmann series.

Now we have the following corollary.
\begin{corollary}
    If $a\in\mathcal{A}$ and $\|1-a\|<1$, then $a$ is invertible.
\end{corollary}
\begin{proof}
    $a=1-(1-a)$.
\end{proof}


\begin{proposition}
    The set of invertible elements of $\mathcal{A}$ is an open subset of $\mathcal{A}$.
\end{proposition}
\begin{proof}
    The open ball about 1 consists of invertible elements. If $d$ is any invertible element, then we define $a\mapsto da$. This map is continuous, i.e. it is the left representation $L_b(a)=ab$ for all $a\in\mathcal{A}$. If $d$ is invertible, then the inverse is also continuous, hence it is a homeomorphism of $\mathcal{A}$ onto itself.

    Denote the unit ball about $1$ as $B_1(1)$, and let $d$ be some invertible element, under $L_d$, homeomorphism, $O\mapsto d\cdot O$, this set is open, and consists of invertible elements. We take the union of all these elements, which give us an open set including every invertible elements.
\end{proof}
\qed

\begin{proposition}
    Let $C(X)$ be the unital Banach algebra, and for $f\in C(X)$, we have $\alpha\in Range(f)$ if and only if $(f-\alpha\cdot 1)$ is not invertible.
\end{proposition}
\begin{proof}
Let $f\in C(X)$, and if $\alpha\in$ range of $f$, so $\alpha=f(x_0)$ for some $x_0$. then
\begin{equation*}
    (f-\alpha\cdot 1)(x_0)=0
\end{equation*}
Hence $f(-\alpha\cdot 1)$ is not invertible.
Conversely, if we have $f-\alpha 1$ is not invertible, then there exists $x_0\in X$ such that
\begin{equation*}
    (f-\alpha\cdot1)(x_0)=0
\end{equation*}
Hence $f(x_0)=\alpha$, i.e., $\alpha\in$ range of $f$.
\end{proof}
\qed


\begin{definition}[spectrum of an element]
    For any unital algebra $\mathcal{A}$ over some field $\mathbb{F}$, for any $a\in\mathcal{A}$, the set
    \begin{equation*}
        \{\lambda\in\mathbb{F}: a-\lambda 1_\mathcal{A}\text{ is not invertible }\}
    \end{equation*}
    is called the spectrum of $a$, denoted as $\sigma(a)$.
\end{definition}

Interpret this in our familiar linear map: $\lambda$ is called an eigenvalue, i.e. is in the spectrum of $T$ if we have $T-\lambda I$ is not invertible.

\begin{proposition}
    Let $\mathcal{A}$ be a unital Banach algebra, and let $a\in\mathcal{A}$, then if $\lambda\in\sigma(a)$, then
    \begin{equation*}
        |\lambda|\leq\|a\|
    \end{equation*}
\end{proposition}
\begin{proof}
    Suppose $|\lambda|>\|a\|$, then $\lambda\neq 0$, then
    \begin{equation*}
        a-\lambda\cdot 1=-\lambda(1-\frac{a}{\lambda})
    \end{equation*}
    And by assumption, $\|a/\lambda\|\leq 1$, hence $(1-a/\lambda)$ is invertible. Hence $a-\lambda\cdot 1$ is invertible (product of two invertible elements),  meaning $\alpha\not\in\sigma(a)$.
\end{proof}
\qed

\begin{proposition}
    Let $\varphi$ be a multiplicative linear functional on $\mathcal{A}$, i.e. $\varphi\in\widehat{\mathcal{A}}$, and then $\varphi(a)\in\sigma(a)$, and we have
    \begin{equation*}
        |\varphi(a)|\leq\|a\|, \|\varphi\|=1
    \end{equation*}
\end{proposition}
\begin{proof}
    $\varphi(a-\varphi(a)\cdot 1)=0$.
    Hence $a-\varphi(a)1$ is not invertible.
\end{proof}
\qed


\begin{proposition}
    $\sigma(a)$ is a closed subset of $\mathbb{R}, \mathbb{C}$.
\end{proposition}
\begin{proof}
    Define the map $\phi: \lambda\mapsto a-\lambda1$, the map $\phi$ is continuous (multiplication and subtraction are both continuous). We know the set of invertible elements of $\mathcal{A}$ is open, hence
    \begin{equation*}
        \sigma(a)=\phi^{-1}(\text{ noninvertible})=\phi^{-1}(\mathcal{A}\setminus\text{ invertible })
    \end{equation*}
    Or simply,
    \begin{equation*}
        \sigma(a)=(\phi^{-1}(\text{ invertible }))^c
    \end{equation*}
    Hence the spectrum of an element is closed.
\end{proof}
\qed


Let $\varphi\in\widehat{\mathcal{A}}$ then $\|\varphi\|=1$. So $\widehat{\mathcal{A}}$ is a subset of the unit ball of $\mathcal{A}'$, which denotes the dual vector space of continuous linear transformations.


On $\mathcal{A}'$, we can equip the weak-* topology, i.e. the weakest topology, making the map $\psi\mapsto\psi(a)$ continuous. 

\begin{proposition}
    $\widehat{\mathcal{A}}$ is closed for the weak-* topology.
\end{proposition}
\begin{proof}
    let $\{\varphi_\lambda\}$ be a net of elemnts of $\widehat{\mathcal{A}}$, that converges to some $\psi\in\mathcal{A}'$ in the weak-* topology, i.e., for every $a\in\mathcal{A}$, $\varphi_\lambda(a)\to\psi(a)$ for all $a\in\mathcal{A}$.

    Then $\varphi(a,b)=\lim\varphi_\lambda(ab)=\lim\varphi_\lambda(a)\varphi_\lambda(b)=\varphi(a)\varphi(b)$.

    $\varphi(1)=\lim(\varphi_\lambda(1))=\lim 1=1$.
\end{proof}

\begin{theorem}[Alaoglu's theorem]
    For any normed vector space $V$, the closed unit ball of $V'$ is compact in the weak-* topology. 
\end{theorem}
As an immediate corollary, we have the following.
\begin{corollary}
    $\widehat{\mathcal{A}}$ is compact with respect to the weak-* toplogy.
\end{corollary}
\begin{proof}
    $\widehat{\mathcal{A}}$ is a closed subset of a compact set, hence is also compact.
\end{proof}
\qed

Let $\mathcal{A}=C(X)$, and $\widehat{\mathcal{A}}$, we define $x\mapsto\varphi_x$ is a bijection. The weak-* topology in $\widehat{\mathcal{A}}$ makes $\varphi_x\mapsto\varphi_x(f)=f(x)$ continuous. Such $x\mapsto\varphi_x$ is a homomorphism of $X$ onto $\mathcal{A}$.

For $\mathcal{A}$ unital Banach algebra, commutative, for any $a\in\mathcal{A}$, define
\begin{equation*}
    \widehat{a}\in C(\widehat{\mathcal{A}}), \widehat{a}(\varphi)=\varphi(a)
\end{equation*}

\begin{proposition}
    The map $a\mapsto\widehat{a}$ is a unital algebra homomorphism from $\mathcal{A}$ into $C(\mathcal{A})$.
\end{proposition}
\begin{proof}
    we have
\begin{equation*}
    \widehat{ab}(\varphi)=\varphi(ab)=\varphi(a)\varphi(b)=\widehat{a}(\varphi)\widehat{b}(\varphi)=(\widehat{a}\widehat{b})(\varphi)
\end{equation*}

Hence
\begin{equation*}
    (\widehat{ab})=\widehat{a}\widehat{b}, \widehat{(a+b)}=\widehat{a}+\widehat{b}, \widehat{1_a}=1
\end{equation*}
\end{proof}
\qed


\section{Lecture 4}
Today we talk about the structure of $\widehat{l^1(S)}, \widehat{l^1(G)}$, where $S,G$ are semigroups and groups, and how they naturally identify with the unit disk $\D$, and the unit circle $\T$.

Let $S$ be a commutative discrete semigroups, for example $\N\cup\{0\}$, and $f\in C_c(S)$, then we can write $f=\sum_{x\in S}f(x)\delta_x$, where we define $\delta_x\delta_y=\delta_{xy}$. Note that $C_c(S)$ is dense in $l^1(S)$.
\begin{definition}[Convolution]
    Take any $f,g\in C_c(S)$, we consider the following:
    \begin{equation*}
        \sum_{x\in S}f(x)\delta_x\sum_{x\in S}g(y)\delta_y=\sum_{x\cdot y}\delta_{xy}=\sum_{z\in S}\left(\sum_{xy=z}f(x)g(y)\right)\delta_z
    \end{equation*}
    where we define the convolution between two functions
    \begin{equation*}
        f\ast g(z)=\sum_{x,y, xy=z}f(x)g(y)
    \end{equation*}
\end{definition}

And under this convolution operation, we have $l^1(S), \ast$ as a Banach algebra.
\begin{example}
    If we consider polynomials of the form $f(x)=\sum_{n=0}^\infty f(n)x^n$, and consider the operation between two polynomials
    \begin{equation*}
        \left(\sum f(m)x^m\right)\left(\sum g(n)x^n \right)=\sum_{p}\left(\sum_{m+n=p}f(m)g(n)x^p \right)=\sum_{p}(f\ast g)(p)
    \end{equation*}
\end{example}

And let $f\in C_c(S)$, where $S=\N$. we define $\|f\|_{l^1}=\sum_{x\in S}|f(x)|$.

It is easy to check we have
\begin{equation*}
    \|f\ast g\|_{l^1}\leq\|f\|_{l^1}\|g\|_{l^1}
\end{equation*}

We let $\mathcal{A}=l^1(S)$, and $\widehat{\mathcal{A}}$ denote the set of unital homomorphisms from $\mathcal{A}$ to $\R, \C$. Note that $\|\varphi\|=1, \varphi\in\widehat{\mathcal{A}}$.

Note that we know $(l^1(S))'=l^\infty(S)$, hence $\widehat{\mathcal{A}}\subset\mathcal{A}'$. Note that we have $\|\varphi\|=1$, hence if we $\varphi\in l^\infty(S)$, we have
\begin{equation*}
    \|\varphi\|_{l^\infty}=1
\end{equation*}
Then for $z\in S, \|z\|\leq 1$, we have $|\varphi(z)|\leq 1$.

\begin{proposition}
    We naturally identify $\widehat{l^1(S)}$ with $Hom(S,\D)$, i.e. $\{\varphi\in l^\infty(S): \|\varphi\|_{l^\infty}=1\}$.
\end{proposition}
\begin{proof}
    Given $f\in\widehat{l^1(S)}$, we know it's multiplicative, unital, hence all these transfer when viewing $\varphi\in l^\infty(S)$. This implies
    \begin{equation*}
        \varphi(\delta_x)\varphi(\delta_y)=\varphi(\delta_{xy})\Rightarrow \varphi(x)\varphi(y)=\varphi(xy)
    \end{equation*}
    Note here $xy$ denotes the operation on $S$ between $x,y$, for example, could be $x+y$. Hence naturally, if $\varphi\in\widehat{l^1(S)}$, $\varphi$ can also be viewed as $\varphi: S\to\D$, and thus is in $l^\infty$, with $|\varphi(s)|\leq 1$.
\end{proof}
\qed

Furthermore, we can identify elements in $\widehat{l^1(S)}$ with the unit disk. Take $S=\N$.
\begin{proposition}
    \begin{equation*}
        \widehat{l^1(\N)}\cong \D
    \end{equation*}
    where $\D$ denotes the unit disk in $\C$.
\end{proposition}
\begin{proof}
    We motivate this by noticing $\N$ is generated by 1, and thus viewing $\varphi\in\widehat{l^1(\N)}$ as $\varphi\in l^\infty(\N)$, we have $\varphi$ is determined by $\varphi(1)$. And denote $\varphi(1)=z_0$, then we have
    \begin{equation*}
        \varphi(n)=z_0^n
    \end{equation*}
    We thus define a map as follows, for $z\in\D$, 
    \begin{equation*}
        z\mapsto \varphi(n)=z^n
    \end{equation*}
    The map is continuous, bijective, and thus a homeomorphism between compact and Hausdorff space.
\end{proof}
\qed

\begin{proposition}
    The standard topology on $\D$ coincides with the weak-* topology on $\widehat{l^1(\N)}$.
    \begin{equation*}
        D_{std}\cong D_{weak-*}
    \end{equation*}
\end{proposition}
\begin{proof}
    We just need to associate an element in $\D$ with a function $\varphi\in\widehat{l^1(\N)}$. And we do this by
    \begin{equation*}
        z\mapsto \sum_{n\in\N}f(n)x^n
    \end{equation*}
    Both maps are continuous, bijective, and between compact and Hausdorff space, hence is a homeomorphism.
\end{proof}

\subsection{On groups}

We let $G$ denote a discrete commutative group, and we see everything above follows, with one extra property.

\begin{proposition}
    We have the following:
    \begin{equation*}
        \widehat{l^1(G)}\cong \T
    \end{equation*}
    where $\T$ denotes the unit circle $\{z\in\C: |z|=1\}$.
\end{proposition}
\begin{proof}
    For $\varphi\in\widehat{l^1(G)}$, we have
    \begin{equation*}
        |\varphi(x\cdot x^{-1})|=|\varphi(e)|=1
    \end{equation*}
    Because $|\varphi(x)|\leq 1, \forall x$, Hence we have
    \begin{equation*}
        |\varphi(x)|=1, \forall x
    \end{equation*}
    Hence we have $\widehat{l^1(G)}$ naturally identifies with $\T$. Like what we described above, we have what is desired.
\end{proof}
\qed

\begin{remark}
    Take $G=\mathbb{Z}$, if we denote $z\in\T$ as $z=e^{2\pi it}$, then we naturally identify with
    \begin{equation*}
        \sum_{n\in\mathbb{Z}}f(m)e^{2\pi int}
    \end{equation*}
    we denote this mapping as $\widehat{f}$, i.e.
    \begin{equation*}
        \widehat{f}(z)=\sum_{m\in\mathbb{Z}}f(m)e^{2\pi int}
    \end{equation*}
    This is the Fourier transform.
\end{remark}

\section{Lecture 5}
Last time, we talked about if we denote $\mathcal{A}=l^1(G)$, equipped with $\|\cdot\|_{l^1}$, under convolution, we have
\begin{equation*}
    \widehat{\mathcal{A}}\text{ ``='' } Hom(G,\T)
\end{equation*}

If we take $G=(\mathbb{Q}, +)$, one can ask the question if $\widehat{\mathcal{A}}$ is big enough. And we will se later in the course, the answer is yes.

For pointwise multiplication, $\widehat{G}$ forms a group, and in fact $\widehat{G}$ is a compact topological group.

For any compact commutative group $G$, for exapmle $\R^n$ under $+$. Define
\begin{equation*}
    \widehat{G}=\text{ continuous homomorphisms into } \T
\end{equation*}
\begin{remark}
    We now require continuous with this general $G$ (previously was not required for discrete group $G$).
\end{remark}

\begin{proposition}
    Let $G$ be a locally compact and commutative group, we have $\widehat{G}$ as a locally compact, commutative group.
\end{proposition}

We define the pairing between $G$ and $\widehat{G}$ as follows: $x\in G, \varphi\in\widehat{G}$,
\begin{equation*}
    \varphi(x)=\langle x, \varphi \rangle
\end{equation*}

And we have the folliwng map is a homeomorphism.
\begin{equation*}
    G\mapsto \widehat{\widehat{G}}
\end{equation*}

Now let $G,H$ denote locally compact groups, and $\phi:G\to H$ bet a continuous homomorphism.
Note we have the following diagram:
\begin{equation*}
    G \xrightarrow{\phi} H
\end{equation*}
\begin{equation*}
    \widehat{G} \xleftarrow{\phi}\widehat{H}
\end{equation*}
If we take an element $\psi\in\widehat{H}$, we consider $\psi\circ\phi$. We get $\psi\circ\phi\in\widehat{G}$.

\begin{definition}[category, functor]
    A category is specified by 
    \begin{enumerate}
        \item a set of objects
        \item morphisms between objects
        \begin{enumerate}
            \item $X, Y, Z$ are objects, and if
            \begin{equation*}
                X\xrightarrow{\Phi} Y\xrightarrow{\Psi} Z
            \end{equation*}
            \item For each object $X$, there is an identity morphism $1_X$.
        \end{enumerate}
    \end{enumerate}
    And a functor is defined to be such a morphism between categories.
\end{definition}
\begin{example}
    For category of finite vector spaces $V$, passing from vector space to its dual $V'$ is a functor.

    Note that we have the following diagram, assuming they are vector spaces over the reals,
    \begin{equation*}
        V\xrightarrow{T}W
    \end{equation*}
    \begin{equation*}
        V'\xLeftarrow{T^t}W'
    \end{equation*}
    \begin{equation*}
        V''\xrightarrow{T^{tt}}W''
    \end{equation*}
\end{example}

The map going in the same directions $V\to W$, and $V''\to W''$ is called covariant, whereas $V'\leftarrow W'$ is called contravariant.
\begin{example}
    For category of locally compact groups $G,H$, assigning the dual group is a functor:
    \begin{equation*}
        G\to H
    \end{equation*}
    \begin{equation*}
        \widehat{G}\leftarrow\widehat{H}
    \end{equation*}
    \begin{equation*}
        \widehat{\widehat{G}}\to\widehat{\widehat{H}}
    \end{equation*}
\end{example}
\begin{example}
Now let $X$ be a compact space. Given $\Phi$ continuous map between $X\to Y$.
\begin{equation*}
    X\xrightarrow{\Phi}Y
\end{equation*}
\begin{equation*}
    C(X)\leftarrow{C(\Phi)} C(Y)
\end{equation*}
For $f\in C(Y)$, we define
\begin{equation*}
    C(\Phi)(f)=f\circ\Phi
\end{equation*}
Similarly, we take
\begin{equation*}
    X\xrightarrow{\varphi}\xrightarrow{\phi}Z
\end{equation*}
\begin{equation*}
    C(X)\xleftarrow{C(\varphi)}C(Y)\xleftarrow{C(\phi)}C(Z)
\end{equation*}
where for $f\in C(Y), C(\varphi)(f)=f\circ\varphi$, and $g\in C(Z), C(\phi)=g\circ \phi$. 
This is a contravariant functor from the category of compact Hausdorff space into the category of unital commutative Banach algebra.
\end{example}

Now we build an important intuition that given a unital algebra homomorphism map between $C(X)$ and $C(Y)$, there eixsts a map from $X$ to $Y$.
\begin{proposition}
    Suppose $X,Y$ are compact, there exists a unital algebra homomorphism
    \begin{equation*}
        C(X)\xleftarrow{F} C(Y)
    \end{equation*}
    Then there exists a continuous homomorphism $\check{F}: X\to Y$.
\end{proposition}
\begin{proof}
    Define $\varphi_x:C(X)\to\C$ as the evalutation map: take $f\in C(X)$,
    \begin{equation*}
        \varphi_x(f)=f(x)
    \end{equation*}
    Then $\varphi_x\circ F\in\widehat{C(Y)}$. And we know that any element in $\widehat{C(Y)}$ is a point evaluation, i.e. there exists $y\in Y$ such that
    \begin{equation*}
        \varphi_y=\varphi_x\circ F
    \end{equation*}
    We thus define $\check{F}(x)=y$ as such that it satisfies the above equation. We need to show $\check{F}$ is continuous. Note that $X,Y$ are compact Hausdorff spaces, and the topology on $Y$ is the coarest topology making all functions $g\in C(Y)$ continuous.
    \begin{align*}
        g\circ\check{F}(x)&=g(\check{F}(x))\\
        &=g(y: \varphi_y=\varphi_x\circ F)\\
        &=\varphi_y(g: \varphi_y=\varphi_x\circ F)\\
        &=\varphi_x\circ F(g)\\
        &=F(g)(x)
    \end{align*}
    Hence by $F,g$ being continuous, we have $\check{F}$ is also continuous. 
\end{proof}
\qed

There is a natural bijection between the continuous functiosn from $X$ to $Y$, and the unital algebra homomorphism from $C(X)$ to $C(Y)$.

A quick reminder:

\begin{remark}
    For $X$ compact, the weak-* topology coincides with the standard topology.
\end{remark}

\section{Lecture 6}

Now we begin. From Aren "not talking to you is torture."

Let $\mathcal{A}$ be a unital Banach algebra.

We write $GL_n(\mathcal{A})$ to denote the general linear group, the group formed by $n\times n$ matrices with entries from $\mathcal{A}$. 

The less standard notation is $GL_I(\mathcal{A})$ is the group of invertible elements in $\mathcal{A}$. As we have shown previously, this is a closed subset of $\mathcal{A}$. This is the notation that we will use.

\begin{remark}
    It is easy to see that the product is jointly continuous.
\end{remark}

\begin{proposition}
    The following map is continuous.
    \begin{equation*}
        a\mapsto a^{-1}
    \end{equation*}
\end{proposition}
\begin{proof}
    Given $\|a-b\|<\delta$, we would like to show $\|a^{-1}-b^{-1}\|<\epsilon$. We first rewrite
    \begin{equation*}
        a^{-1}-b^{-1}=a^{-1}(b-a)b^{-1}
    \end{equation*}
    Hence we have
    \begin{equation*}
        \|a^{-1}-b^{-1}\|\leq\|a^{-1}\|\|b-a\|\|b^{-1}\|
    \end{equation*}
    Take $\delta=\epsilon/\|a^{-1}\|\|b^{-1}\|$ would suffice.
\end{proof}
\qed

\begin{proposition}
    Fix $a\in GL(\mathcal{A})$, there exists a neighborhood $O$ of $a$ and a constant $K$ such that for all $y\in O$, we have
    \begin{equation*}
        \|c^{-1}\|<K
    \end{equation*}
\end{proposition}
\begin{proof}
    Let $V=\{d\in\mathcal{A}: \|1-d\|<1/2\}$, then $d$ is invertible and
    \begin{equation*}
        d^{-1}=\sum_{n=0}^\infty(1-d)^n
    \end{equation*}
    We thus have
    \begin{equation*}
        \|d^{-1}\|\leq\frac{1}{1-\|1-d\|}\leq \frac{1}{1-1/2}=2
    \end{equation*}
    We then identify what our $O$ should be. Let $O=aV$, then we want to show that every $ad$ has an inverse with bounded norm. Because $a,d$ are both invertible, $ad$ is also invertible.
    \begin{equation*}
        \|(ad^{-1})\|=\|d^{-1}a^{-1}\|\leq \|d^{-1}\|\|a^{-1}\|\leq 2\|a^{-1}\|
    \end{equation*}
\end{proof}
\qed

\begin{remark}
    For each invertible element, we can find a neighborhood of invertible elements around it, and using that $(1-d)$ is bounded, then $d$ is invertible, we can bound $\|d^{-1}\|$.
\end{remark}

\begin{definition}
    Fix $a\in\mathcal{A}$, the resolvent set of $\mathcal{A}$ is the complement of spectrum of $\mathcal{A}$, i.e. it is the set
    \begin{equation*}
        \{\lambda\in\mathbb{F}: a-\lambda I \text{ is invertible } \}
    \end{equation*}
\end{definition}

Hence the resolvent set is an open, unbounded suset of $\C$ or $\R$.

\begin{definition}[Resolvent function]
    On the resolvent set, $\{\lambda\in\mathbb{F}: a-\lambda1 \text{ is invertible }\}$ is as follows:
    \begin{equation*}
        R(a,\lambda)=(\lambda1_\mathcal{A}-a)^{-1}
    \end{equation*}
    note that $a$ is fixed, and $\lambda$ is the variable here.
\end{definition}

Now we note that this $R_a(\lambda)$ function is nicely behaved.
\begin{proposition}
    The resolvent function $R_a(z)$ is analytic on the resolvent set, and vanishes as $z\to\infty$.
\end{proposition}
\begin{proof}
    We first define the notation of analyticity on an open subset of $\R, \C$: this means for every point in the open set $O$, we can find a power series expansion of the function such that its radius of convergence $>0$.

    Fix $z_0$ in the resolvent set. We know $z_01_\mathcal{A}-a$ is invertible. We consider $(z1_\mathcal{A}-a)$, for $z$ in the resolvent set. We will omit the $1_\mathcal{A}$ for simplicity.
    \begin{equation*}
        z1_\mathcal{A}-a=(z_0-a)-(z_0-z)=(z_0-a)\left(1_\mathcal{A}-\frac{z_0-z}{z_0-a}\right)
    \end{equation*}
    We know the the latter term is invertible if $\|\frac{z_0-z}{z_0-a}\|<1$ has norm, hence we have
    \begin{equation*}
        (z-a)^{-1}=\sum_{n=0}^\infty\left(\frac{z_0-z}{z_0-a}^n \right)(z_0-a)^{-1}
    \end{equation*}

    What happens when we let $z\to\infty$, we consider $R_a(1/z)$, and let $z\to 0$. Note that we have the following:
    \begin{equation*}
        R_a\left(\frac{1}{z}\right)=\left(\frac{1}{z}-a\right)^{-1}=\left(\frac{1-az}{z} \right)^{-1}=z(1-az)^{-1}
    \end{equation*}
    Let $z\to 0$ makes $R_a(1/z)$ go to zero.
\end{proof}
\qed

Now given that $R_a(z)$ is analytic and bounded at $\infty$, we can state the following important theorem.
\begin{theorem}[Nonemptyness of spectrum]
    Let $\mathcal{A}$ be a unital Banach algebra over $\C$, then for any $a\in\mathcal{A}$, we have $\sigma(a)\neq\emptyset$.
\end{theorem}
\begin{proof}
    Assume there exists $a\in\mathcal{A}$, such that $\sigma(a)=\emptyset$.
    If $\mathcal{A}=\mathcal{C}$, then we would have $R_a(\lambda)$ be a bounded entire, complex-valued function defined on all of $\C$. By Liouville's theorem, we must have $R_a(z)$ a constant function, but we know $z\to\infty$, $R_a\to 0$, hence $R_a(z)$ is constantly 0, but this cannot be true. 

    If our $\mathcal{A}$ is a more general Banach algebra, then we take a slight detour of creating an entire bounded function, via the following map
    \begin{equation*}
        z\mapsto \phi(R_a(z))
    \end{equation*}
    where $\phi$ is some nonzero element in $\mathcal{A}'$, guaranteed by Hahn-Banach theorem. Then we have the above map is complex-valued, entire, bounded at $\infty$. Again, the function is constantly 0. 
\end{proof}

With the nonemptyness of spectrum theorem, we now state the Gelfand-Mazur theorem.
\begin{theorem}[Gelfand-Mazur]
    Let $\mathcal{A}$ be a unital Banach algebra over $\C$, if any nonzero element of $\mathcal{A}$ is invertible, then $\mathcal{A}$ is isomorphic to $\C$.
\end{theorem}
\begin{proof}
    For any $a\in\mathcal{A}$, we know $\sigma(a)\neq\emptyset$, hence there exists $\lambda$ such that $\lambda1_\mathcal{A}-a$ is invertible, i.e. $a=\lambda1_\mathcal{A}$, hence establishing an isomorphism between $\mathcal{A}$ and $\C$. In other words, $\mathcal{A}=\C1_\mathcal{A}$.
\end{proof}
\qed


\subsection{Functional Calculus}
\begin{proposition}
    Let $a\in\mathcal{A}$, then if $f(z)=\sum_{n=0}^\infty \alpha_nz^n$ converges for $|z|<r$, where $r>\|a\|$, then $\sum_{n=0}^\infty\alpha_na^n$ converges as well.
\end{proposition}

We first start with proving the following statement.
\begin{lemma}
    Let $f$ be a polynomial, $\mathcal{A}$ is a unital Banach algebra over $\C$, $f=\sum_{n=0}^ka_nx^n$, then for $a\in\mathcal{A}$, we have
    \begin{equation*}
        \sigma(f(a))=f(\sigma(a))
    \end{equation*}
    This states the spectrum of $a$ under $f$ is exactly the spectrum of $f$ evaluated at $a$.
\end{lemma}
\begin{proof}
    $(\Leftarrow)$. We take $\lambda\in\sigma(a)$, and we would like to show $f(\lambda)$ is in the spectrum of $f(a)$. We note that if $\lambda\in\sigma(a)$, then $a=\lambda1_\mathcal{A}$, and $f(\lambda1_\mathcal{A})=f(a)$, hence by definition, $f(a)-f(\lambda)1_\mathcal{A}$ is not invertible implying $f(\lambda)$ is in the spectrum of $f(a)$. Note that this also implies $f(a)-f(\lambda)=(a-\lambda)Q(z)$ for some polynomial $Q(z)$.

    $(\Rightarrow)$. We take $\lambda\in\sigma(f(a))$, i.e. $f(a)=\lambda1_\mathcal{A}$. we would like to show $\lambda=f(y)$, where $y\in\sigma(a)$. If $f$ is some polynomial, then we can rewrite as follows:
    \begin{equation*}
        f(z)-\lambda=d(z-c_1)...(z-c_n)
    \end{equation*}
    Plugging in $a$ we get
    \begin{equation*}
        f(a)-\lambda=d(a-c_11_\mathcal{A})...(a-c_n1_\mathcal{A})
    \end{equation*}
    If $f(a)-\lambda$ is not invertible, then there exists $j$ such that $(a-c_j1_\mathcal{A})$ is not invertible. This implies,
    \begin{equation*}
        c_j\in\sigma(a)
    \end{equation*}
    Recall we would like to show $\lambda=f(y)$, where $y\in\sigma(a)$. In fact, we have $\lambda=f(c_j)$ by knowing $f(c_j)-\lambda=0$. 
\end{proof}
\qed

Now let $f(z)=z^n$, and if $\lambda\in\sigma(a)$, then $\lambda^n\in\sigma(a^n)$ by the previous lemma. Then we know that 
\begin{equation*}
    |\lambda^n|=|\lambda|^n\leq\|a^n\|
\end{equation*}
This implies
\begin{equation*}
    |\lambda|\leq\|a^n\|^{1/n}, \forall n
\end{equation*}
Hence we have
\begin{equation*}
    |\lambda|\leq\liminf_n\{\|a^n\|^{1/n}\}
\end{equation*}

\begin{definition}[spectral radius]
    Fix $a\in\mathcal{A}$, we define the spectral radius of $a$, denoted by $r(a)$,
    \begin{equation*}
        r(a)=\sup_\lambda\{|\lambda|:\lambda\in\sigma(a)\}
    \end{equation*}
\end{definition}
Next we introduce an equivalent definition of the spectral radius which connects to the Gelfand transform.
\begin{proposition}
    For $\mathcal{A}$ a Banach algebra, we have the following relationship:
    \begin{equation*}
        r(a)=\sup\{|\lambda|:\lambda\in\sigma(a)\}=\|\Gamma(a)\|_\infty
    \end{equation*}
\end{proposition}

\begin{example}
    Note it we have a self-adjoint operator $T$, then the spectral radius of $T$ would be the absolute value of the largest eigenvalue, $|\lambda|$.
\end{example}
\begin{corollary}
    \begin{equation*}
        r(a)\leq\limsup_n\{\|a^n\|^{1/n}\}
    \end{equation*}
\end{corollary}
\begin{proof}
From the previous remark that $|\lambda|\leq\|a^n\|^{1/n}$, hence this follows.
\end{proof}


\section{Lecture 7}
I have not typed up for this?


\section{Lecture 8}
Let $\mathcal{A}$ be a unital Banach algebra. Then for $a\in\mathcal{A}$, and we look at the resolvent of $a$, $R_a(\lambda)$, we've noted that as $\lambda\to\infty$, we have
\begin{equation*}
    \lim_{\lambda\to\infty}R_a(\lambda)=\lim_{\lambda\to\infty}(\lambda1_\mathcal{A}-a)^{-1}=\lim_{\lambda\to\infty}\lambda^{-1}\sum_{n=0}^\infty a^n\lambda^{-n}
\end{equation*}
And the above Laurent series converges for $|\lambda|\geq\|a\|$.

Recall that we define the spectral raidus, $r(a)$, as 
\begin{equation*}
    r(a)=\sup\{|\lambda|:\lambda\in\sigma(a)\}\leq\|a\|
\end{equation*}

Now we would like to prove the following proposition.
\begin{proposition}[Gelfand-Beurling]
    \begin{equation*}
        r(a)=\lim\|a^n\|^{1/n}
    \end{equation*}
\end{proposition}

\begin{proof}

If we let $\lambda=1/z$, then 
\begin{equation*}
    R(a,z)=z\sum_{n=0}^\infty a^nz^n
\end{equation*}
This converges for $|z|\leq\|a\|^{-1}$, but maybe?? also for $|z|< r(a)^{-1}$?

For $r>r(a)$, i.e. $|z|\leq r^{-1}$, we  know $\sum_na^nr^n$ converges for $r>r(a)$. 

know $z\sum a^nz^n$ converges absolutely. In particular,
\begin{equation*}
    a^nz^n\to 0
\end{equation*}
Hence there exists $M$ such that for $n\geq M$, we have
\begin{equation*}
    \|a^nr^{-n}\|\leq 1
\end{equation*}
This implies that
\begin{equation*}
    \|a^n\|\leq r^n \Rightarrow \|a^n\|^{1/n}\leq r 
\end{equation*}
for all $n\geq M$.

This implies that
\begin{equation*}
    \limsup \|a^n\|^{1/n}\leq r
\end{equation*}
And note that $r$ is arbitrary close to the spectral radius $r(a)$. Hence we have
\begin{equation*}
    \limsup \|a^n\|^{1/n}\leq r(a)\leq\liminf\|a^n\|^{1/n}
\end{equation*}
We've derived the second inequality from last class. Hence all inequalities become equalities.
This gives us
\begin{equation*}
    r(a)=\lim \|a^n\|^{1/n}
\end{equation*}

\end{proof}
\qed


For each $\varphi\in\mathcal{A}'$, consider the map
\begin{equation*}
    \lambda\mapsto\lambda^{-1}\sum\varphi(a^n)\lambda^{-n}
\end{equation*}
This series converges for $r>r(a)$.
We can apply the same process, to argue that there exists $M_\varphi$ such that
\begin{equation*}
    \|\varphi(a^n)r^{-n}\|\leq M_\varphi
\end{equation*}
for all $n\geq 0$. Note that $M_\varphi$ could be different for all $\varphi$. 

Note that 
\begin{equation*}
    \mathcal{A}\to \mathcal{A}'\to \mathcal{A}''
\end{equation*}
there is a natural injection of $a\mapsto\widehat{a}\in\mathcal{A}''$.

For each $n$, definite $F_n\in\mathcal{A}''$, by $F_n(\varphi)=|\varphi(a^nr^{-n})|\leq M_\varphi$. Applying the UBP, we have
\begin{equation*}
    |F_n(\varphi)|\leq M\Rightarrow |\varphi(a^n)r^{-n}|\leq M
\end{equation*}
This implies that 
\begin{equation*}
    |\varphi(a^n)|\leq r^nM
\end{equation*}
Note that by Hahn-Banach, for any $b\in\mathcal{A}$, we have
\begin{equation*}
    \|b\|=\sup\{|\varphi(b)|:\|\varphi\|=1\}
\end{equation*}
Taking $n$-th root of both sides, we gets
\begin{equation*}
    \|a^n\|\leq r^nM\Rightarrow \|a^n\|^{1/n}\leq rM^{1/n}\to r
\end{equation*}
Hence we again obtain the same result.

\qed



Recall UBP.
\begin{theorem}[Uniform Boudnedness Principle]
    Let $X$ be Banach, and $Y$ be normed, let $T_n:X\to Y$ be a family of linear operators, and if for all $x\in X$, we have
    \begin{equation*}
        \|T_n(x)\|<\infty
    \end{equation*}
    Then for all $n$, we have
    \begin{equation*}
        \|T_n\|<\infty
    \end{equation*}
\end{theorem}

Note that 
if $\mathcal{A}$ is unital, and if $\mathcal{A}\subset\mathcal{B}$ with some unit. For $a\in\mathcal{A}$, if $a$ is not invertible in $A$, then it might be invertible in $\mathcal{B}$. Hence if we use $\sigma_\mathcal{A}(a)$ to denote the spectrum of $a$ in $\mathcal{A}$.
\begin{proposition}
    \begin{equation*}
        \sigma_\mathcal{B}(a)\subset \sigma_\mathcal{A}(a)
    \end{equation*}
\end{proposition}


\begin{example}
    Let $\mathcal{B}=l^1(\mathbb{Z})$, and let $\mathcal{A}=l^1(\N)$, equipped with convolution. 
    
    Clearly $\mathcal{A}\subset\mathcal{B}$. And note that the delta function at 1, $\delta_1$ is not invertible in $\mathcal{A}$ but it has an inverse $\delta_{-1}$ in $\mathcal{B}$. Hence we see $0\in\sigma_\mathcal{A}(a)$, but $0\not\in\sigma_\mathcal{B}(a)$.


\end{example}

\begin{proposition}[Spectral radius is preserved]
    For $\mathcal{A}\subset\mathcal{B}$, we have
    \begin{equation*}
        r_\mathcal{A}(a)=\lim\|a^n\|^{1/n}=r_\mathcal{B}(a)
    \end{equation*}
\end{proposition}
This proposition tells us that the spectral radius of an element $a\in\mathcal{A}$ is independent of the Banach algebra it is considered in, but rather only depends on itself.

\begin{proposition}
    Let $X$ be compact, and let $\mathcal{A}=C(X)$. Then for $f\in C(X)$, we have
    \begin{equation*}
        \|f^2\|_\infty=\|f\|_\infty^2
    \end{equation*}
\end{proposition}
\begin{proof}
    Look at where $f$ takes $\|f\|_\infty$, and sqaure it, since when $X$ is compact, you can actually obtain the point where $|f(x)|=\|f\|_\infty$ .
\end{proof}

\begin{remark}
The same property holds for $f$ in any unital subalgebra of $C(X)$, for example, if $X\subset\C$, and let $\mathcal{A}$=functions that are holomorphic on an open subset of $\C$ that are in $X$.
\end{remark}

\begin{proposition}
    Let $\mathcal{A}$ be a unital Banach algebra such that for $a\in\mathcal{A}$, we have
    \begin{equation*}
        \|a^2\|=\|a\|^2
    \end{equation*}
    Then we have
    \begin{equation*}
        r(a)=\|a\|
    \end{equation*}
\end{proposition}
\begin{proof}
    If we have
    \begin{equation*}
        \|a^2\|=\|a\|^2
    \end{equation*}
    This implies that
    \begin{equation*}
        \|a^4\|=\|a\|^4
    \end{equation*}
    By induction, for any $n$, we have
    \begin{equation*}
        \|a^{2^n}\|=\|a\|^{2^n}
    \end{equation*}
    Hence by taking $1/2^n$-root of both sides, we get that the spectral radius of $r(a)$
    \begin{equation*}
        r(a)=\|a^{2^n}\|^{1/2^n}=\|a\|
    \end{equation*}
\end{proof}
\qed

Let $\mathcal{H}$ be a Hilbert space, over $\C$, and let $\mathcal{A}=B(H)$, i.e. the bounded linear operators on $\mathcal{H}$, and equip with the operation of taking adjoint. $T\mapsto T^*$.

\begin{proposition}
    For any $T\in B(\mathcal{H})$, we have
    \begin{equation*}
        \|T^*T\|=\|T\|^2
    \end{equation*}
\end{proposition}
\begin{proof}
    We know that $\|T^*\|=\|T\|$. And thus
    \begin{equation*}
        \|T^*T\|\leq\|T^*\|\|T\|=\|T\|^2
    \end{equation*}
    For the reverse direction, let $\xi\in\mathcal{H}$, then
    \begin{equation*}
        \|T(\xi)\|^2=\langle T\xi, T\xi\rangle=\langle \xi, T^*T\xi\rangle\leq \|T^*T\|\|\xi\|^2
    \end{equation*} 
    where the last inequality follows form Cauchy-Schwartz. This implies that
    \begin{equation*}
        \|T(\xi)\|\leq \|T^*T\|^{1/2}\|\xi\|
    \end{equation*}
    which by definition ($\|T\|$ is the smallest constant for the inequality), gives
    \begin{equation*}
        \|T\|\leq\|T^*T\|^{1/2}
    \end{equation*}
    Taking squares we get the desired result.
\end{proof}
\qed

\begin{note}
    We used the inner product to justify $\|T\|^2\leq\|T^*T\|$, which we cannot necessarily do in a non-Hilbert space.
\end{note}
\begin{corollary}
    If $T^*=T$, then
    \begin{equation*}
        \|T^2\|=\|T\|^2
    \end{equation*}
    And we have
    \begin{equation*}
        r(T)=\|T\|
    \end{equation*}
    where the spectral radius is determined by the algebra elements.
\end{corollary}

Note that for general $T$, we have  $T^*T$ is always self-adjoint,
\begin{equation*}
    \|T\|^2=\|T^*T\|=r(T^*T)
\end{equation*}
Then we have
\begin{equation*}
    \|T\|=(r(T^*T))^{1/2}
\end{equation*}
where the spectral radius is determined by the *-algebra structure.


\section{Lecture 9}
Let $\mathcal{H}$ be a hilbert space over $\C$, and $\mathcal{B}(\mathcal{H})$ with $\|\cdot\|_\infty$, and closed under taking involutions. If $T\in\mathcal{B}(\mathcal{H})$, then
\begin{equation*}
    \|T^*T\|=\|T\|^2
\end{equation*}
So if $T^*=T$, then we have
\begin{equation*}
    \sigma(T)=\|T\|
\end{equation*}

\begin{definition}[Concrete $C^*$-algebra]
    A concrete $C^*$-algebra is a norm-closed sub-algebra $\mathcal{A}$ of $\mathcal{B}(\mathcal{H})$, for some $\mathcal{H}$ such that is \textbf{self-adjoint}, i.e., if $T\in\mathcal{A}$, then $T^*\in\mathcal{A}$. We call $\mathcal{A}$ is unital if $1_\mathcal{H}\in\mathcal{A}$. 
\end{definition}

\begin{corollary}
    If $\mathcal{A}$ is a $C^*$ algebra, then for all $a\in\mathcal{A}$,
    \begin{equation*}
        \|a^*a\|=\|a\|^2
    \end{equation*}
    If $\mathcal{A}$ is unital $C^*$-algebra, and if $a^*=a$, then $r(a)=\|a\|$.
\end{corollary}
This follows from our discussio above. Next we say a bit about the Gelfand transform.
\begin{definition}
    Let $\mathcal{A}$ be a unital Banach algebra, and commutative, then we have the Gelfand transform $\Gamma:\mathcal{A}\to C(\widehat{A})$:
    \begin{equation*}
        \Gamma(a)(\varphi)=\varphi(a)
    \end{equation*}
    \textcolor{red}{then he said something of homomor to the complex numbers or something}
\end{definition}

Note that if $a\in\mathcal{A}$, and $\varphi\in\widehat{A}$, then $\varphi(a)\in\sigma(a)$, then we have
\begin{equation*}
    |\varphi(a)|\leq\|a\|=r(a)
\end{equation*}

then $\|\widehat{a}\|_\infty\leq r(a)$. Now we would like to show
\begin{equation*}
    \|\widehat{a}\|_\infty=r(a)
\end{equation*}
\begin{theorem}
    $r(a)$ is the spectral radius of $a$, which is defined as $r(a)=\sup\{|\lambda|:\lambda\in\sigma(a)\}$, and we have
    \begin{equation*}
        r(a)=\|\widehat{a}\|_\infty
    \end{equation*}
\end{theorem}\begin{note}
    This gives us a correspondance between $\varphi$ and non-invertible elements of $\mathcal{A}$. This says if $a$ is not invertible, then we can find some $\varphi$ such that $\varphi(a)=0$, i.e. a $\varphi$ kills the non-invertible element.
\end{note}

We will now dedicate the next 50 minutes of our life to proving this theorem.
\begin{theorem}[$\varphi$ and maximal ideal]
    If $\lambda\in\sigma(a)$, then there exists $\varphi\in\widehat{A}$ such that $\varphi(a)=\lambda$. This is equiavalent to saying: if $(a-\lambda1)$ is not invertible, then there is a $\varphi\in\widehat{\mathcal{A}}$, such that 
    \begin{equation*}
        \varphi(a-\lambda1)=0
    \end{equation*}

    This means if $a$ is not invertible, then there exists $\varphi\in\widehat{\mathcal{A}}$ such that $\varphi(a)=0$.
\end{theorem}
\begin{proof}
    Suppose $a\in\mathcal{A}$, and consider
    \begin{equation*}
        a\mathcal{A}=\{ab: b\in\mathcal{A}\}
    \end{equation*}
    The set $a\mathcal{A}$ does not contain the identity element i.e. $1_\mathcal{A}\not\in a\mathcal{A}$ (otherwise it would imply it has an inverse). And $a\mathcal{A}$ is a two-sided proper ideal (by $\mathcal{A}$ being commutative).

    We now introduce a fact that we will use.
    \begin{definition}
        An ideal $I$ is maximal if $I$ is proper in $R$, and not contained in any bigger proper ideals.
    \end{definition}
        
    \begin{lemma}
        Let $R$ be a unital ring commutatitve, every proper ideal is contained in a maximal ideal (by Zorn's lemma).
    \end{lemma}

    \begin{lemma}
    For $\mathcal{A}$ unital commutative Banach algebra, if $I$ is a proper ideal, then its closure is a proper ideal.
    \end{lemma}
        \begin{proof}
        We have seen that $GL(\mathcal{A})$, the set of invertible elements, is open. Hence its complement is closed. Any proper ideal does not contain any elements in $GL(\mathcal{A})$, hence its closure is closed inside a closed set. 
        \end{proof}
    
    \begin{remark}
        Let $X$ be locally compact, but compact, such as $\R$, then we have $C_c(X)\subset C_\infty(X)$. Note that $C_c(X)$ is a proper ideal of $C_\infty(X)$, but it's dense in $C_\infty(X)$, hence its closure is the entire space, hence no longer proper. This tells us the closure of a proper ideal is not always proper, if $\mathcal{A}$ is not unital.
    \end{remark}

    \begin{theorem}
        Every maximal ideal of $\mathcal{A}$ is closed.
    \end{theorem}
        \begin{proof}
        The closure of any proper ideal is closed in unital algebras, hence its closure is itself.
        \end{proof}
    First let $V$ be a normed vector space. Let $W$ be a closed subspace, and form the quotient space $V/W$. There is a natrual way to equip $V/W$ with a norm
    \begin{equation*}
        \|\dot{v}\|=\inf\{\|v-w\|: w\in W \}
    \end{equation*}
    i.e. the distance between $v$ to $W$. This is a norm. Further if $V$ is complete, so is $V/W$.

    Let $\mathcal{A}$ be a normed algebra, commutative, unital. Let $I$ be a closed ideal.
    \begin{proposition}
        For $a,b\in\mathcal{A}$, we have 
        \begin{equation*}
            \|\dot{a}\dot{b}\|=\|\dot{ab}\|\leq \|\dot{a}\|\|\dot{b}\|
        \end{equation*}
        so that $\mathcal{A}/I$ is a normed algebra.
    \end{proposition}
        \begin{proof}
            Let $c,d\in I$, and
            \begin{equation*}
                (a-c)(b-d)=ab-(ad+cb-cd)
            \end{equation*}
            Note that $(ad+cb-cd)\in I$, hence 
            \begin{equation*}
                \|\dot{ab}\|\leq \|ab-(ad+cb-cd)\|=\|(a-c)(b-d)\|\leq\|(a-c)\|\|(b-d)\|
            \end{equation*}
            Taking infimum over all $c,d$, we get
            \begin{equation*}
                \|(\dot{ab})\|\leq\|\dot{a}\|\|\dot{b}\|
            \end{equation*}
        \end{proof}
        \qed

    \begin{proposition}
        If $\mathcal{A}$ is a Banach algebra and if $I$ is a closed ideal, then $\mathcal{A}/I$ is a Banach algebra for the norm $\|\dot{a}\|$ defined above.
    \end{proposition}
    Let $\mathcal{A}$ be a unital commutative Banach algebra over $\C$, let $I$ be a maximal ideal of $\mathcal{A}$, then $\mathcal{A}/I$ is a Banach algebra, if $\mathcal{A}/I$ has a proper ideal, then you can put this ideal back in $\mathcal{A}$ such that it contains $I$. By $I$ already being ideal, this implies that $\mathcal{A}/I$ does not contain any proper ideals.

    Now coming back. Let nonzero element in $\mathcal{A}/I$ is invertible. The Gelfand Mazur theorem tells us
    \begin{equation*}
        \mathcal{A}/I\cong \C
    \end{equation*}
    Moreover, $\mathcal{A}/I=1_{\mathcal{A}/I}\C$. Then the quotient map
    \begin{equation*}
        \mathcal{A}\to\mathcal{A}/I\cong\C
    \end{equation*}
    is an element of $\mathcal{A}$, i.e. an algebra homomorphism $\varphi$, with the property $\varphi(I)=0$.

    If $a\mathcal{A}\subset I$, then for $y\in a\mathcal{A}$, we have
    \begin{equation*}
        \varphi(y)=0
    \end{equation*}
    And we are therefore finally done. We thus have
    \begin{equation*}
        \|\widehat{a}\|=r(a)
    \end{equation*}
\end{proof}
\qed

\begin{corollary}
    We have
    \begin{equation*}
        \sigma(a)=Range(\widehat{a})
    \end{equation*}
\end{corollary}

\section{Lecture 10}
Consider $C_\infty(\R)\subset C_b(\R)$, and $C_\infty(\R)$ is an ideal of $C_b(\R)$.

\begin{definition}[Abstract $C^*$-algebra]
    An abstract $C^*$-algebra is a Banach algebra with an involution, such that 
    \begin{equation*}
        \|a^*a\|=\|a\|^2
    \end{equation*}
\end{definition}
\begin{remark}
    Zorn's lemma states that $C_\infty(\R)$ is contained in a maximal ideal, in a commutative Banach algebras, maximal ideals give rise to bounded multiplcative linear functionals.
\end{remark}
\begin{remark}
    There is ideals of $C_b(\R)$ that are bigger than $C_\infty(\R)$.
\end{remark}

There exists linear functionals that are 0 on $C_\infty(\R)$, but nonzero on $C_b(\R)$, but such functional is not ``constructable.''

We also have $c_0\subset l^\infty(\N)$, where $c_0$ are sequences that converge to 0 at infinity. Again, nonzero linear functionals exist on $l^\infty(\N)$, and is identically zero on $c_0$, but such is also not constructable.

\begin{definition}
    $\prod_{j=1}^\infty \Z_5$= the sequences of elements of $\Z_5$.
    $\bigoplus \Z_5$ all sequences that are 0 except for finitely many number of entries.
\end{definition}
Note that $\bigoplus\Z_5$ is an ideal of $\prod^\infty\Z_5$. 

\begin{proposition}
    $l^\infty(\N)$ is not separable, $\prod^\infty \Z_5$ is not separable, nor is it finitely generated.
\end{proposition}

\begin{proposition}
    If $\mathcal{A}$ is a unital commutative Banach algebra over $\C$, which is separable, and if $I$ is a closed ideal, then one can construct a maximal ideal containing $I$ by countable \textcolor{red}{what}
\end{proposition}
\begin{proof}
    Let $\{a_n\}$ be a countable subset of $\mathcal{A}$, whose linear span is dense.  
    \begin{lemma}
        Note that $\mathcal{A}/I$ contains noninvertible elements if and only if $I$ is not maximal.
    \end{lemma}
    If $I$ is not maximal, then you can find the first $a_n$ such that $a_n\in\C 1_\mathcal{A}$ such that $a_n\not\in \mathcal{A}/I$, then 
    \begin{equation*}
        \overline{a_n\mathcal{A}/I} \text{ is a proper ideal of } \mathcal{A}
    \end{equation*}
    hence it generates a proper ideal in $\mathcal{A}$, we denote it as $I_1$. If $I_1$ is not maximal, then repeat the process. By $\{a_n\}$ being countable, and that they are dense, we have a countable addition, which gives a maximal ideal containing $I$ by countable inclusions.
\end{proof}
\qed

\begin{remark}
    $C_\infty(\R)$ is separable, and $C_b(\R)$ is not separable.
\end{remark}

Let's look at $L^\infty([0,1], m)$, where $m$ denotes the Lebesgue measure. This is a $C^*$-algebra, commutaitve, unital.

Could you exhibit any linear functionals on $L^\infty$

Note that $L^2([0,1],m)$, a Hilbert space, as an algebra on $L^2$, $L^\infty$ is clsoed for the strong operator topology on $\mathcal{B}(\mathcal{H})$ by the seminorm,
\begin{equation*}
    T\in\mathcal{B}(\mathcal{H}), T\to\|t\xi\|, \text{ for } \xi\in\mathcal{H}
\end{equation*}

For example, figure 1. We say that $L^\infty([0,1])$ is a von Neumann algebra. Every commutative von Neumann algebra looks like some $L^2([0,1], \mu)$. But note that noncommutative ones are quite interesting.

For a commutative Banach algebra over $\C$, the Gelfand transform
\begin{equation*}
    a\mapsto\widehat{a}
\end{equation*}

We have
\begin{equation*}
    \|\widehat{a}\|_\infty=r(a)
\end{equation*}
\begin{proposition}[Gelfand isometric condition]
    If $\|a^2\|=\|a\|^2$, then the Gelfand transform is isometric. Thus we have
\begin{equation*}
    \|\widehat{a}\|_\infty=\|a\|
\end{equation*}
\end{proposition}

\begin{definition}[Involution $*$]
    For an involution on an algebra over $\C$, is a map $*$ from $\mathcal{A}\to\mathcal{A}$, with the properties
\begin{enumerate}
    \item $(a^*)^*=a$
    \item $(a+b)^*=a^*+b^*$
    \item $(\alpha a)^*=\overline{\alpha}a^*$ for $\alpha\in\C$.
    \item $(ab)^*=b^*a^*$
\end{enumerate}
\end{definition}

\begin{definition}[Banach $*$ algebra]
    If $\mathcal{A}$ has a norm, then we say it is a $*$ normed if
\begin{equation*}
    \|a^*\|=\|a\|
\end{equation*}
If $\mathcal{A}$ is complete, then it is called a Banach $*$ algebra.
\end{definition}

Let $G$ be a discrete group, let $\mathcal{H}$ be a Hilbert space, then $Aut(\mathcal{H})=U(\mathcal{H})$ is the group of unitary operators on $\mathcal{H}$ to itself. By a unitary representation of $G$ on $\mathcal{H}$, we mean 
\begin{definition}[Unitary representation]
    A unitary representation of $G$ on $\mathcal{H}$ is a homomorphism $\pi: G\to U(\mathcal{H})$.
\end{definition}
We note that $C_c(G)\subset l^1(G)$, and
\begin{equation*}
    \pi_f=\sum_{x\in G}f(x)\pi_x, \pi_f\pi_g=\pi_{f\ast g}
\end{equation*}
Now we ask what is $(\pi_f)^*$?
\begin{equation*}
    (\pi_f)^*=\sum \overline{f(x)}\pi_x^*=\sum_{x\in G}\overline{f(x)}\pi_{x^{-1}}=\sum\overline{f(x^{-1})}\pi_x
\end{equation*}
So we gets
\begin{equation*}
    (f^*)(x)=\overline{f(x^{-1})}
\end{equation*}
This defines an involution on $l^1(G)$. And it is easy to check that 
\begin{equation*}
    \|f^*\|_{1}=\|f\|_1
\end{equation*}
\begin{remark}
    The same process would not work for semingroups without the presence of $x^{-1}$ necessarily.
\end{remark}

We would like to think of this involution as some sort of complex conjugation.

\begin{definition}
    Let $\mathcal{A}$ be a Banach $*$-algebra is symmetric if whenever $a\in\mathcal{A}$, and $a^*=a$, then
    \begin{equation*}
        \sigma(a)\subset\R
    \end{equation*}
\end{definition}
If one looks at $l^1$ over noncommutative groups, some are symmetric, some are not.

\begin{example}
    Let $\mathcal{A}=\C\bigoplus\C$, with $\|\cdot\|_\infty$. We define an involution:
    \begin{equation*}
        (\alpha, \beta)^*=(\overline{\beta}, \overline{a})
    \end{equation*}
    This is a well-defined involution. However, this is not symmetric under this involution.
\end{example}

\begin{proposition}
    If $G$ is commutative, then $l^1(G)$ is symmetric.
\end{proposition}
\begin{equation*}
    \widehat{\mathcal{A}}=\{\text{ set of homomorphisms } G\to\T\}
\end{equation*}
This is symmetric.

\begin{proposition}
    Let $\mathcal{A}$ be an abstract, unital $C^*$-algebra, then $\mathcal{A}$ is symmetric.
\end{proposition}
This is quite strong! (Every $C^*$-algebra is symmetric).



\section*{Lecture 11}
Let $\mathcal{A}$ be a *-Banach algebra.
\begin{definition}[symmetric $*$-algebra]
    $\mathcal{A}$ is symmetric if for any $a\in\mathcal{A}$, we have
    \begin{equation*}
        a^*=a
    \end{equation*}
    we have $\sigma(a)\in\R$.
\end{definition}

Note that a $C^*$ algebra is necessarily a *-algebra. Hence we have
\begin{equation*}
    \|a\|^2=\|a^*a\|\leq\|a^*\|\|a\|
\end{equation*}
And we apply it to $a^*$, hence we get
\begin{equation*}
    \|a^*\|\leq\|a\|
\end{equation*}
Hence the involution property is satisfied.

\begin{proposition}[$C^*$-algebras are symmetric]
    Let $\mathcal{A}$ be a unital $C^*$-algebra, i.e. we have
    \begin{equation*}
        \|a^*a\|=\|a\|^2, \forall a\in\mathcal{A}
    \end{equation*}
    Then $\mathcal{A}$ is symmetric, i.e. $a^*=a$.
\end{proposition}
In the Gelfand Noimark paper (1943), 
\begin{proof}[Arens Truck, 1946]
    Given $a\in\mathcal{A}$ with $a^*=a$, for any $t\in\R$, let $b=a+it$, we look at $b^*b=(a-it)(a+it)=a^2+t^2$. So we have
    \begin{equation*}
        \|b^*b\|\leq\|a^2\|+t^2
    \end{equation*}
    Now let $\lambda\in\sigma(a)$, with $\lambda=r+is$, we would like to show $s=0$. Note we have $\lambda+it\in\sigma(b)$, this gives
    \begin{equation*}
        \lambda+it=r+i(s+t)\in\sigma(b)
    \end{equation*}
    Then we have
    \begin{equation*}
        |r+i(s+t)|\leq\|b\|
    \end{equation*}
    Hence
    \begin{equation*}
        r^2+(s+t)^2|r+i(s+t)|^2\leq\|b^2\|=\|b\|^2=\|b^*b\|\leq\|a^2\|+t^2
    \end{equation*}
    We thus have
    \begin{equation*}
        r^2+s^2+2st\leq\|a^2\|, \text{ for all } t
    \end{equation*}
    This gives $s=0$.
\end{proof}
\qed

Let's step back. Let $\mathcal{A}$ be a commutative symmetric Banach *-algebra. Then if $a\in\mathcal{A}$, and if $a^*=a$, so $\sigma(a)\subset\R$. But $\sigma(a)=Range(\widehat{a})$, so $\mathcal{A}$ is an $\R$-valued function on $\mathcal{A}$.

For any $a\in\mathcal{A}$, we have
\begin{equation*}
    a=\frac{a+a^*}{2}+i\frac{a-a^*}{2i}=a_r+ia_i
\end{equation*}
then $\widehat{a}=\widehat{a_r}+i\widehat{a_i}$, note $a^*=a_r-ia_i$, then we have
\begin{equation*}
    \widehat{a^*}=\widehat{a_r}-i\widehat{a_i}=\overline{\widehat{a}}
\end{equation*} 
Thus, we have
\begin{equation*}
    \widehat{a^*}=\overline{\widehat{a}}
\end{equation*}
So $a\mapsto\widehat{a}$ is a *-algebra homomorphism of $\mathcal{A}$ into $C(\widehat{\mathcal{A}})$.

\begin{definition}[separation of points by functions]
    A collection of functions $\{f\}_j$ defined on $X$ is said to separate points if for all $x,y\in X$, such that $x\neq y$, there exists $f$ such that we have
    \begin{equation*}
        f(x)\neq f(y)
    \end{equation*}
\end{definition}
\begin{proposition}
    For any unital commutative Banach algebra $\mathcal{A}$, then Gelfand transform $a\mapsto\widehat{a}$, separates the points of $\widehat{\mathcal{A}}$.
\end{proposition}
\begin{proof}
    We prove the contrapositive, if we assume for all $\widehat{a}$, we have $\widehat{a}(\varphi)=\widehat{a}(\psi)$, then we would like to show $\varphi=\psi$.
    If $\varphi,\psi\in\widehat{\mathcal{A}}$, and $\widehat{a}(\varphi)=\widehat{a}(\psi)$, then 
    \begin{equation*}
        \varphi(a)=\psi(a), \text{ for all } a
    \end{equation*}
    Hence $\varphi=\psi$.
\end{proof}
\qed

\begin{proposition}
    If $\mathcal{A}$ is a unital symmetric Banach *-algebra, then the image of $\Gamma$ is dense in $C(\widehat{\mathcal{A}})$.
\end{proposition}
\begin{proof}[Key ingredient: Stone-Weierstrass]
    $\{\Gamma(\varphi):\varphi\in\widehat{\mathcal{A}}\}$ is a unital subalgebra of $C(\widehat{\mathcal{A}})$ that separates the points of $\mathcal{A}$, and is closed under taking complex conjugates, so Stone-Weierstrass theorem applies (a compact space and a unital subalgebra of continuous functions that separates the points of the space, and closed under complex conjugation, then this algebra is dense for the $\|\cdot\|_\infty$ norm).
\end{proof}
\qed

\begin{theorem}[Little Galfand-Naimark theorem]
    Let $\mathcal{A}$ be a unital commutative $C^*$-algebra (abstract, which doesn't have to include hilbert space), then the Gelfand transform
    \begin{equation*}
        \widehat{a}(\varphi)=\varphi(a)
    \end{equation*}
    is an isometric *-isomorphism of $\mathcal{A}$ into $C(\widehat{\mathcal{A}})$, i.e. $\|\widehat{a}\|=\|a\|$.   
\end{theorem}
\begin{proof}
    Since $\mathcal{A}$ is symmetric, the range of the Gelfand transform is dense. We also saw that $\|a^{2^n}\|=\|a\|^{2^n}$, so the spectral radius of $a$, $r(a)=\|a\|=\|\Gamma(a)\|$. 

    Therefore $a\mapsto\Gamma(a)$ is isometric, and the range of $\Gamma(a)$ is norm-closed.
\end{proof}
\qed

\begin{remark}
    In a commutative Banach algebra, we have $r(a)=\|\widehat{a}\|_\infty$, and have $r(ab)\leq r(a)r(b)$, hence $\|a^*a\|=\|a\|^2, r(a^*a)\leq r(a)^2$, we have
    \begin{equation*}
        \|a\|^2\leq r(a)^2\leq \|a\|^2
    \end{equation*}
\end{remark}

For $T\in\mathcal{B}(\mathcal{H})$, and $T=T^*$, then
\begin{equation*}
    C^*(T,I)=\cong C(\sigma(T))
\end{equation*}

\begin{proposition}
    Let $G$ be a commutative group, then $l^1(G)$ with its * is symmetric.
\end{proposition}
\begin{proof}
    Let $\mathcal{A}=l^1(G)$, then $\widehat{\mathcal{A}}$ is isomorphic to the homomorphisms of $G$ into $T$.

    If $\varphi\in\widehat{\mathcal{A}}$, then
    \begin{equation*}
        \varphi(f):=\sum_{x\in G} f(x)\varphi(x), f\in l^1(G)
    \end{equation*}
    Then \begin{equation*}
        \varphi(f^*)=\sum f^*(x)\varphi(x)=\sum\overline{f(x^{-1})}\varphi(x)=\sum\overline{f(x)}\varphi(x^{-1})=\sum\overline{f(x)}\overline{\varphi(x)}=\overline{\varphi(f)}
    \end{equation*}

    Note how we might have homomorphisms not mapping into $\T$ if $G$ is not commutative.
\end{proof}
\qed

\begin{proposition}
    For $G$ commutative, the range of the Gelfand transform $\Gamma$, which is the Fourier transform (for $f\in l^1(\mathbb{Z})$, we have $\widehat{f}(e^{i\theta})=\sum f(n)e^{{i\theta}^n}$, note $\widehat{\mathbb{Z}}=\T$ ) in this setting, this is dense in $C(\widehat{G})$. However, this is not isometric, and the range is not norm-closed unless $G$ is finite.
\end{proposition}


\section{Lecture 12}
Recall last time, we proved the Little-Galfand-Naimark theorem.
\begin{theorem}
    Let $\mathcal{A}$ be a unital commutative $C^*$-algebra then we have
    \begin{equation*}
        \mathcal{A}\cong C(\widehat{\mathcal{A}})
    \end{equation*}
    And $\widehat{\mathcal{A}}$ is comapct. 
\end{theorem}

\begin{definition}
    Let $C$ be a category, we think of objects as categories $X,Y$, with morphisms in between $X,Y$, the abstract dual  of $C$, which is another category, has the same objects, but you reverse all the morphisms (arrows).
\end{definition}
Next we introduce the important summary of the things we've been doing.

\begin{theorem}
    The category of unitial commutative $C^*$-algebras, with unital *-homomorphisms is a concrete realization of dual of the category of compact Hausdorff spaces.
    \begin{equation*}
        X\rightarrow y
    \end{equation*}
    \begin{equation*}
        C(X)\leftarrow C(Y)
    \end{equation*}
\end{theorem}

$X$ is \textcolor{red}{normal?} if $C(X)$ contains no proper projects, i.e. elemnets like $P$ such that
\begin{equation*}
    P^2=P=P^*
\end{equation*}

We now look at the following.
\begin{proposition}
    Let $\mathcal{A}$ be a unital Banach algebra, and let $a_0\in\mathcal{A}$, suppose $\mathcal{A}$ is generated by $a_0$, i.e.e the norm closure of all the polynomials in $a_0$, with the identity $1_\mathcal{A}$. Then the $\widehat{A}$ is homeomorphic to $\sigma(a_0)$, via $\varphi\in\widehat{\mathcal{A}}$, 
    \begin{equation*}
        \varphi\mapsto \varphi(a_0)\in\sigma(a_0)
    \end{equation*}
\end{proposition}
\begin{proof}
    $\varphi$ is entirely determined by $\varphi(a_0)$, hence the map above is one-to-one. note that for every element in $\lambda\in\sigma(a_0)$, there exist $\varphi$ such that $\varphi(a_0)=\lambda$. Hence the map is also surjective.
\end{proof}

Let $\mathcal{A}$ be a unital $C^*$-algebra, and let $a\in\mathcal{A}$ and $a^*=a$, then $C^*(a,1_\mathcal{A})$ is commutative, and unital, and generated by $a$ so that
\begin{equation*}
    \widehat{B}=\sigma_B(a)
\end{equation*}
such that $\mathcal{B}=C(\widehat{\mathcal{B}})=C(\sigma(a))$, hence we have
\begin{equation*}
    C^*(a,1)\cong C(\sigma(a)), a\mapsto \widehat{a}
\end{equation*}

The continuous functional calculus (dealt with operators on a Hilbert space). Still we assume $a^*=a$.

Given $f\in C(\sigma(a))$, then there exists a $b\in C^*(a, 1)$, such that 
\begin{equation*}
    \widehat{b}=f
\end{equation*}
we denote $b$ as $f(a)$, then 
\begin{equation*}
    f\mapsto f(a)
\end{equation*}
is a *-homomorphism of $C(\sigma(a))$ onto $C^*(a, 1)$, and so into $\mathcal{A}$.

\begin{corollary}
    If $T\in\mathcal{B}(\mathcal{H})$, and if $T^*=T$, then for any function $f\in C(\sigma(T))$, we can form $f(T)$. This is part of the spectral theorem.
\end{corollary}

\begin{definition}
    In any unital $C^*$-algebra, and $a\in\mathcal{A}$, we say that $a$ is normal if $a^*\in C^*(a, 1)$, and $a^*$ and $a$ commute.
\end{definition}
We introduce the spectral permanents)
\begin{theorem}
    Let $\mathcal{A}$ be a unital $C^*$-algebra, and let $\mathcal{B}$ be a unital $C^*$-subalgebra of $\mathcal{A}$. Then for any $b\in\mathcal{B}$, we have
    \begin{equation*}
        \sigma_\mathcal{B}(b)=\sigma_\mathcal{A}(b)
    \end{equation*}
    Note that we are not requiring commutativity for $\mathcal{A}$ or $\mathcal{B}$.
\end{theorem}
\begin{proof}
    Note that we already have $\sigma_\alga(b)\subset\sigma_\algb(b)$ (an element not invertible in $\algb$ may be invertible in $\alga$). Then to show the other inclusion.
    We will first assume that $b^*=b$. If $b$ has an inverse in $\alga$, then it has a inverse in $\algb$. So suppose $c$ is an inverse in $\alga$ for $b$, then 
    \begin{equation*}
        cb=1_\alga=bc
    \end{equation*}
    Now it suffices to consider $(b-\lambda 1)^{-1}$. Assume $b$ is not invertible in $\algb$
    Consider the $C^*$ algebra generated by $b, 1$, then $C^*(b, 1):=\algb_1\subset\algb$. If $b$ is not invertible in $\algb$, then $b$ is not invertible in $\algb_1$, hence $\widehat{b}$ has no inverse in $C(\sigma_\algb(\mathcal{H}))$: which has a criterion that it takes nonzero elements to 0.

    Thus $\widehat{b}$ takes value 0 at some $\lambda\in\sigma_\algb(b)$, and note that $\widehat{b}$ is continuous, there is an open neighborhood of $\lambda_0$ such that
    \begin{equation*}
        |\widehat{b}(\lambda)|\leq\frac{1}{2\|c\|}
    \end{equation*}
    So by Urysohn's lemma, there is a $g\in C(\sigma(b))$ such that $supp(g)\subset O$, and $g=0$ outside of $O$, with $\|g\|_\infty=1$. 

    Then for $d:=g(b)$, so for the Gelfand transform,
    \begin{equation*}
        \widehat{g(b)}=g
    \end{equation*}
    we have $\|\widehat{b}g\|_\infty\leq\frac{1}{2\|c\|}$, then
    \begin{equation*}
        \|db\|\leq\frac{1}{\|c\|}
    \end{equation*}
    then
    \begin{equation*}
        1=\|g\|_\infty=\|d\|=\|(cb)d\|\leq\|c\|\|bd\|\leq\|c\|\frac{1}{2\|c\|}=\frac{1}{2}
    \end{equation*}
    Hence we've reached a contradiction. Hence the self-adjoint case is done. 
\end{proof}
\qed


\section{Lecture 13}
Let $\mathcal{A}$ be a unital $C^*$-algebra, and $\mathcal{B}$ be a unital $C^*$-subalgebra (implying the same unit), and in previous lecture, we saw if $b\in\mathcal{B}$, and $b^*=b$, and if $b$ has an inverse in $\mathcal{A}$, then it has an inverse in $\mathcal{B}$. 
This implies that
\begin{equation*}
    \sigma_\mathcal{B}(b)=\sigma_\mathcal{A}(b)
\end{equation*}



\begin{proposition}
    Let $\mathcal{A}$ be a $C^*$-algebra, and $\mathcal{B}$ subalgebra, if $b$ is invertible in $\mathcal{A}$, then $b$ is invertible in $\mathcal{B}$.
\end{proposition}
\begin{proof}
    We already know that this holds for $b^*=b$. For general $b\in\mathcal{B}$, (we no longer require $b^*=b$), then if $b$ has an inverse in $\mathcal{A}$, then so does $b^*$, then $b^*b$ has an inverse in $\mathcal{A}$, hence $b^*b$ has an inverse in $\mathcal{B}$. Hence $b$ has a left inverse $a(b^*b)=(b^*b)a=1$, and $bb^*$ is also invertible in $\mathcal{A}$, hence invertible in $\mathcal{B}$, hence $b$ has a right inverse.
\end{proof}
\qed

if we look at the shift operators on $l^2(\N)$, 
\begin{equation}
    Se_n=e_{n+1}
\end{equation}
Then the adjoint of this would be
\begin{equation*}
    S^*(e_n)=\begin{cases}
        e_{n-1}, n\geq 2\\
        0, n=1
    \end{cases}
\end{equation*}

Then we have
\begin{equation*}
    S^*S=I_\mathcal{H}, SS^*=I-P_{e_1}
\end{equation*}
where $P_{e_1}$ is the projection onto $e_1$.

Let $\mathcal{A}=l^1(\N_{\geq 0})$, and let $\mathcal{D}=\{z\in\C: |z|\leq 1\}$.
\begin{theorem}
    If $f\in l^1(\N)$, and if $\hat{f}\in C(D)$, then nowhere takes value 0, then $\hat{f}$ is invertible as a function in $C(D)$, and $\hat{f}$ has absolutely convergence power series, then $\frac{1}{\hat{f}}$ also has an absolutely convergence power series.
\end{theorem}
\begin{note}
    If we take $\mathcal{A}=l^1(\Z)$, so $\widehat{\mathcal{A}}=\T$, and if $\hat{f}$, which is the Fourier series, nowhere takes value 0 on $\T$, then the function $\frac{1}{\hat{f}}$ has absolutely convergent Fourier series. (This is much harder to prove).
\end{note}

Let $G$ be a group and let $(\mathcal{H}, U)$ be a unitary representation of $G$ on $\mathcal{H}$, and let $U: G\to U(\mathcal{H})$, and $l^1(G)$ with convolution, for $f\in l^1(G)$, and for 
\begin{equation*}
    U_f=\sum f(x)U_x\in\mathcal{B}(\mathcal{H})
\end{equation*}
with $\|U_f\|\leq\|f\|_{L^1}$. We then define
\begin{equation*}
    f^*(x):=\overline{f(x^{-1})}, U_f^*=(U^*)_f
\end{equation*}

We take $G=SL(n, \Z)$, the $n\times n$ matrices with $\det(T)=1, T\in SL(n,\Z)$. 

\begin{problem}
    What are the unitary representations of $G$ on $l^1(G)$
\end{problem}
$G$ acts on $G$ by left translations $\alpha$ (actions), and acts on $G/H$ (sets of cosets) for $H$ any subgroups. Note that $G/H$ are often called homogenous spaces. If $G$ acts on a set $M$, consider $l^p(M)$, then $G$ acts on isometries on $l^p(M)$, by
\begin{equation*}
    (\alpha)x\xi(y)=\xi(\alpha_x^{-1(y)})
\end{equation*}
\begin{equation*}
    X\rightarrow Y, C(X)\leftarrow C(Y)
\end{equation*}
In particular, this action on $l^2(M)$ is unitary.

\begin{definition}[Left regular representation]
    The representaiton $U$ of $G$ on $l^1(G)$ is called the left regular representation of $G$ if we define, for $x,y\in G$, $\xi\in l^2(G)$, we have
    \begin{equation*}
        (U_x\xi)(y)=\xi(x^{-1}y)
    \end{equation*}
\end{definition}

We now, naturally define the integrated form of the representation of $G$ on $l^1(G)$:
\begin{definition}[integrated form of a representation]
    We define $U_f\in End(l^1(G))$, we define $U_f$ naturally as follows: let $\xi\in l^1(G)$, and 
    \begin{equation*}
        U_f(\xi)=\sum_{g\in G}f(g)U_x(\xi)
    \end{equation*}
    i.e. $U_f=\sum_{x\in G}f(x)U_x$, where $U_x\in End(V)$ by
    \begin{equation*}
        x\xrightarrow{U}U_x
    \end{equation*}
    where $U$ is the map $: G\to End(l^1(G))$.
\end{definition}

\begin{definition}[Reduced $C^*$-algebra]
    The operator norm closure of $\{U_f: f\in l^1(G)\}\in \mathcal{B}(l^1(G))$ is called the reduced $C^*$-algebra of $G$, denoted as $C_r^*(G)$.
\end{definition}
\begin{note}
    Again, the defining property of a $C^*$-algebra is $\|a^*a\|=\|a\|^2$
\end{note}
In 1975, we see that $C_r^*(F_2)$ is simple, and has no proper ideals, note $F_2$ can be thought of the group generated by $a,b, a^{-1}, b^{-1}$ with unit. Note that the trivial representation is not continuous for $\| \|_{C_r^*}$.

\begin{definition}[amenable groups]
    $G$ is amenable if the integrated form of trivial representation if continuous for $\|\|_{C_r^*}$.
\end{definition}
\begin{remark}
    This implies that the integrated form of all unitary representations of $G$ are continuous for $\| \|_{C_r^*(G)}$. There are many equivalent properies of amenable using the geometric properties of $G$.
\end{remark}
\begin{note}
    All commutative groups are amenable.
\end{note}

\begin{definition}[Non-degenerate representation]
    Let $\pi$ be a representation of $\mathcal{A}$ on $V$, $\pi:\ala\to V$, then $\pi$ is non-degenerate if
    \begin{equation*}
        \text{ the linear span of }\{\pi(a)v: a\in\ala, v\in V\} \text{ is dense in } V
    \end{equation*}
\end{definition}
\begin{definition}[faithful representations]
    (In short, it's a representation that is injective.) The left representation is faithful if whenever $U_f=0$, then we have
    \begin{equation*}
        f=0, f\in l^1(G)
    \end{equation*}
\end{definition}
\begin{proof}
    $l^1(G)$, with convolution, with identity $\delta_e$. note that $\delta_e\in l^2(G)$. If we consider $\delta_e\in l^2(G)$, and we look at 
    \begin{equation*}
        U_f\delta_e=f\in l^2(G)
    \end{equation*}
    Because we have the embedding $l^1\subset l^2$. 
\end{proof}

Now assume that $G$ is commutative, then we consider $l^1(G)$ acts on $l^2(G)$, and 
\begin{equation*}
    C_r^*(G)=C^*(G)=C(\widehat{G})
\end{equation*}
note that we still have $\|f\|_{C_r^*(G)}\leq\|f\|_{L^1}$.

\section{Lecture 13}
Let $G$ be commutative, and $(l^2(G), U)$ be the left regular representation. We have the interal form $U_f, hf\in l^1(G)$, and 
\begin{equation*}
    U: l^1(G)\to \mathcal{B}(l^2(G))
\end{equation*}
and we let
\begin{equation*}
    C_r^*(G)=\{U_f: f\in l^1(G)\}^{\overline{\phantom{.}}}
\end{equation*}
where we take the closure with respect to the operator norm.

For $G$ commutative, we have $C_r^*(G)$ is a commutative $C^*$-algebra hence
\begin{equation*}
    \mathcal{A}:=C_r^*(G)\cong C(\widehat{\mathcal{A}})
\end{equation*}

We've shown last time, that $U$ is injective from $l^1(G)$ to $C_r^*(G)$. Each $\varphi\in\widehat{\mathcal{A}}$ a multiplicative linear functional, we have
\begin{equation*}
    f\mapsto \varphi(\pi_f)\in(l^1(G))^{\widehat{\phantom{.}}}
\end{equation*}

For any $f\in l^1(G)$, and $f\neq 0$, we have $U_f=0$, and the map is injective, hence $\pi_f=0$, we have, there exists $\varphi$ such that $\varphi(\pi_f)\neq 0$.

\begin{corollary}[largeness of the dual group]
    $\widehat{G}$ is big enough given that $f,g\in l^1(G)$, if $f\neq g$, then there exists $\varphi\in\widehat{G}$ succh that 
    \begin{equation*}
        \widehat{f}(\varphi)\neq\widehat{g}(\varphi)
    \end{equation*}
    In other words $\varphi(f)\neq\varphi(g)$.
\end{corollary}

We now state the big Galfand-Naimark theorem.
\begin{theorem}[Big Gelfand-Naimark]
    Let $\mathcal{A}$ be an abstract $C^*$-algebra, e.g. a Banach *-algebra such that 
    \begin{equation*}
        \|a^*a\|=\|a\|^2, \forall a\in\mathcal{A}
    \end{equation*}
    Then there exists a *-representation $\pi$ of $\mathcal{A}$ on a Hilbert space $\mathcal{H}$ which is isometric, i.e.
    \begin{equation*}
        \|\pi(a)\|=\|a\|
    \end{equation*}
    And
    \begin{equation*}
        \mathcal{A}\cong \{\pi(a): a\in\mathcal{A}\}
    \end{equation*}
\end{theorem}
\begin{note}
    In Little Galfand-Naimark, $C(\widehat{\mathcal{A}})$ is explicitly determined, but for big, it is not determined.
\end{note}

For $X$ a compact space, $C(X)$ is a $C^*$-algebra.

Consider $X_d$, which is discrete, and take $l^1(X_d)$ with the counting measure, is called the atomic representation.

Take any Borel measure $\mu$ on $X$, we have
\begin{equation*}
    L^2(X,\mu)
\end{equation*}
If $\mu$ has full support, then map of $C(X)$ is isometric.

\textbf{Now to introduce positive linear functionals on $\mathcal{A}$.}
Let $\mathcal{A}$ be a *-algebra, and $\pi:\mathcal{A}\to\mathcal{B}(\mathcal{H})$ a *-representation. Let's take any $\xi\in\mathcal{H}$, and $\xi\neq 0$, define
\begin{equation*}
    \varphi_\xi(\mathcal{A})=\langle \pi(a)\xi, \xi\rangle 
\end{equation*}

then we look at 
\begin{equation*}
    \varphi(a^*a)=\langle\pi(a^*a)\xi, \xi\rangle=\langle \pi(a)\xi, \pi(a)\xi\rangle\geq 0
\end{equation*}
\begin{note}
    For $f\in C(X)$, we always have $f^*f\geq 0$.
\end{note}
\begin{definition}[Positive linear functionals]
    If $\varphi$ is a linear functional on $C(X)$, such that for all $f$,
    \begin{equation*}
        \varphi(f^*f)\geq 0
    \end{equation*}
\end{definition}
\begin{remark}
    They are always continuous. And they give rise to a measure $\mu_\varphi$ on $X$.
\end{remark}
You think of $a^*a$ as being ``positive.''

\begin{proposition}
    If $\mathcal{A}$ is a $C^*$-algebra, if $a,b\in\mathcal{A}$, there exists $c$ such that
    \begin{equation*}
        a^*a+b^*b=c^*c
    \end{equation*}
\end{proposition}

\begin{definition}[positive linear functionals]
    It $\mathcal{A}$ is a *-algebra, and if $\varphi$ is a linear functional on $\mathcal{A}$, if for all $a\in\mathcal{A}$, we have
    \begin{equation*}
        \varphi(a^*a)\geq 0
    \end{equation*}
    then we call $\varphi$ \textbf{positive}.
\end{definition}
\begin{proposition}
    If $\varphi, \psi$ are positive, then $r\varphi+s\psi$, with $r,s\in\R^+$, then the positive linear functionals form a \textbf{cone}.
\end{proposition}

Let $\mathcal{A}$ be a *-algebra, and let $\varphi$ be a positive linear functional on $\mathcal{A}$, then define a pre-inner product on $\mathcal{A}$ by
\begin{equation*}
    \langle a, b\rangle_\varphi=\varphi(b^*a)
\end{equation*}

Then we have
\begin{equation*}
    \langle a, a\rangle_\varphi=\varphi(a^*a)\geq 0
\end{equation*}

\begin{proposition}
    For $\la a,b\ra_\varphi=\varphi(b^*a)$ defines a pre-inner product on $\mathcal{A}$. (A pre-inner product does not require $\la \xi, \xi\ra=0$ implies $\xi=0$.)
\end{proposition}
\begin{proof}
    We have $\overline{\langle a,b\rangle_\varphi}=\langle b, a\rangle_\varphi$.
\end{proof}
\subsection{GNS construction}
Now for a positive linear functional, we attempt to associate a cyclic representation with it: we will define a pair $(\pi, \mathcal{H})$ such that it satisfies:
\begin{equation*}
    \varphi(a)=\la \pi(a)\xi, \xi\ra
\end{equation*}

Let $\eta_\varphi=\{a\in\mathcal{A}: \langle a, a\rangle_\varphi=0\} $, then if $b\in\mathcal{A}, a\in\eta_\varphi$, then we have
\begin{equation*}
    |\langle ba, ba\rangle|=|\langle b^*ba, a\rangle|\leq \langle a, a\rangle^{1/2}=0
\end{equation*}
So we get that $\eta_\varphi$ is an ideal of $\mathcal{A}$, so form $\mathcal{A}/\eta_\varphi$, then
\begin{equation*}
    \langle, \rangle_\varphi
\end{equation*}
drops to an inner product on $\mathcal{A}/\eta_\varphi$, denote its complement by $L^2(a,\varphi)$, if we are given $c\in\mathcal{A}$, let $\pi$ be the left regular representation of $\mathcal{A}$ on $\mathcal{A}$ via
\begin{equation*}
    \pi_ca=ca
\end{equation*}
then we have
\begin{equation*}
    \langle \pi_ca, b\rangle_\varphi=\langle ca, b\rangle=\varphi(b^*ca)=\varphi((c^*b)^*a)=\langle a, c^*b\rangle=\langle a, \pi(c^*)b\rangle
\end{equation*}
Then the left regular representation ``is'' a *-representation on $\mathcal{A}$, this drops to a *-representation on $\mathcal{A}/\eta_\varphi$.

Next time: we show $\pi_c$ is not continuous, and we will use polynomials. Now if you assume $\mathcal{A}$ is Banach *-algebra, then this $\pi_c$ are always bounded.
\textbf{GNS representation}, where $S$ is Siegel. 

\section{Lecture 15}
Recall the GNS construction. Given a *-normed unital algebra $\mathcal{A}$, and a positive linear functional $\mu$ on $\mathcal{A}$, we mean
\begin{equation*}
    \mu(a^*a)\geq 0, \forall a\in\mathcal{A}
\end{equation*}

Now we define a pre-innner product on $\mathcal{A}$ by
\begin{equation*}
    \langle a,b\rangle_\mu=\mu(b^*a)
\end{equation*}
And one could check this is indeed a pre-inner product.
\begin{enumerate}
    \item $\overline{\langle a,b\rangle_\mu}=\langle b,a\rangle_\mu$
    \item $\langle a+b, a+b\rangle_\mu\geq 0$
\end{enumerate}
If we let $\eta_\mu=\{a\in\mathcal{A}:\langle a,a\rangle=0\}$, then by Cauchy-Schwarz inequality, we would show that $\eta_\mu$ is a left ideal. Form $\mathcal{A}/\eta_\mu$, then $\langle, \rangle$ becomes an inner product on $\mathcal{A}/\eta_\mu$.

One could complete $\mathcal{A}/\eta_\mu$ to get a Hilbert space $L^2(\mathcal{A},\mu)$. Then we have
\begin{equation*}
    \langle f,g\rangle=\int f\overline{g}d\mu
\end{equation*}

\begin{definition}[left regular representation]
    For $c\in\mathcal{A}$ , define the left regular representation $\pi$ on $\mathcal{A}$ and on $\mathcal{A}/\eta_\mu$ via
    \begin{equation*}
        \pi_ca=ca, a\in\mathcal{A}
    \end{equation*}
    Then we have
    \begin{equation*}
        \langle \pi_ca,b\rangle_\mu=\langle ca, b\rangle_\mu=\langle a, \pi_c^*b\rangle
    \end{equation*}
    Hence $\pi$ is a *-representation.
\end{definition}

Now let $P$ be the algebra of polynomials with complex coefficients, viewed as functions on $\R$. Define $\mu$ on $P$ as follow:
\begin{equation*}
    \mu(p)=\int_{-\infty}^\infty p(t)e^{-t^2}dt
\end{equation*}
Then our $\mu$ is a positive linear functional. Then we identify this as $L^2(\R, e^{-t^2}dt)$.

\begin{proposition}
    Let $\mathcal{A},\mu$, assume $\mathcal{A}$ is complete, let 1 denote the unit of the algebra. And $\mu$ is continuous with $\|\mu\|=\mu(1)$.
\end{proposition}
\begin{remark}
    By completeness, you immediately get continuity in some cases.
\end{remark}
\begin{proof}
    Now we introduce the main lemma.
\end{proof}
\textcolor{red}{unfinished}

\section{Lecture 16}
We now discuss classical physics and quantum physics.

All possible ``states'' for the system. Then you have observables. 
$\R$-valued for the phase space $P$. 


If the configuration space is $\R$, the velocities are given as $\R$ numbers, then the phase space is the cartesian product $\R\times\R$, and the Poisson bracket is given by
\begin{equation*}
    \{f,g\}=\left(\frac{\partial f}{\partial x}\frac{\partial g}{\partial y}-\frac{\partial f}{\partial y}-\frac{\partial g}{\partial x}\right)(p)
\end{equation*}

In quantum physics, there is no configuration space that we work with. The phase space becomes a $C^*$-algebra, usually non-commutative. And the observables are the self-adjoint elements of $\mathcal{A}$, where $\mathcal{A}=\mathcal{B}(\mathcal{H})$, and such choice of Hilbert space is not unique. Possibles values for an observalbe $a=a^*$ form $\sigma(a)$.

When you observe a system in a certain state, and you measure and observable $a$ several times, you can get different values (all in $\sigma(a))$.

For the system in a given state, there is a porobablity measure on $\sigma(a)$ that gives you the probability of getting a particular value of $a$. As the system evolves, this probably changes.

The \textbf{state} (this is why we call them states, i.e. the set of linear transformations that have norm 1) space is the set of all positive linear transformations on $\mathcal{A}$ of norm 1, $\mu$, then for any observable $a$, form 
\begin{equation*}
    C^*(a,1)\cong C(\sigma(a))
\end{equation*}
Then the restriction  of $\mu$ to $C^*(a,1)$ give syou a probability measure on $\sigma(a)$.

Experiments show that for certain pairs of observables $a,b$, it is impossible to measure both simultaneously at high accuracy.

The way this is modeled is that it happens exactly if $ab\neq ba$, i.e. non-commutativity makes us impossible to measure them simultaneously.

\begin{definition}[Poisson bracket]
    For $a,b$ observables such that they are noncommutative, we define the Poisson bracket as follows:
    \begin{equation*}
        i[a,b]=ab-ba
    \end{equation*}
\end{definition}

For the evolution of a quantum system given by $\R\mapsto Aut(\mathcal{A})$, and $t\mapsto \alpha_t$, and states evolve by $\mu\mapsto \mu\circ\alpha_t$.

If we let this Planck's constant $h$ go to 0, then we have
\begin{equation*}
    ih[a,b]\to \text{ Poisson bracket }
\end{equation*}
i.e. getting back from quantum back to the classical system.

Let $\mathcal{A}$ be a *-normed unital algebra, and $\mu$ is a continuous positive linear functional, then
$L^2(\mathcal{A}, \mu)$ and $\pi^\mathcal{H}: \mathcal{A}\to \mathcal{B}(L^2(\mathcal{A}, \mu))$. 

Let $\xi_\mu=1_\mathcal{A}$, viewed as an element of $L^2(\mathcal{A}, \mu)$, and 
\begin{equation*}
    \{ \pi_\mu(a)\xi_\mu: a\in\mathcal{A}\}=\mathcal{A}/\pi_\mu
\end{equation*}
viewed in $L^2(\mathcal{A}, \mu)$ is dense in $L^2(\mathcal{A}, \mu)$.

\begin{definition}
    If we have $\mathcal{A}$ some representation $(\mathcal{H}, \pi)$, and a vector $\xi\in\mathcal{H}$ is said to be a cyclic vector of $
    \{\pi_\mu\xi: a\in\mathcal{A}\}$ is dense in $\mathcal{H}$.
\end{definition}

\section{Lecture 17}
If you look at $\mathcal{A}$ a *-normed unital algebra, and $\mu$ a continuous linear functional, and the GHS representation: $(\mathcal{H}_\mu, \pi_\mu, \xi_\mu)$, where $\overline{\mathcal{A}/\eta_\mu}$, where $\xi_\mu$ is the unital element $1_\mathcal{A}$ in the Hilbert space.

Given any *-representation of $\mathcal{A}$ on $K$, and any vector $\xi\in K$, let 
\begin{equation*}
    \mu_\xi(a)=\langle \pi(a)\xi, \xi\rangle
\end{equation*} 
Now we ask what positive linear functional comes from the cyclic vector $\xi_\mu$, and we look at 
\begin{equation*}
    \langle \pi_mu(a)\xi_\mu, \xi_\mu\rangle_\mu
\end{equation*}
where it is essentially
\begin{equation*}
    \langle a1_\mathcal{A}, 1\rangle=\mu(a)
\end{equation*}

Every state is a vector state, for some representation, namely, the GNS representation.

Consider the set $\{\pi(a): a\in\mathcal{A}\}$, or for a unitary representation $U$ of a group $G$, consider the set
\begin{equation*}
    \{U_x: x\in G\}
\end{equation*}
More importantly, given a Hilbert space $\mathcal{H}$, let $S$ be a subset of the bounded operators on $\mathcal{H}$, $\mathcal{B}(\mathcal{H})$ such that if $a\in S$, then $a^*\in S$, and $I_H\in S$.

\begin{definition}
    A subspace $K\subset H$ is said to be $S$-invariant (where $S\subset\mathcal{B}(\mathcal{H}))$, if whenever $\xi\in K$, and $a\in S$, and $a\xi\in K$. You could write $aK\subset K$.
\end{definition}

\begin{proposition}
    If $K$ is $S$-invariant, then so is $K^\perp$.
\end{proposition}
\begin{proof}
    Let $\xi\in K^\perp, a\in S$, want to show that $a\xi\in K^\perp$.

    Let $\eta\in K$, then $\langle a\xi, \eta\rangle=\langle \xi, a^*\eta\rangle =0$. This is true for all $\eta$, hence $a\xi\in K^\perp$.
\end{proof}
\qed

Let $\mathcal{A}$ be *-normed unital algebra, and let $(\mathcal{H}, \pi)$ be a *-representation of $\mathcal{A}$ on $\mathcal{H}$. Choose $\xi\in\mathcal{H}$, and let 
\begin{equation*}
    K_\xi=\overline{\{\pi(a)\xi: a\in\mathcal{A}\}}\subset\mathcal{H}
\end{equation*}

This is a $\{\pi(a): a\in\mathcal{A}\}$-invariant subspace. If we look at $K_\xi^\perp$, this is also $\{\pi(a):a\in\mathcal{A}\}$-invariant. 

\begin{definition}
    If $(\mathcal{H}, \pi)$ a representation of $\mathcal{A}$, and $H$ contains no proper nonempty $\pi$-invariant closed subspaces, we say then $(\mathcal{H}, \pi)$ is irreducible. (This gives the name ``simple module.'')
\end{definition}

If $K_\xi^\perp$ is not the zero subspace, then you can choose $\xi_1\in K_\xi^\perp, \xi_1\neq 0$.

Set $K_{\xi_1}$ to be the cyclic subspace generated by $\xi_1$, and $\pi$-invariant, if $K_{\xi_1}^\perp$ is $\pi$-invariant. And if it's not the zero subspace, then you could repeat this process.

If $\mathcal{H}$ is finite-dimensional, then can what we said above to get 
\begin{equation*}
    \mathcal{H}=K_1\bigoplus K_2\bigoplus... \bigoplus K_n
\end{equation*}
And for each $K_j$, we have $\pi$ on these is irreducible. You could decompose any $\mathcal{H}$ into a direct sum of irreducible representations. 

What happens when the space is infinite-dimensional? Group $G$ has a representation on $l^2(G)$. Given any $(\mathcal{H}, \pi)$ with $\mathcal{H}$ infinite-dimensional, you can apply the above process, and may not get any irreducible representations, but you could keep getting \textbf{cyclic representations}.

For any Hilbert space, pick unit vector, look at orthogonal subspace, pick a unit vector in that, etc... What happens when you keep on going. Note that \textbf{ when you keep going, you use Zorn's lemma}.

Via Zorn's lemma, you get the following.
\begin{proposition}
    Every representation is a possibly infinite direct sum of cyclic representations.
\end{proposition} 
We need to define infinite sum of representations.

Let $\{\mathcal{H}_\lambda\}_{\lambda\in\Lambda}$ be a collection of Hilbert spaces. Set the direct sum of these Hilbert spaces $\bigoplus\mathcal{H}$, and functions on these to be $\xi:\Lambda\to \cup \mathcal{H}_\lambda: \xi(\lambda)\in\mathcal{H}_\lambda$ for all $\lambda$ and $\sum_{\lambda\in\Lambda}\|\xi_\lambda\|^2<\infty$, hence we have $\xi_\lambda=0$ except for a finite number of $\lambda$'s.

And define $\langle \xi, \eta\rangle=\sum_{\lambda\in\Lambda}\langle \xi_\lambda, \eta_\lambda\rangle$, such that the sum $\sum\|\xi_n\|^2<\infty$, and $\langle \xi, \eta\rangle=\sum\xi_\lambda\overline{\eta}_\lambda$.

You know how to show $\mathcal{H}$ is complete under $\langle \xi, \eta\rangle=\sum\xi_\lambda\overline{\eta}_\lambda$, then you know how to show $\bigoplus\mathcal{H}_\lambda$ is complete under $\langle \xi, \eta\rangle=\sum_{\lambda\in\Lambda}\langle \xi_\lambda, \eta_\lambda\rangle$.

If $\{T_\lambda: T_\lambda\in\mathcal{B}(\mathcal{H}_\lambda)\}$, and $\bigoplus_{\lambda\in\Lambda}T_\lambda$, and if we define
\begin{equation*}
    (\bigoplus T_\lambda)(\xi):=\{T_\lambda\xi_\lambda\}_{\lambda\in\Lambda}
\end{equation*}
and we would like to put these in $\bigoplus\mathcal{H}_\lambda$, there is a constant $c$ such that $\|T_\lambda\|\leq c$ for all $\lambda$, i.e. ${T_\lambda}$ is bounded in norm.

Hence
\begin{equation*}
    \|T_\lambda\xi_\lambda\|\leq\|T_\lambda\|\cdot\|\xi_\lambda\|\leq c\|\xi_\lambda\|
\end{equation*}

If $\mathcal{A}$ is a *-normed unital algebra, and $(\mathcal{H}_\lambda, \pi_\lambda)$ is a collection of *-representation of $\mathcal{A}$, continuous, then for $\bigoplus_{\lambda\in\Lambda}\mathcal{H}_\lambda$, and for $a\in\mathcal{A}$, set
\begin{equation*}
    \bigoplus(\pi_\lambda)(a)\xi=\{\pi_\lambda(a)\xi_\lambda: \|\pi_\lambda(a)\|\leq\|a\|\}
\end{equation*}
and $\{\xi_\lambda\}\in\bigoplus_\lambda \mathcal{H}_\lambda$.

By Zorn's lemma, every Hilbert space is a direct sum of cyclic representations.

Next: spectral theorem for self-adjoint operators.

\section{Lecture 18}
\begin{definition}[Equivalent representations]
    Let $\mathcal{A}$ be a (group) a *-algebra, and let $(\mathcal{H}, \pi)$, and $(K, \rho)$ are two *-representations of $\mathcal{A}$, then these representations are equivalent, if there is a unitary operator $U: H\to K$, $(U^{-1}: K\to H)$, such that
    \begin{equation*}
        U\pi(a)=\rho(a)U
    \end{equation*}
    $U$ is the representation that equivalates $\pi$ and $\rho$. ``U intertwines $\pi$ and $\rho$''
\end{definition}

\begin{proposition}
    Let $\mathcal{A}$ be a unital *-normed algebra, and let $(\mathcal{H}, \pi, \xi)$ and $(K, \rho, \eta)$, where $\xi, \eta$ are cyclic vectors, and they each determine a positive linear functional on $\mathcal{A}$. 

    Let $\mu_\xi$, and $\mu_\eta$ be the correspondonig positive linear functionals, and if $\mu_\xi=\mu_\eta$, then $(\mathcal{H}, \pi)$ and $(K, \rho)$ are unitarily equiavalent via a unitary operator such that $U\xi=\eta$.
\end{proposition}
\begin{comment}
    If your representation is non-irreducible, then every nonzero vector is a cyclic vector.
\end{comment}
\begin{proof}
    Since we want that $U\xi=\eta$, then we want 
    \begin{equation*}
        U(\pi(a)\xi)=U\pi(a)(\xi)=\rho(a)U\xi=\rho(a)\eta
    \end{equation*}
    Start by try and define $U$ by 
    \begin{equation*}
        U(\pi(a)\xi)=\rho(a)\xi
    \end{equation*}
    However, this raises the question, is this well-defined? If $\pi(a)\xi=\pi(b)\xi$, for some $a,b$, then do we have $\rho(a)\eta=\rho(b)\eta$? (This would imply $U$ is well-defined).

    \begin{remark}
        In linear situations like this, if $\pi(a-b)\xi=0$, is it true that $\rho(a-b)\eta=0$?
    \end{remark}
    In other words, \textbf{it suffices to show that } if $\pi(\xi)=0$,  we have $\rho(c)=0?$.
    \begin{equation*}
        \|\rho(c)\eta\|^2=\langle \rho(c)\eta, \rho(c)\eta\rangle=\langle \rho(c^*c)\eta, \eta\rangle=\mu_\eta(c^*c)=\mu_\xi(c^*c)=\langle \pi(c)\xi, \pi(c)\xi\rangle =0
    \end{equation*}
    We note that
    \begin{equation*}
        \|\rho(c)\eta\|^2=\|\pi(c)\xi\|^2
    \end{equation*}
    The operator preserves norm on a dense subspace, we further have $U$ is unitary.

    We now see that $U$ intertwines $\pi, \rho$, we have
    \begin{equation*}
        U\pi(a)(\pi(c)\xi)=U\pi(ac)\xi=\rho(ac)\eta=\rho(a)\rho(c)\eta=\rho(a)U(\pi(c)\xi)
    \end{equation*}
    From this we see
    \begin{equation*}
        U\pi(a)=\rho(a)U
    \end{equation*}
\end{proof}
\qed

\begin{comment}
    You start with $\mu_\xi$, and do GNS, and get something unitarily equivalent to what you start with.
\end{comment}
\begin{corollary}
    There is a bijection between the positive linear functionals on $\mathcal{A}$, and the pointed cyclic representations on $\mathcal{A}$. 
\end{corollary}

Let $\mathcal{A}$ be a commutative unital *-normed algebra and let $(\mathcal{H}, \mu)$ be a cyclic *-representation with cyclic vector $\xi$. Then let $\mathcal{B}=\overline{\pi(a)}$ be the norm closure is a $C^*$-algebra. So $\mathcal{B}=C(X)$.

Then $\mu_\xi$ is a positive linear functional on $\mathcal{B}=C(X)$. Hence $\mu_\xi$ gives a finite regular Borel measure on $X$, $\tilde{\mu}_\xi$, so you can form the $L^2(X,\tilde{\mu}_\xi)$ with $\mathcal{B}$ acting on $L^2(X, \tilde{\mu}_\xi)$ by pointwise multiplication. \textbf{ This is basically the GNS representation.} Then you have the cyclic vector as the constant function 1. And find that $\mu_1=\mu_\xi$, so
\begin{equation*}
    (\mathcal{H}, \pi, \xi)\cong (L^2(X, \tilde{\mu}_\xi), 1)
\end{equation*}
via the unitary $U$ such that $U\xi=1$.

Given $C(X)$ and any *-representation of it, $(H, \pi)$ and you decompose $(\mathcal{H}, \pi)$ into direct sum of cyclic representations, $\bigoplus(H_\lambda, \pi_\lambda, \xi_\mu)$ where each $\xi_\mu$ is cyclic.

Each one $(H_\lambda, \pi_\lambda, \xi_\mu)$ is isomorphic to some $L^2(X,\mu_\lambda, \xi_\lambda)$, with $C(X)$ acts pointwise on each $L^2(X,\mu_\lambda, \xi_\lambda)$.
\begin{example}
Let $X=[0,1]$, and $L^2(X, m)$, where $m$ is the Lebesgue measure. And let 
\begin{equation*}
    \nu=\delta_\frac{1}{4}+\delta_\frac{1}{2}+\delta_\frac{1}{5}
\end{equation*}
All the measures above and mutually exclusive to $m$, and $L^2(X, m+\nu)$.
\end{example}

This gives the Borel functional calculus. For any bounded Borel function on $X$ (Borel functions are those that are measurable with respect to all possible Borel measures), it acts on each $L^2(X,\mu_\lambda)$ by pointwise multiplication, hence acts on $\mathcal{H}$. If you have a given Hilbert space $\mathcal{H}$, $T\in\mathcal{B}(\mathcal{H})$, and $T^*=T$, and
\begin{equation*}
    C^*(T, I_\mathcal{H})=C(\sigma(T))
\end{equation*}
so $C(\sigma(T))$ acts on $\mathcal{H}$, hence every Borel function acts on $\mathcal{H}$. 

Again we have $C(X)$ acting on $\mathcal{H}$ and the bounded Borel functions acting on $\mathcal{H}$, let $E$ be any Borel subset of $X$, so $\chi_E$ acts on $\mathcal{H}$ and is a projection. So we have $E\mapsto \chi_E\in\mathcal{B}(\mathcal{H})$ via $\nu$, and this is a projection-valued measure on $X$. 

If $E, F$ are disjoint, then
\begin{equation*}
    \chi_E\chi_F=\chi_{E\cap F}, \chi_{E\bigoplus F}=\chi_E+\chi_F
\end{equation*}
\begin{remark}
    This is somewhat countably additive in a weak sense.
\end{remark}

\section{Lecture 19}
Let $\mathcal{A}$ be a unital commutative $C^*$-subalgebra of $\mathcal{B}(\mathcal{H})$, and let $(\mathcal{H}, \pi, \xi)$ be a cyclic representation (note this is not unique at all, like choosing an orthonormal basis of $\mathcal{H}$). And $\mathcal{A}\cong C(X)$, and we've said
\begin{equation*}
    \mathcal{H}\cong\bigoplus_{\lambda\in\Lambda}L^2(X, \mu_\lambda)
\end{equation*}
If $f$ is a $\C$-valued bounded Borel function on $X$, where $X$ is a compact space, then $f$ determines an opeartor $T$ on each $L^2(X,\mu)$ by pointwise multiplication. with $\|T\|\leq\|f\|_\infty$. Then this gives a bounded operator on $\mathcal{H}$. Let $\mathcal{B}$ be the $C^*$-algebra of bounded Borel functions, then you get a representations of $\mathcal{B}$ on $\mathcal{H}$.

For each Borel subset $E$ of $X$, $\chi_E$ goes to a projection operator on $\mathcal{H}$.
\begin{definition}
    Let $\Sigma$ be a $\sigma$-algebra of subsets of a set $X$ (don't quite need a topology), and let $\mathcal{H}$ be a Hilbert space by a projection-valued measure on $\Sigma$, we mean an assignment 
    \begin{equation*}
        E\xrightarrow{\mu}\mu(E)
    \end{equation*}
    where $\mu(E)$ is a projection operator on $\Sigma$ that satisfies
    \begin{enumerate}
        \item $\mu(\emptyset)=0, \mu(X)=I_\mathcal{H}$ \text{ the identity operator}
        \item If $E, F\in\Sigma$, then $\mu(E\cap F)=\mu(E)\mu(F)$.
        \item If $\{E_j\}$ is a countable collection of disjoint elements in $\Sigma$, then $\mu(\bigoplus_j E_)=\sum_{j=1}^\infty\mu(E_j)$, for either the strong or the weak operator topology.
    \end{enumerate}
\end{definition}
\begin{note}
    Every here looks like a mesaure, and we have to be careful about how the sum is well-defined.
\end{note}

Let $X$ be a compact set, and $B(X)$ denote the set of Borel sets, let $E_j\subset B(X)$ be disjoint. These viewed in $L^2(X,\mu)$, we have
\begin{equation*}
    \sum_{j=1}^\infty\chi_{E_j}=\lim_{n\to\infty}\sum_{j=1}^n\chi_{E_j}=\lim_{j=1}^n\chi_{\bigoplus_jE_j}=\chi_{\bigoplus_{j=1}^\infty E_j}
\end{equation*}
And note as $j\to\infty$, this is an increasing function, this is not converging to the uniform form. But these do converge, for the $L^1$ or $L^2$ norm by Dominated Converge theorem.

If $\xi\in L^2(X,\mu)$, and we look at 
\begin{equation*}
    \chi_{\cup_1^\infty E_j}\xi\to \chi_{\cup_1^\infty}\xi \text{ for the }L^2-norm
\end{equation*}
If any $\eta\in L^2(X,\mu)$, 
\begin{equation*}
    \la \chi_{\cup_1^nE_j}\xi, \eta\ra=\int \chi_{\cup_1^\infty E_j}\xi\overline{\eta}\to \la \chi_{\cup_1^\infty E_j}\xi, \eta\ra
\end{equation*}
where the $L^2$ case follows from that $\xi\overline{\eta}\in L^2(X,\mu)$.

\begin{definition}
    The strong operator topology  on $\mathcal{B}(\mathcal{H})$ is the topology defined by the seminorms $T\to \|T\xi\|$ for all the ? $\xi\in\mathcal{H}$
    
    If $\{T_\lambda\}$ is a bounded net of operators on $\mathcal{B}(\mathcal{H})$, then it converges to $T$ in the strong operator norm if for all $\xi$, 
    \begin{equation*}
        \|T_\lambda\xi-T\xi\||\xrightarrow{\lambda} 0
    \end{equation*}
\end{definition}

Then the weak operator topology on $\mathcal{B}(\mathcal{H})$ is defined by the seminorms, for all $\xi, \eta$
\begin{equation*}
    T\mapsto |\la T\xi, \eta\ra
\end{equation*}
If $\{T_\lambda\}$ is a bounded net, then we say it converges to $T$ if
\begin{equation*}
    |\la T_\lambda\xi, \eta\ra-\la T\xi, \eta\ra|\to 0
\end{equation*}
\begin{remark}
    Strong operator topology implies the weak operator topology, not the reverse.
\end{remark}
\begin{remark}
    If you look at the group of unitary operators, then the strong and weak operator topologies are equivalent.
\end{remark}

Let $\mathcal{A}$ be a $C^*$-subalgebra of $\mathcal{B}(\mathcal{H})$, and $\mathcal{H}=\bigoplus(X, \mu_\lambda)$, and for $E\in Borel(X)$, $\chi_E$ actives on each one of $(X,\mu_\lambda)$, and 
\begin{equation*}
    E\mapsto \chi_E
\end{equation*}
acting on $\mathcal{H}$ is a projection-valued measure, and is called the spectral measure for action of $\mathcal{A}$ on $\mathcal{H}$.

For $T\in\mathcal{B}(\mathcal{H})$, $T^*=T$, we denote $C^*(T,I)=\mathcal{A}$, and $\widehat{\mathcal{A}}=\sigma(\mathcal{A})$, then $C(\widehat{A})=\mathcal{A}$. So far each $E\in Borel(\sigma(T))$, you get an operator.

Let $P_r$ be the projection $\chi_{(-\infty, r)}$, and for $r>\|T\|$, we have $P_r=I_\mathcal{H}$. These are called the ``resolution of the identity'' for $T$.

You could make sense of the operator $T$ as follows:
\begin{equation*}
    T=\int_{-\infty}^\infty tdP_t
\end{equation*}

Let $G$ be a locally compact group. And the product is jointly continuous $G\times G\to G, (x,y)\to xy$, and taking inverses is also continuous.

\begin{example}
    $\R, \R^n, \T, \T^n, GL(n,\R)$
\end{example}
We know need is a projection measure on $G$ that is invariant for left translations. 


\section{Lecture 20}
We will discuss the Haar measure today.

Let $G$ be a group, and $M$ a topological space, and action of $G$ on $M$ is:
\begin{equation*}
    \alpha: G\to Hom(G)
\end{equation*}
And if $f$ is a $\C$-valued function on $M$, then the set 
\begin{equation*}
    \alpha_x(f)m):=f(L_x^{-1}(m))
\end{equation*}
So $\alpha: G\to Aut(Functions on M)$. 
If $M$ is locally compact, $f\in C_c(M)$. For example, $G=\R$.

Now let $G$ be a compact group, then $G$ acts on itself by left translations: $\lambda$:
\begin{equation*}
    \lambda_x(y)=xy
\end{equation*} 

We can get an action on functions:
\begin{equation*}
    \lambda_x(f)(y)=f(x^{-1}y)
\end{equation*}

We then talk about a measure on a group, which is also a topological space in a sense, and would like to assign finite measure on comapct sets. The goal is to construct such a measure that is translation invariant with respect to the left trasnlations.

\begin{definition}[Translation-invariant measures]
    For $M$ locally compact, a measure $\mu$ on $M$ is $\alpha$-invariant, if 
    \begin{equation*}
        \mu(\alpha_x(E))=\mu(E), \text{ for all } x\in G
    \end{equation*}
    where $E$ is a Borel subset of $M$.
\end{definition}
\begin{remark}
    On discrete groups, the counting measures are invariant under translations.
\end{remark}

In 1933, Haar proved that every locally compact, second countable group (i.e. a countable base for the topology) has a left-(translatioin)invariant (nonzero) Borel measure, which we call the Haar measure. This is unique up to positive scalar multiplicaton.
\begin{note}
    The Lebesgue measure in a Haar measure on the real numbers $\R$.
\end{note}

Weil: worked instead with positive linear functionals $\varphi$ on $C_c(G)$, and he proved that we always hav ea $\varphi$ that is left invariant, i.e.
\begin{equation*}
    \varphi(\lambda_xf)=\varphi(f), \forall x\in G
\end{equation*}

Sketch: choose $f_0\in C_c^+(G)$, so that $\varphi(f_0)=1$, and . 
For a small nbhd $O$ of the identity element $e$, choose a function $g_O=g$ supported in $O$, a smooth bump function.

Let $(f: g_O)=\inf\{\sum_{j=1}^nc_j, c_j>0: \text{ there exists } x_1, ..., x_j\in G \text{ with } f\leq \sum_jc_j(\lambda_{x_j}g) \}$, This expression here $f(:g_O)$ is left translation-invariant, now we consider
\begin{equation*}
    \frac{(f: g_O)}{(f_0: g_O)}
\end{equation*}
You show that this converges to a linear functional on $C_c(G)$, which necessarily gives rise to a linear functional that is left translation-invariant. 

If for $f\in C_c(G)$, define $\tilde{f}(x)=f(x^{-1})$, then the function
\begin{equation*}
    f\mapsto \varphi(\tilde{f})
\end{equation*}
is a right invariant positive linear functional on $C_c(G)$.

Sometimes $\varphi(f)=\int_Gf(x)dx$, given $x_0$, if we look at 
\begin{equation*}
    \int f(xx_0)dx=\int \rho_{x_0}(f)dx
\end{equation*}
This is also left-invariant, hence there exists $\delta(x_0)$ such that 
\begin{equation*}
    \int f(xx_0)dx=\Delta(x_0)\int f(x)dx
\end{equation*}
\begin{proposition}
    $\Delta: G\to\R^+$, a group under multiplication, is and a group homomorphism, and later we will show this is continuous. And this $\Delta$ is called the ``modular funtion'' of $G$.
\end{proposition}

\begin{definition}
    $G$ is said to be unimodular if $\delta\equiv 1$, i.e. the left Haar measure is right-invariant.
\end{definition}
\begin{example}
    The discrete group, commutative groups, compact groups, and nilpotent Lie groups, semi-simple lie groups.
\end{example}
But many are lie groups are not unimodular.

\begin{equation*}
    \int f(x^{-1})\Delta(x^{-1})dx=\int f(x)dx
\end{equation*}
Let $H$ be a closed subgroup of $G$, let $G/H$ be the corresponding homogenous space, and $G$ acts on $G/H$, we now ask if there is an invariant measure that satisfies $\Delta_H=\Delta_G\vert_H$. 

\begin{definition}
    For a topological group $G$, and an action which we call a representation $\pi: G\to Aut(V)$ of $G$ on a Banach space $V$.
\end{definition}
\begin{example}
    $\R$ acts on $L^2(\R)$ by translations $U_t$. One could ask if this is continuous, i.e. as $t\to 0$, do we get
    \begin{equation*}
        \|U_t\to U_0\|\to 0
    \end{equation*}
\end{example}
You could have a little bump around 0 as your $L^2$ function, and when you translate it, the supports are disjoint and hence the $L^2$ norm gets preserved.

But there eixsts a continuous one for the strong operator topology. (The rep via translation itself does not converge, but when you apply it to something, it is indeed convergent).
\begin{example}
    If $f\in C_c(X)$, and $\alpha$, if you have $\alpha_x(f)\to f$, and $x\to e$. 
\end{example}


\section{Lecture 21}
\begin{comment}
    If you have a $\sigma$-ring of subsets of a grou, and a measure on the $\sigma$-ring, if you have a translation invariant measure on the group, then you can give the group a topology, that is locally compact.
\end{comment}

Let $G$ be a locally compact group, and let $M$ be a locally compact space, and let $\alpha$ be an action of $G$ on $M$, and 
\begin{equation*}
    \alpha: G\to Hom(M)
\end{equation*}
This is with $\alpha$ jointly continuous, i.e. $G\times M$ equipped with the product topology, and the mapping $G\times M\to M$
\begin{equation*}
    (x, m)\mapsto \alpha_x(m)
\end{equation*}
is continuous.

One classic example is $G$ acting by left translation on $G$. 
\begin{theorem}
    The action of $G$ on $C_\infty(M)$ via
    \begin{equation*}
        \alpha_x(f)(m)=f(\alpha_x^{-1}m)
    \end{equation*}
    is strongly continuous, for the strong operator topology.
\end{theorem}

\begin{proposition}
    If $\alpha$ is an ction of a topology $G$, on a Banach space, by isometries, (i.e. each $\alpha_x$ is an isometry on the Banach space), and if there is a dense subspace $V_0\subset V$,(or the vectors whose span is a dense subspace) such that on $V_0$, this action is strongly continuous, i.e. for all $v\in V_0$, then function
    \begin{equation*}
        x\mapsto \alpha_x(v) \text{ is continuous }
    \end{equation*}
    Then $\alpha$ is strongly continuous on $V$.
\end{proposition}
\begin{proof}
    You do the standard approximation argument by $\frac{\epsilon}{3}$-argument.
\end{proof}

Now back to the theorem, it suffices to prove this for $C_c(M)$, since it is a dense subset of $C_\infty(M)$ with $\|\cdot\|_\infty$ norm. And it suffices to prove continuity at the identity element at $e_G$ (by uniformity).
\begin{equation*}
    \|\alpha_x(v)-\alpha_y(v)\|=\|\alpha_{y^{-1}}(\alpha_x(v)-\alpha_y(v))\|=\|\alpha_{y^{-1}x}(v)-v\|
\end{equation*}
\begin{proof}
    Let $f\in C_c(G)$, and want to show that the map
    \begin{equation*}
        x\mapsto \alpha_x(f) \text{ is strongly continuous }
    \end{equation*}
    suffices to show at $x=e_G$. Let $\epsilon>0$ be given, let $K=supp(f)$, and choose a comapct neighborhood $O$ of $e_G$. By joint continuity of $G\times M\xrightarrow{\alpha} M$, then we have
    \begin{equation*}
        O\times K\mapsto \alpha_O(K):=OK\in G \text{ is compact }
    \end{equation*}
    Now because $f$ is continuous, for each $m\in OK$, there is an open neighborhood $U_m$ of $m$ such that if $n\in U_m$, then 
    \begin{equation*}
        \|f(n)-f(m)\|<\epsilon/2
    \end{equation*}
    So there is an open neighborhood $W_m$ of the identity element, such that $O_m W_m\subset U_m$, you can even required $O_m\subset O$ (what we started with, ($O_m$'s are in $G$, and $W_m$'s are in $M$ )).The $W_m$'s form an open cover of $OK$ so there is a finite subcover $W_{m_1}, ..., W_{m_n}$ and let $O^*=\cap_{j=1}^n O_j$,

    Now we claim that for $x\in O^*$, we have that
    \begin{equation*}
        \|\alpha_x(f)-f\|<\epsilon
    \end{equation*}
    For every $m$, if $\alpha_x(f)(m)-f(m)\neq 0$, then 
    \begin{equation*}
        f(\alpha_x^{-1}m)-f(n)\neq 0
    \end{equation*}
    So each $m\in K$, $m\in O^*K$, and have $m\in O^*K\subset OK$, so there exists $j$ such that $m\in W_{m_j}$, $x\in O^*\subset O_j$, and so 
    \begin{equation*}
        \alpha_x(m)\in U_{m_j}
    \end{equation*}
    This gives
    \begin{equation*}
        \|f(\alpha_x(m_j))-f(m_j)\|<\epsilon/2, \|f(m)-f(m_j)\|<\epsilon/2
    \end{equation*}
\end{proof}

Let $\alpha$ be an action of $G$ on $M$, and suppose there is an $\alpha$-invariant Borel (or even Radon measure) measure on $M$. This gives an action of $G$ on $L^p(M, \nu)$, and 
\begin{equation*}
    \alpha_x(f)(m)=f(\alpha_x^{-1}m)
\end{equation*}
where $\|\alpha_x(f)\|_{L^p}=\|f\|_{L^p}$ by $\alpha$-invariant.
\begin{proposition}
    This action is strongly continuous.
\end{proposition}
\begin{proof}
    Check this is true on $C_c(M)\subset L^p(M, \nu)$, where $C_c(M)$ is a dense subspace. 
\end{proof}

\section{Lecture 21}
$G$ locally compact group, and $x$ locally compact space, and $\alpha$ a jointly continuous actionof $G$ on $X$, then the corresponding action of $G$ on $C_\infty(X)$ is strongly continuous.

For any $f\in C_\alpha(X)$, and
\begin{equation*}
    x\mapsto \alpha_xf \text{ is continuous for }\|\cdot\|_\infty
\end{equation*}
Assume that $\mu$ is an $\alpha$-invariant measure on $X$, i.e. 
\begin{equation*}
    \mu(\alpha_xf)=\mu(f), \text{ for all } x,f
\end{equation*}
We then can form $L^p(X,\mu)$, with the $\|\cdot\|_{L^p}$ norm:
\begin{equation*}
    \|f\|_{L^p}=\left(\mu(|f|^p)\right)^\frac{1}{p}
\end{equation*}
And $L^p(X)$ contains $C_c(X)$, and what we want is the action $\alpha$ on the $L^p$ is again strongly continuous. (One could take $f$ such that $\|f\|_\infty$ is small, but the $L^p$ norm is large.)

The action $\alpha$ of $G$ on $C_c(X)$ is continuous for the ``inductive limit topology.'' We shall it define it now.

\begin{definition}[Inductive limit topology]
    If $O\subset X$, and $\overline{O}$ is compact, then you can view $C_\infty(O)$, equipped with $\|\cdot\|_\infty$, as a subset of $C_c(X)$ (simply by extending by 0), then the inductive limit topology is the strongest topology on $C_c(X)$ making the inclusion continuous.
\end{definition}

\begin{definition}[Convergence in ILT]
    If a net $\{f_\lambda\}$ converges to $f$ uniformly, and eventually, and there is a compact set $K$ such that eventually all $f_\lambda$ are supported in $K$, then this $\{f_\lambda\}$ converges to $f$ in the inductive limit topology.
\end{definition}
If $\mu$ is a Radon measure on $C_c(X)$, then the net $\{f_\lambda\}$ converges to $f$ for $\|\cdot\|_{L^p}$ of $L^p(X,\mu)$. We can find $f_\lambda$ converges uniformly to $f$ in the $\|\cdot\|_\infty$ sense.
\begin{equation*}
    \left(\|f-f_\lambda\|_{L^p}\right)^p=\int_X|f-f_\lambda|^pd\mu\leq\|f-f_\lambda\|_\infty^p\mu(K)
\end{equation*}
And $\mu(K)<\infty$, and $\|f-f_\lambda\|_\infty<\epsilon$. Everything is of finite measure, and uniform convergence gives you convergence in the $L^p$ norm.

To show that $x\mapsto\alpha_x(F)$ is continuous for $\|\cdot\|_{L^p}$, it suffices to show that it is continuous at $e$, let $O$  be a compact neighborhood of $E$, and let $K=supp(f)$, then for $x\in O$, then $\alpha_x(f)$ is compactly supported in $\alpha_O(K)$, and $\|f-\alpha_x(f)\|_\infty\to 0$, hence is strongly continuous for the $\|\cdot\|_{L^p}$ norm.

Let $G$ be a locally compact and let $\alpha$ be an action by isometries on a Banach space $V$, we define the integrated form of $\alpha$, $f\in C_c(G)$, and $v\in V$:
\begin{equation*}
    \alpha_f(v)=\int_Gf(x)\alpha_x(v)dx, \alpha_x(v)\in V
\end{equation*}
where $dx$ is a choice of left-invariant Haar measure.

Given $\varphi\in V^*$,
\begin{equation*}
    \int f(x)\la \alpha_x(v), \varphi\ra dx
\end{equation*}
the above form is called the ``weak integral.''
and $range(f)$ is a normed-closed compact subset of $V$.

Consider, $C_c(X,\R)$, and $V$ is over $\R$. and \begin{equation*}
    (X,\R)\bigotimes V=\{\sum_{i=1}^n f_i\bigotimes  v_i, f_i\in C_c(X,\R), v\in V\}
\end{equation*}
and viewed as an element of $C_c(X,V)$, and $(x)=\sum_{i} f_i(x)v_i\in V$. Given a Radon measure $\mu$, we have
\begin{equation*}
    \int \sum_{j=1}^nf_j\bigotimes v_jd\mu=\sum\mu(f_j)v_j
\end{equation*}
The above is well-defined, and apply to $V^*$, if we denote $F=\sum_{j=1}^nf_j\bigotimes v_j$, then
\begin{equation*}
    \varphi(\int F(x)d\mu(x))=\int\varphi(F(x))d\mu(x)
\end{equation*}
One should think of these $F$ as simple functions $f=\sum_j\chi_{E_j}v_j$.

Note that
\begin{equation*}
    \{\sum_{j=1}^nf_j\bigotimes v_j\} \text{ is dense for the inductive limit topology}
\end{equation*}
Given $F\in C_c(X,V)$, and some $\epsilon>0$, let $K=supp(F)$, and $C$ be a compact neighborhood of $K$. Then, for each $x\in C$, there is an open neighborhood $O_x$ with
\begin{equation*}
    \|f(y)-f(x)\|<\epsilon \text{ if } g\in O_x
\end{equation*}
And by $C$ being compact, there exists a finite subcover $O_{x_1}, ..., O_{x_n}$. Choose a partition of unity, subordinate to the $\{O_{x_j}\}_{j=1}^n$. This means $F_j\in C_c(X,\R)$, and $0\leq f_j\leq 1$, and $supp(f_j)\subset O_j$, such that $\sum\varphi_j=1$ on $K$. Then the set
\begin{equation*}
    F_\epsilon=\sum f_j\bigotimes F(x_j)
\end{equation*}
and $\|F-F_\epsilon\|_\infty<\epsilon$. 

Let $\alpha$ be an action on $V$, if we write $\alpha_f(v)=\int_G f\alpha_x(v)dx$, and $\alpha_f\alpha_g=\alpha_{f\ast g}$, then
\begin{equation*}
    (f\ast g)(x)=\int f(y)g(y^{-1}x)dy
\end{equation*}
Fubini's theorem for Radon measures,  use $C_c(X)\bigotimes C_c(Y)$, dense in $C_c(X\times Y)$
\begin{equation*}
    \sum_{j=1}^n f_j\bigotimes g_j
\end{equation*}
for the inductive limit topology. This is the Stone-Weierstrass theorem. Now we ask the question, what is $(\pi_f)^*$.

\section{Lecture 22}
Let $G$ be locally compact, and if $(\mathcal{H}, \pi)$ is a unitary representation of $G$, with the integrated form:
\begin{equation*}
    f\mapsto\pi_f, f\in C_c(G)\subset L^1(G)
\end{equation*}
we have
\begin{equation*}
    (\pi_f)^*=\left( \int f(x)\pi_xdx\right)^*=\int\overline{f(x)}\pi_x^*dx=\int\overline{f(x)}\pi_{x^{-1}}dx=\int\overline{f(x^{-1})}\Delta(x)\pi_{x^{-1}}dx
\end{equation*}

\begin{proposition}
    If $G$ is locally compact, but not discrete, then $L^1(G)$ does not have an identity. 
\end{proposition}
\begin{example}
    $C_\infty(X)$.
\end{example}
\begin{note}
    Many Banach algebras have an ``approximate'' identity elements.
\end{note}
\begin{example}
    Let's look at $C_\infty(\R)$. You could take a function that is a smooth characteristic function, whose support is contained in $[-N, N]$, and pushing $N\to\infty$. If you take $N$ large enough, you eventually approximate the function itself.
\end{example}

\begin{definition}[Approximate identities]
    For a normed algebra $\mathcal{A}$, let $a$ be a left approximate identity , we mean a net ${e_\lambda}$ such that for any $a\in\mathcal{A}$, we have that $e_\lambda a\to a$ in norm. A right approximate identity is one such that $ae_\lambda\to a$ in norm. A two-sided approximate is one such that it satisfies both. And a bounded approximate identity is one such that $\|e_\lambda\|\leq c$ for all $\lambda$ and such that $e_\lambda a\to a$ in norm. (There is therefore, left bounded approximate identity, and right, and two-sided). A norm 1 approximate identity is such that $\|e_\lambda\|=1$.
\end{definition}
If $\mathcal{A}$ has a * operation, then you can define a self-adjoint approximate identity, if
\begin{equation*}
    e_\lambda^*=e_\lambda \text{ for all } \lambda
\end{equation*}
If $\mathcal{A}$ is a $C^*$-algebra, a positive approximate identity is a net with $e_\lambda>0$ for all $\lambda$. 

\begin{proposition}
    For any locally compact group, $L^1(G)$ has a approixmate identity of norm 1.
\end{proposition}
\begin{note}
    The picture should look like a tall bump function around the identity $e_G$.
\end{note}
\begin{proof}
    Let $\Gamma$ be a collection of comapct neighborhoods of $e_G$, and for each $O$, choose $e_O\in C_c(G)$ with $supp(e_O)\subset O$, and $\int e_O(x)dx=1$.

    $f\ast g(x)=\int f(y)g(y^{-1}x)dy$ with integrated form of the action of $G$ on $L^1(G)$ by translation $g(x)\to g(y^{-1}x)$. In fact, for any represntation of a Banach space $V$ of $G$ by $\pi_{e_\lambda}v\to v$ in norm. We would like the following to go to zero.
    \begin{equation*}
        \|\int e_O(x)\pi_xv-v\|=\|\int e_O(x)\pi_xv-\int e_O(x)dx v\|=\|\int e_O(x)(\pi_xv-v)\|
    \end{equation*}
    For any $\epsilon>0$, choose $O_\epsilon$ and that for $x\in O_\epsilon$, we have $\|\pi_xv-v\|<\epsilon$ (by SOT). For any neighborhood smaller than $O_\epsilon$, we still have this property, $O\subset O_\epsilon$.
    So for the above equation, we get that
    \begin{equation*}
        \|\int e_O(x)\pi_x(v)-\int e_O(x)dxv\|\leq\int Oe_O(x)\|\pi_xv-v\|\leq\epsilon
    \end{equation*}
\end{proof}
\qed

\begin{proposition}
    For any $c^*$-algebra $\mathcal{A}$ has a positive approximate identity of norm 1.
\end{proposition}
\begin{proof}
    Let $\Gamma$ be the collection of finite subsets of $\mathcal{A}$, and for $\lambda\in\Gamma$, let the finite sum be as follows:
    \begin{equation*}
        b_\lambda=\sum\{b^*b: b\in\lambda\}
    \end{equation*}
    let
    \begin{equation*}
        e_\lambda=\frac{b_\lambda}{\frac{1}{n}+b_\lambda}<1, n=|\lambda|=\text{ the number of elements in }\lambda
    \end{equation*}
\end{proof}
\qed

For any Banach normed algebra $\mathcal{A}$, we can get an identity element by 
\begin{equation*}
    \tilde{A}=\{(a,z): a+z1_{\tilde{\mathcal{A}}}\}
\end{equation*}
If $\mathcal{A}$ has an approximate identity of norm 1, and if $\mu$ is continuous positive $\mu(a^*a)\geq 0$ linear functional, on $\mathcal{A}$, but no identity element, but does have a norm $\|\mu\|$. Now if you have an approximate identity, then $\mu$ extends to a positive linear functional on $\tilde{\mathcal{A}}$, where $\|\mu\|=1$. Then you could apply GNS to this $\mu$.
\begin{note}
    Any $C^*$-algebra $\mathcal{A}$ has a positive approximate identity of norm 1. For example $G$, $L^2(G)$, and $\pi$
    \begin{equation*}
        \overline{\{\pi_f:f\in\mathcal{A}\}}=D_r^*(f)
    \end{equation*}
\end{note}


\section{Lecture 23}
\begin{proposition}
    Let $G$ be a locally compact group, the left-regular representation of $L^1(G)$ on $L^2(G)$ is faithful.
\end{proposition}
\begin{proof}
    let $f\in L^1(G)$, and $f\neq 0$, with $L^1(G)$ has a norm-1 approximate identity of functions in $C_c(G)$. Then there exists $g\in C_c(G)$ such that $f\ast g\neq 0$, and
    \begin{equation*}
        f\ast g=\int_G f(x)\lambda_xgdx\in C_\infty(G)\cap L^1(G)\cap L^2(G)
    \end{equation*}
    so now $g$ is an element of $L^2(G)$,
    \begin{equation*}
        \lambda_f(g)=f\ast g\in L^2(G)
    \end{equation*}
    we have that
    \begin{equation*}
        \|f\ast g\|_{L^2}^2=\int|f\ast g|^2d\mu>0
    \end{equation*}
    So $\lambda_f\neq 0$. For $G$ commutative, the norm closure
    \begin{equation*}
        \overline{\{\lambda_f: f\in L^1(G)\}}=C_r^*(G)
    \end{equation*}
\end{proof}

\begin{proposition}
    Let $\mathcal{A}$ be a $C^*$-algebra, without an identity element. Let $\tilde{\mathcal{A}}$ be $\mathcal{A}$ with 1 adjoint. (Side note: $\|a+\alpha 1\|=\|a\|+|\alpha|$, and note such norm is not good for $\mathcal{A}=C_\infty(X)$.) For the left regular representation on $\mathcal{A}$, i.e. if $b\in\tilde{\mathcal{A}}$, set $\|b\|:=\sup\{\|ba\|: \|a\|\leq 1\}$. With this norm $\|b\|$, we have that $\tilde{\mathcal{A}}$ is a $C^*$-algebra. 
\end{proposition}
This is to check that $\|b^*b\|=\|b\|^2$. We already have $\|b^*b\|\leq\|b\|^2$. And $\|ba\|^2$, we have that
\begin{equation*}
    \|ba\|^2=\|(ba)^*(ba)\|\leq\|a^*\|\|b^*ba\|\leq\|b^*b\|\|a\|=\|a\|^2\|b^*b\|
\end{equation*}
And it is easy to see that if $\mathcal{A}$ is complete, then $\tilde{\mathcal{A}}$ is also complete.

If $\mathcal{A}$ is a commutative $C^*$-algebra without identity, and $\tilde{\mathcal{A}}=C(X)$, and this is the nonzero homomorphisms of $\mathcal{A}$ onto $\C$, with $\{\infty\}$. So $\tilde{\mathcal{A}}=X\setminus\{\infty\}$, and $\mathcal{A}\cong C_\infty(X\setminus \{\infty\})$, where the space $X\setminus\{\infty\}$ is locally compact. 

Let $G$ be a commutative, discrete group, where
\begin{equation*}
    C_r^*(G)\cong C_\infty(X)
\end{equation*}
where each point of $X$ gives a nonzero homeomorphism of $L^1(G)$ into $\C$. Then get for any $f\in L^1(G)$, there is a continuous *-homomorphism of $L^1(G)$, then there exists a $\varphi\in\widehat{L^1(G)}$ such that $\varphi(f)\neq 0$. We want to describe all $\varphi\in\widehat{L^1(G)}$, let $f,g\in L^1(G), g\neq 0$. We have that
\begin{equation*}
    \varphi(f)\varphi(g)=\varphi(f\ast g)=\varphi(\int f(x)\lambda_xgdx)
\end{equation*}
So
\begin{equation*}
    \varphi(f)=\int f(x)\varphi(\lambda_x g)/\varphi(g)dx
\end{equation*}
Define $\omega\varphi(x)=\varphi(\lambda_xg)/\varphi(g)$, is continuous. hence we have that
\begin{equation*}
    \varphi_f\varphi_g=\it f(x)\varphi(\lambda_xg)dx
\end{equation*}
We then have
\begin{equation*}
    \varphi(g)\omega_\varphi(x)=\varphi(\lambda_xg)
\end{equation*}
If we look at 
\begin{equation*}
    \omega_\varphi(xy)\varphi(g)=\varphi(\lambda_{xy}g)=\varphi(\lambda_x(\lambda_yg))=\varphi(\lambda_yg)\omega_\varphi(y)\omega_\varphi(x)
\end{equation*}
Because we have $\varphi(g)\neq 0$, we divide both sides, then we have
\begin{equation*}
    \omega_\varphi(xy)=\omega_\varphi(x)\omega_\varphi(y)
\end{equation*}
So $\omega_\varphi\in\widehat{G}$ into $T$.

For $f\in L^1(G)$, define
\begin{equation*}
    \widehat{f}(\sigma)=\int f(x)\sigma(x)dx\in\widehat{G}\in C_\infty(\widehat{G})
\end{equation*}
where we equip $\widehat{G}$ with the weak-* topology, and $\sigma\in\widehat{G}$. And the above defines the Fourier transform.
\begin{corollary}
    The Fourier trasnform defined above is injective.
\end{corollary}
For any $f\in L^1(G)$, if $f\neq 0$, then $\widehat{f}\neq 0$. And we have
\begin{equation*}
    \widehat{f^*}=\overline{\widehat{f}}
\end{equation*}
Next we state a fact: 
\begin{proposition}
    The weak-* topology on $\widehat{G}$ agrees with the topology of uniform convergence on compact subsets of $G$. Moreover, under this uniform topology on compact subsets of $G$, we can see that $\widehat{G}$ is a topological group.
\end{proposition}
Next time: unbounded operators on Hilbert spaces! (And the spectral theorem for those).

\section{Lecture 24}
\begin{definition}[Power series of a bounded operator]
    If $V$ is a Banach space, and $A$ is a bounded linear operator on $V$, then have the operator:
    \begin{equation*}
        T_t=e^{tA}=\sum_{n=0}^\infty\frac{(tA)^n}{n!}
    \end{equation*}
\end{definition}
Then $T_tT_s=T_{t+s}$, and $s,t\in\R$, where $T_0=I$. For $v\in V$. For $v\in V$, and
\begin{equation*}
    t\mapsto T_tv \text{ is norm continuous }
\end{equation*}
If $V=C_\infty(\R^n, L^p(\R^n))$, and
\begin{equation*}
    Af=\Delta f, \text{ only defined for smooth } f
\end{equation*}
And
\begin{equation*}
    \frac{dI}{dt}f=\Delta f 
\end{equation*}

Let $V$ be a Banach space, and let $\{T_t\}$ be a semigroup of bounded operators on $V$, and $T_sT_t=T_{s+t}$, and $T_0=I_V$, with each strongly continuous, so
\begin{equation*}
    t\mapsto T_tv \text{ is norm continuous for each }v
\end{equation*}
\begin{definition}
    $v$ is differentiable if 
    \begin{equation*}
        Av=\lim_{h\to 0}\frac{T_{t+h}v-T_tv}{h}
    \end{equation*}
    has a limit as $h\to 0$.
\end{definition}
Let $\mathcal{D}=\{v\in V: v \text{ is differentiable }\}$ 
\begin{definition}
    If $v, w\in\mathcal{D}$, then $u+v\in\mathcal{D}$, and $\alpha v\in\mathcal{D}$ if $\alpha\in\C$. And $A$ is a linear operator from $\mathcal{D}$ to $V$.
\end{definition}

For each $\{T_tv:t\in [0,1]\}$ is compact, so bounded, so there exists $k_v$ such that $\|T_tv\|\leq k_v$ for all $t\in [0,1]$. So by uniform boundedness principle, there is a $k$ such that
\begin{equation*}
    \|T_t\|\leq k, \text{ for } t\in [0,1]
\end{equation*}
Then any $t\geq 0$, is of the norm $n+s$ with $s\in [0,1]$. So
\begin{equation*}
    T_t=T_nT_s=(T_1)^nT_s, \|T_t\|\leq k^{n+1}=kk^n=ke^{n\ln(k)}\leq ke^{t\beta}, \beta=\ln(k)
\end{equation*}
Let $\tilde{T}_t=k^{-1}e^{-t\beta}T_t$, then $\|\tilde{T}_t\|\leq 1$, this gives that $t\|\tilde{T}_t\|$ is a strongly continuous operator.

\begin{equation*}
    \frac{T_{t+h}-T_t}{h}=T_t\frac{T_h-T_0}{h}
\end{equation*}
And we also get
\begin{equation*}
    T_tAv=AT_t
\end{equation*}
\begin{proposition}
    If $v\in\mathcal{D}(A)$, then so does $T_tv$ for all $t$, and we have
    \begin{equation*}
        T_tAv=AT_t
    \end{equation*}
\end{proposition}
Given $f$ continuous on $[0,\infty)$, and $v\in V$. We can define 
\begin{equation*}
    \int_0^tf(s)T_s(v)ds 
\end{equation*}
is a norm continuous function on $\R^+$. This integral is defined by the Riemann integral (because is norm-continuous!).
One should think of this integrated form of $T$ for $f\vert_{[0,t]}$.
\begin{proposition}
    We have
    \begin{equation*}
        \int_0^tT_svds\in\mathcal{D}(A)
    \end{equation*}
\end{proposition}
And this is to show 
\begin{equation*}
    \int_0^tT_svds\in\mathcal{D}(A)
\end{equation*}. We will prove this next time. And note that
\begin{equation*}
    \frac{1}{t}\int_0^tT_svdt\to v, \text{ as } t\to 0
\end{equation*}
And this converges to the approximation of norm 1.


\section{Lecture 25}
Let $V$ be a Banach space, and $\{T_t\}$ a strongly continuous semigroup.
\begin{proposition}
    For any $t>0$, we have that 
    \begin{equation*}
        \int_0^tT_svds\in{D}(A)
    \end{equation*}
    where $D(A)$ is the domain of $A$.
\end{proposition}

\begin{proof}
    \begin{align*}
        \frac{T_h-T_0(I)}{h}\left(\int_0^t T_svds\right)&=\frac{1}{h}\left( T_h\left(int_0^tT_svds\right)-\int_0^tT_svds\right)\\
        &=\frac{1}{h}\left(\int_0^tT_{s+h}vds\right)-\frac{1}{h}\int_0^tT_svds\\
        &=\frac{1}{h}\left(\int_h^{t+h}T_svds-\int_0^sT_svds\right)\\
        &=\frac{1}{h}\left(\int_t^{t+h}T_svds-\int_0^tTsvds\right)=T_tAv-v
    \end{align*}
    In order words, 
    \begin{equation*}
        A\left(\int_0^tT_svds\right)=T_tAv-v
    \end{equation*}
\end{proof}
\qed

Hence, to reiterate, we have
\begin{equation*}
    \int_0^t T_svds\in D(A), \text{ so }\frac{1}{t}\int_0^tT_svds\in D(A)
\end{equation*}
And as
\begin{equation*}
    \lim_{t\to 0}\left(\frac{1}{t}\int_0^t\right)=v
\end{equation*}
Then
\begin{proposition}
    The domain of $A$, $D(A)$ is dense in $V$.
\end{proposition}
For each operator $S$ on a domain $D$, with $D\subset V$, the graph of $S$,
\begin{equation*}
    \Gamma(S)=\{(v,Sv): v\in D(S)\}\subset V\times V
\end{equation*}
And there is no unique norm that you put on here, but there exists some equivalent norms to put on here.
\begin{example}
    We could have the following norms on the graph of $S$, 
    \begin{equation*}
        \|(v,w)\|=\begin{cases}
            \|v\|_V\|w\|_\infty\\
            \|v\|+\|w\|\\
            (\|v\|^2+\|w\|^2)^\frac{1}{2}
        \end{cases}
    \end{equation*}
\end{example}
\begin{definition}[Closed and closable graph]
    You call $S$ is closed if $\Gamma(S)$ is a closed subset of $V\times V$.

    We call that $S$ is closable, if we have the closure of $\Gamma(S)$ is the graph of an operator. 
\end{definition}
\begin{note}
    The issue here is that if $(v, w_1), (v,w_2)$ both belong to $\overline{\Gamma(S)}$. Then, you need $w_1=w_2$. In other words, you need that if $(0,w)\in\overline{\Gamma(S)}$, then $w=0$. Note that this is also a sufficient condition. If closable, then closure of $S$ is the operator from $\overline{\Gamma(S)}$.
\end{note}
\begin{remark}
    This does not mean that the closure is the whole space.
\end{remark}
From an unbounded operator, how to create a one-parameter semigroup, such that is closable.

\begin{proposition}
    This is the aim: for $A$ from $\{T_t\}$, $A$ is a closed operator.
    \begin{equation*}
        A\left(\int_0^tT_svdx\right)=T_tv-v
    \end{equation*}
\end{proposition}
\begin{proposition}
    For $v\in D(A)$, we have
    \begin{equation*}
        \int_0^tA(T_sv)ds=\int_0^tT_s(Av)=T_tv-v
    \end{equation*}
\end{proposition}
\begin{proof}
    Let $V^*$ be the dual vector space, and let $\varphi\in V^*$, and let 
    \begin{equation*}
        f(t)=\varphi\left(\int_0^tAT_svds\right)=\int_0^t\varphi(AT_sv)ds, g(t)=\varphi(T_tv-v)
    \end{equation*}
    We have $f(0)=g(0)=0$. Then we consider the derivatives:
    \begin{equation*}
        f'(t)=\varphi(AT_tv), g'(t)=\varphi(AT_tv)
    \end{equation*}
    Now by the unique solutions of ordinary differential equations, we get that
    \begin{equation*}
        f(t)=g(t), \forall t
    \end{equation*}
\end{proof}
\qed

Now we prove the proposition that $A$ on $T_t$ is a closed operator.
\begin{proof}
    Suppose we have a sequence of $\{v_n\}\subset D(A)$, with $v_n\to v\in V$, and $Av_n\to w\in V$. We thus have
    \begin{equation*}
        (v_n, Av_n)\to (v,w)
    \end{equation*}
    Then for any $t$, we have (given $T_t$ is bounded)
    \begin{equation*}
        \int_0^tAT_sv_nds=T_tv_n-v_n\to T_tv-v
    \end{equation*}
    Note that this also converges to 
    \begin{equation*}
        \int_0^t T_s(Av_n)ds\to \int_0^tT_swds
    \end{equation*}
    So we have that 
    \begin{equation*}
        \int_0^tT_swds=T_tv-v
    \end{equation*}
    \begin{equation*}
        \frac{1}{t}\int_0^tT_swds=\frac{T_tv-v}{t}
    \end{equation*}
    Let $t\to 0$, then we have (the LHS is approximate of identity)
    \begin{equation*}
        w=Av
    \end{equation*}
    Hence we have that $v\in D(A)$, i.e. the pair
    \begin{equation*}
        (v_n, Av_n)\to (v,w)=(v,Av)\in\Gamma(A)
    \end{equation*}
    $A$ is closed.
\end{proof}
\qed

\begin{note}
    \textcolor{red}{what semigroup/}
\end{note}

Let $\mathcal{H}$ be a Hilbert space, and let $A\in\mathcal{B}(\mathcal{H})$, and let 
\begin{equation*}
    T_t=e^{tA}
\end{equation*} 
We ask the question: when is $T_t$ a group of \textbf{unitary} operators, such that $T_tT_t^*=T_tT_T^{-1}=I$  


\section{Lecture 26}
Let $A\in\mathcal{B}(\mathcal{H})$,  $T_t=e^{tA}$, unitary, and
\begin{equation*}
    T_tT_t^*=I
\end{equation*}
and 
\begin{equation*}
    \frac{d}{dt}\vert_{t=0}=A+A^*=0
\end{equation*}
And we have
\begin{equation*}
    e^{tA}e^{tA^*}=I
\end{equation*}
i.e. $A^*=-A$.

Let $B=-iA$, and $B$ is self-adjoint, and 
\begin{equation*}
    A=iB, e^{itB}\text{ is self-adjoint}
\end{equation*}
We now take
\begin{equation*}
    U_t=e^{itA}
\end{equation*}
where $A$ is unbounded, we ask if it is self-adjoint?
For an unbounded operator $A$ on $\mathcal{H}$, $D(A)$, dense.
Ho do we define $A^*$?
\begin{equation*}
    \la A\xi, eta\ra=\la \xi, A^*\eta\ra, \xi\in D(A)
\end{equation*}
where
\begin{equation*}
    D(A^*)=\{h\in\mathcal{H}: \xi\to A\xi \text{ is continuous }\}
\end{equation*}

\begin{equation*}
    \Gamma(A^*)=\{(\eta,\zeta):\la A\xi, \eta\ra=\xi, \zeta, \forall\xi\in D(A)\} 
\end{equation*}
In other words,
\begin{equation*}
    \la A\xi, \eta\ra-\la \xi, \zeta\ra=0
\end{equation*}
which implies
\begin{equation*}
    \la(A\xi-\xi), (\eta, \zeta)\ra=0
\end{equation*}
And we have
\begin{equation*}
    \la V(\xi, A\xi), (\eta, \zeta)\ra=0
\end{equation*}
\begin{equation*}
    \Gamma(A^*)=(V(\Gamma(A)))^\perp=V(\Gamma(A)^\perp)
\end{equation*}
We have that $\Gamma(A^*)$ is closed, and hence $V(\overline{\Gamma(A)})$ is closed.

Hence if $A$ is closed, then 
\begin{equation*}
    \Gamma(A^*)=(V\Gamma(A))^\perp=V((\Gamma(A))^\perp)
\end{equation*}
Then 
\begin{equation*}
    \mathcal{H}\bigoplus\mathcal{H}=\Gamma(A^*)\bigoplus V\Gamma(A)
\end{equation*}
\begin{proposition}
    We have $D(A^*)$ is dense.
\end{proposition}
\begin{proof}
    If $D(A^*)$ is not dense, then there exists $\xi\in\mathcal{H}$, such that
    \begin{equation*}
        \la \xi, D(A^*)\ra =0
    \end{equation*} 
    \begin{equation*}
        0=\la(0,\xi), (A^*\eta,-\eta)\ra=\la (0,\xi), V((\eta, A^*\eta))\ra
    \end{equation*}
    for $\eta\in\Gamma(A^*)$. So $(0,\xi)$ is perpendicular to $V(\Gamma(A^*))$, so 
    \begin{equation*}
        (0,\xi)\in\Gamma(A), A0=\xi\Rightarrow \xi=0
    \end{equation*}
\end{proof}
\qed

\begin{equation*}
    \mathcal{H}\bigoplus\mathcal{H}=\Gamma(A^*)\bigoplus V\Gamma(A)=\Gamma(A)\bigoplus V(\Gamma(A^*))
\end{equation*}
For an $\xi\in\mathcal{H}$, and 
\begin{equation*}
    (\xi, 0)=(\eta, A\eta)+(A^*S, -S)
\end{equation*}
and 
\begin{equation*}
    \zeta=\eta+A^*\zeta=\eta+A^*A\eta=(I+A^*A)\eta, 0=A\eta-\zeta
\end{equation*}
and then
\begin{equation*}
    (I+A^*A): D(A)\to\mathcal{H}
\end{equation*}
For any $\zeta\in D(A)$,  note that we have
\begin{equation*}
    \la (I+A^*A)\eta,\eta\ra=\la \eta, \eta\ra+\la A^*A\eta, \eta\ra=\la A\eta, A\eta\ra=0, \text{ if }\eta\neq 0
\end{equation*}
\begin{corollary}
    $(I+A^*A)$ is injective and onto $\mathcal{H}$.
\end{corollary}

If $S,T$ are unbounded operators on $\mathcal{H}$, and $D(S), D(T)$, then
\begin{equation*}
    D(ST)=\{\xi:\xi\in D(T), \text{ and } T\xi\in D(S)\}
\end{equation*}
\begin{equation*}
    D(S+T)=D(S)\cap D(T)
\end{equation*}

We have that
\begin{equation*}
    \|(I+A^*A)\xi\|\geq\|\xi\|
\end{equation*}
And again we have $(I+A^*A)^{-1}$ exists on $\mathcal{H}$ and mapping onto $D(A)$. So
\begin{equation*}
    \|(I+A^*A)^{-1}\|\leq 1
\end{equation*}

\section{Lecture 27}
\begin{proposition}
    For $A$ closed, we have $I+A^*A$ is injective on $D(A^*A)$, and $D(A^*A)$ is dense in $\mathcal{H}$.
\end{proposition}
\begin{proof}
    We would like to show for a given $\xi\in\mathcal{H}$, we have that
    \begin{equation*}
        \la \xi, \eta\ra=\la(I+A^*A)\eta, \eta\ra=\la\eta, \eta\ra=\la A\eta, A\eta\ra
    \end{equation*}
    So that if the above is equal to 0, we get that $\eta=0$, which we get $\xi=0$, hence the density claim.

    Let $\eta\in D(A^*A)$, and let $\xi=(I+A^*A)\xi$, if $\xi=0$, then we must have our $\eta=0$. So $(I+A^*A)=I_\mathcal{H}$. And we get that $(I+A^*A)$ is one-to-one from $D(A^*A)$ on $\mathcal{H}$, hence
    \begin{equation*}
        Range(S)=D(A^*A)
    \end{equation*} 
\end{proof}
\qed

For any $\xi$, we get
\begin{equation*}
    \la S^*\xi, \xi\ra-\la S^*(I+A^*A)S\xi, \xi\ra=\la (I+A^*A)S\xi, S\xi\ra=\la S\xi, S\xi\ra^\perp\la AS\xi, AS\xi\ra\geq 0
\end{equation*}
Being positive implies that $S^*=S$, and $S$ is positive and adjoint. $S$ is also one-to-one, and
\begin{equation*}
    Range(S)=D(A^*A)
\end{equation*}
This gives that $(I+A^*A)S=I_\mathcal{H}$, then
\begin{equation*}
    S=(I+A^*A)^{-1}
\end{equation*}
\begin{definition}
    For a closed operator $A$, we call $(A,D(A))$ is self-adjoint, if 
    \begin{equation*}
        (A, D(A))=(A^*, D(A^*))
    \end{equation*}
\end{definition}
We will show that $(I+A^*A, D(A^*A))$ is self-adjoint.

\begin{definition}
    For $(A,D(A))$ is symmetric if for all $\xi\in D(A)$, we have
    \begin{equation*}
        \la A\xi, \xi\ra=\la \xi, A\xi\ra
    \end{equation*}
\end{definition}
We will show some operators are self-adjoint next time.


\section{Lecture 28}
For $A$ closed on $D(A)\subset\mathcal{H}$, and
\begin{equation*}
    I+A^*A: D(A^*A)\to\mathcal{H}
\end{equation*}

And $S: \mathcal{H}\to D(A^*A)$, and
\begin{equation*}
    (I+A^*A)S=I_\mathcal{H}
\end{equation*}
And last time we saw that $I+A^*A$ is injective. Then we also have that $S$ is onto $D(A^*A)$, and then
\begin{equation*}
    S=(I+A^*A)^{-1}
\end{equation*}
from $\mathcal{H}$ to $D(A^*A)$.
\begin{note}

If $T: D(T)\to D'$ is bijective, thus $T^{-1}$ exists, then
\begin{equation*}
    \Gamma(T^{-1})=W\Gamma(T), W((\xi,\eta))=(\eta, \xi)
\end{equation*}
Hence $\Gamma(T^{-1})$ is closed if and only if $\Gamma(T)$ is closed. 
\end{note}
This implies that $S$ is closed.
\begin{proposition}
    $I+A^*A$ is closed.
\end{proposition}
\begin{proof}
    Above.
\end{proof}

\begin{definition}
    $(A,D(A))$, let $A$ be densely defined, is self-adjoint, if $D(A^*)=D(A)$ ($A^*$ is also densely defined), and on this domain,
    \begin{equation*}
        A=A^*
    \end{equation*}
\end{definition}

\begin{proposition}
    If $A, D(A)$ is closed, then $D(A^*)$ is dense.
\end{proposition}
\begin{proof}
    If $D(A^*)$ is not dense, then there exists a nonzero $\xi$ such that $\xi\perp D(A^*)$, and we have
    \begin{equation*}
        (0,\xi)\perp (A^*\eta, -\eta)
    \end{equation*}
    for all $\eta\in D(A^*)$. 
    \begin{equation*}
        (0,\xi)\perp V(\eta, A^*\eta), \text{ for all } \eta
    \end{equation*}
    This gives that
    \begin{equation*}
        (0,\xi)\in\Gamma(A)
    \end{equation*}
    Hence $\xi=0$.
\end{proof}
\qed

\begin{proposition}
    If $A$ is closed, then $A=A^{**}$.
\end{proposition}
\begin{proof}
    Note that we have
    \begin{equation*}
        \Gamma(A^*)=(V\Gamma(A))^\perp
    \end{equation*}
    $\Gamma(A^*A)=(V(\Gamma(A^*))^\perp)$, and note that $V^2=-I$, hence
    \begin{equation*}
        \Gamma(A^{**})=(V(\Gamma(A^*))^\perp)=V(\Gamma(A^*)^\perp)=V(V\Gamma(\overline{A}))
    \end{equation*}
    Thus,
    \begin{equation*}
        \Gamma(A^{**})=\Gamma(A)
    \end{equation*}
\end{proof}
\qed


\begin{proposition}
    If $A$ is intertible and closed, and $A:D(A)\to D'$, then
    \begin{equation*}
        \Gamma((A^{-1})^*)=\Gamma((A^*)^{-1})
    \end{equation*}
\end{proposition}
\begin{proof}
    We have that
    \begin{equation*}
        WV\Gamma(A^{-1})^*=W \Gamma(A^{-1})^\perp=(W\Gamma(A^{-1}))^\perp=\Gamma(A)^\perp
    \end{equation*}
    And note that we also have
    \begin{equation*}
        VW\Gamma((A^*)^{-1})=V(A^*)=\Gamma(A^{**})^\perp=\Gamma(A)^\perp
    \end{equation*}
    Note that we have
    \begin{equation*}
        VW=-VW
    \end{equation*}
    \begin{equation*}
        (WV)(\xi,\eta)=W(\eta,-\xi)=(-\xi, \eta)
    \end{equation*}
    \begin{equation*}
        (VW(\xi, \eta))=V(\eta,\xi)=(\xi, -\eta)
    \end{equation*}
    \begin{note}
        The negative sign does not matter when describing graphs.
    \end{note}
\end{proof}
\qed

\begin{theorem}
    $I+A^*A$ is self-adjoint.
\end{theorem}
\begin{proof}
    \begin{equation*}
        I+A^*A=S^{-1}, (I+A^*A)^{-1}=S
    \end{equation*}
    so
    \begin{equation*}
        ((I+A^*A)^{-1})^*=S^*=S=(I+A^*A)^{-1}
    \end{equation*}
    Hence $(I+A^*A)^{-1}$ is self-adjoint, hence $I+A^*A$ is also self-adjoint. 
\end{proof}
\qed

\begin{theorem}
    If $A$ is self-adjoint, $S$, $AS=R$, then we have $SR=RS$. 
\end{theorem}
If $A$ is self-adjoint, $S$, $AS=R$, then we want
$SR=RS$ Let $\xi\in D(A)$, then
\begin{equation*}
    \xi=(I+A^*A)S\xi=S\xi+A^*AS\xi
\end{equation*}
We know that $S\xi\in D(A^*A)\subset D(A)$, so
\begin{equation*}
    A^*AS\xi\in D(A)
\end{equation*} 
Then we apply $A$ to everything
\begin{equation*}
    A\xi=AS\xi+AA^*AS\xi=(I+AA^*)AS\xi
\end{equation*}
Notice the * is in the wrong place now.
\begin{equation*}
    (I+AA^*)^{-1}A\xi=AS\xi
\end{equation*}
we call
\begin{equation*}
    \tilde{S}=(I+AA^*)^{-1}
\end{equation*}
\begin{note}
    It looks like $S$, but just the * is in the wrong place.
\end{note}
Note that 
\begin{equation*}
    \tilde{S}A\xi=AS\xi
\end{equation*}
If $A$ is self-adjoint, so $A^*=A$, \begin{definition}[Normal operators]
    We say $A$ is normal if 
    \begin{equation*}
        A^*A=AA^*, D(A^*A)=D(AA^*)
    \end{equation*}
\end{definition}
If you have $A$ as normal, then you could say $S=\tilde{S}$.

So if $A$ self-adjoint, then for $\xi\in D(A)$, 
\begin{equation*}
    SA\xi=AS\xi
\end{equation*}
For any $\eta\in\mathcal{H}$, let $\xi=S\eta\in D(A^*A)\subset D(A)$, 
\begin{equation*}
    S(AS)\xi=(AS)(S\xi)
\end{equation*}
Hence for $A$ self-adjoint,
\begin{equation*}
    SR\xi=RS\xi, \text{ for all }\xi\in\mathcal{H}
\end{equation*}


\section{Lecture Nov 3}
We have 
\begin{equation*}
    l^1(\mathbb{N})\subset l^1(\mathbb{Z}), \mathcal{A}=L^1(\R^+)\subset L^1(\R)
\end{equation*}
We note that 
\begin{equation*}
    \widehat{\mathcal{A}}=\{\text{ continuous homomorphisms of } \R^+ \text{ into the unit disk }\}
\end{equation*}
This is 
\begin{equation*}
    \{\varphi_\lambda: \varphi_\lambda(t)=e^{-\lambda t}, Re(\lambda)\geq 0\}
\end{equation*}
This looks like the right half plane of $\R^2$.

The Gelfand transform sends $f\in L^1(\R^+)$ is 
\begin{equation*}
    \widehat{f}(\lambda)=\int_0^\infty f(t)e^{-\lambda t}dt
\end{equation*}
\begin{note}
    This is the Laplace transform.
\end{note}
\begin{note}
    Notice this if we don't assume $f$ is integrable, but instead just $f$ is bounded, and the above integral is well-defined for $Re(\lambda)>0$. (Would not make sense if $Re(\lambda)=0)$.
\end{note}
Let $V$ be a Banach space, and let $\{T_t\}$ be a strongly continuous 1-parameter semigroup on $\R^+$ on $V$, continuous, i.e.
\begin{equation*}
    \|T_t\||\leq 1, \forall t
\end{equation*}
For $Re(\lambda)>0$, set 
\begin{equation*}
    R_\lambda\xi=\int_0^\infty e^{-\lambda s}T_s\lambda ds
\end{equation*}
This will convergge given $Re(\lambda)>0$. Let $B$ be the ``generator'' of $\{T_t\}$. Then we have
\begin{equation*}
    T_h(R_\lambda\xi)=\int_0^\infty e^{-\lambda s}T_{s+h}\xi ds=\int_h^\infty e^{\lambda(s-h)}T_s\xi ds 
\end{equation*}
This has 
\begin{align*}
    \frac{T_h-I}{h}&=\frac{1}{h}\int_h^\infty e^{\lambda(s-h)}T_s\xi dt-\int_0^\infty e^{-\lambda s}T_s\xi ds\\
    &=\frac{1}{h}\int_0^\infty e^{\lambda(s-h)}T_s\xi ds-\frac{1}{h}\int_0^\infty e^{-\lambda s}T_s\xi ds-\frac{1}{h}\int_0^h e^{-\lambda(s-h)}T_s\xi ds\\
    &=\frac{e^{\lambda h}-1}{h}\int_0^\infty e^{-\lambda s}T_s\xi ds-\frac{1}{h}\int_0^h e^{-\lambda(s-h)}T_s\xi\\
    &=\lambda R_\lambda\xi-\xi
\end{align*}
Thus for all $\xi\in V$, and $R_\lambda\xi\in D(B)$, and 
\begin{equation*}
    B(R_\lambda\xi)=\lambda R_\lambda\xi-\xi
\end{equation*}
Then we have
\begin{equation*}
    \xi=(\lambda R_\lambda-BR_\lambda)\xi=(\lambda-B)R_\lambda\xi
\end{equation*}
All of the above leads to the following theorem.
\begin{theorem}
    For $R_\lambda\xi\in D(B)$ for all $\xi\in V$, $Re(\lambda)>0$, and 
    \begin{equation*}
        (\lambda-B)R_\lambda\xi=\xi
    \end{equation*}
    Thus $Range(\lambda-B)=V$. And 
    \begin{equation*}
        R_\lambda=\frac{1}{\lambda-B} ``='' \text{ the resolvent of } B
    \end{equation*}
\end{theorem}

Let $\mathcal{H}$, and a semigroup of unitary operators, $\{U_t\}$, $A$, we have 
\begin{equation*}
    \la U_t\xi, U_t\eta\ra=\la \xi, \eta\ra
\end{equation*}
And 
\begin{equation*}
    \la A\xi, \eta\ra+\la \xi, A\eta\ra=0, \xi, \eta\in D(A)
\end{equation*}
So $-A\subset A^*$. Hence $A$ is skew-symmetric. We apply to $\{U_t\}_{t=0}$, for $\lambda>0$, $Range(A-\lambda)=\mathcal{H}$.

And let $\tilde{T}_t=T_{-t}$, and $Range(A+\lambda)=\mathcal{H}$. Then range 
\begin{equation*}
    range(iA\pm i\lambda)=\mathcal{H}
\end{equation*}

\begin{proposition}
    $C$ is a symmetric operator on $\mathcal{H}$, and that $Range(C\pm i)=\mathcal{H}$, then $C$ is a self-adjoint in the technical sense.
\end{proposition}
\begin{proof}
    We have $D(C)\subset D(C^*)$, and on $D(C)$, we have $C^*\vert_{D(C)}=C$, then we want: if $\xi\in D(C^*)$, then $\xi\in D(C)$. Now let $\xi\in D(C^*)$ be given, then because there exists $\eta\in D(C)$, so 
    \begin{equation*}
        (C^*-i)\eta=(C^*-i)\xi
    \end{equation*}
    But $D(C)\subset D(C^*)$, 
    \begin{equation*}
        (C^*-i)\eta
    \end{equation*}
    This implies that $\xi-\eta\in Ker(C^*-i)=Ker(C+i)^*=(Range (C+i))^\perp$. And note that $Range(C+i)=\mathcal{H}$, hence this is 0.
    \begin{equation*}
        \xi=\eta, \xi\in D(C)
    \end{equation*}
    Hence we are done.
\end{proof}
\qed

We will talk about compact operators next time. 

\section{Lecture Nov 6}
We will discuss compact operators now.
\begin{definition}
    Let $V, W$ be normed vector spaces, let $T: V\to W$ be linear, then $T$ is said to be compact if
    \begin{equation*}
        T(V_1) \text{ is totally bounded in } W
    \end{equation*}
    where $V_1=\overline{B}(0,1)$ in $V$, the closed unit ball. Recall that totally bounded means for every $\epsilon>0$, the set can be covered with finite number of balls of radius at most $\epsilon$. If $W$ is complete, then $T$ is compact if
    \begin{equation*}
        \overline{T(V_1)} \text{ is compact }
    \end{equation*}
\end{definition}
\begin{note}
    This implies that $T$ is a bounded operator.
\end{note}

A bit of notation: let $B_0(V,W)$ be the set of compact operators from $V,W$.
\begin{proposition}
    If $S,T\in B_0(V,W)$, then $S+T\in B_0(V,W)$. (Less nontrivially, so is $\alpha T$.)
\end{proposition}
\begin{proof}
    Let $\epsilon>0$, then there exists $w_1, ..., w_m\in W$ so that $Ball( w_j, \epsilon/2)$ cover $S(V_1)$. There exists $w'_1, ..., w'_n\in W$ such that $Ball(w'_j, \epsilon/2)$ cover $T(V_1)$.

    So for any $v\in V_1$, there is $w_j$ and such that $Sv\in Ball(w_j, \epsilon/2)$, and a $w'_R$ such that $Tv\in Ball(w'_R, \epsilon/2)$. This gives that 
    \begin{equation*}
        \|(S+T)v-(w_j+w'_R)\|\leq \|Sv-w_j\|+\|Tv-w'_R\|\leq\epsilon/2+\epsilon/2=\epsilon
    \end{equation*}
\end{proof}
\qed

\begin{proposition}
    If $T\in B_0(V,W)$, and $S\in B(U,V)$ (just a bounded operator), then $TS: U\to W$ is in $B_0(U,W)$.

    If $R: W\to Y$, and $R\in B(W,Y)$, then $RT: V\to Y$ is in $B_0(V,Y)$. This implies that 
    \begin{equation*}
        \{T: T\in B_0(V,W) \} \text{ is a two-sided ideal in } B(V,w)
    \end{equation*}
\end{proposition}
\begin{note}
    $R$ is uniformly coninuous, hence maps totally bounded sets to totally bounded sets.
\end{note}
\begin{note}
    $B_0(V)$ for $B_0(V,V)$, then $B_0(V)$ is a 2 sided ideal in $B(V)$.
\end{note}
\begin{proposition}
    $B_0(V,W)$ is norm-closed in $B(V,W)$.
\end{proposition}
\begin{proof}
    Let $\{T_n\}$ be a sequence in $B_0(V,W)$, and $T_n\to T$ in norm in $B(V,W)$. We now want to show $T$ is compact. Let $\epsilon>0$ be given, choose $N$ such that
    \begin{equation*}
        \|T-T_N\|<\epsilon/2
    \end{equation*}
    Find $w_1, ..., w_n\in W$ so that $Ball(w_j, \epsilon/2)$ cover $T_N(V_1)$. Then for any $v\in V_1$, there exists $w_j$ such that $Tv\in Ball(w_j, \epsilon/2)$, and $\|v\|\leq 1$, hence
    \begin{equation*}
        \|Tv-w_j\|\leq \|Tv-T_Nv\|+\|T_Nv-w_j\|<\epsilon/2+\epsilon/2=\epsilon
    \end{equation*}
    Hence $T\in B_0(V,W)$. Now we have shown that $B_0(V)$ is a closed two-sided ideal.
\end{proof}
\qed

Next we talk about some important examples of compact operators.
\begin{example}
    Let $T:V\to W$, bounded, has finite rank, i.e. $Range(T)$ is finite dimensional.
\end{example}
\begin{example}
    Let $V=l^p(X), 1\leq p<\infty$, and let $f\in C_0(X)=C_\infty(X)$. And let $T=M_p$ by pointwise multiplication by $f$ (if $X$ is finite, then it follows from the above example that $T$ is finite rank), such $T$ is compact.
\end{example}
The next example is slightly interesting.
\begin{example}
    Integral operators: $A=\{\alpha_{j,k}\}^n$ act on $\C^n$
    \begin{equation*}
        (Av)_j=\sum a_{jk}v_k=\sum (\alpha_{j,k})v(k)
    \end{equation*} 
\end{example}
Let $X,Y$ be measure spaces, and $K$ measurable on $X\times Y$, and for a function $\xi$ measurable on $Y$, define 
\begin{equation*}
    (T_k\xi)(x)=\int K(x,y)\xi(y)dy
\end{equation*}
The above $K(x,y)$ is called the kernel. 
\begin{example}
    If $K\in L^\infty(X,Y)$, then for almost every $x$,
    \begin{equation*}
        y\mapsto K(x,y)\in L^\infty(Y)
    \end{equation*}
    If $\xi\in L^1(Y)$, then 
    \begin{equation*}
        |(T_K\xi)(x)|=\int |K(x,y)||\xi(y)|dy<\infty
    \end{equation*}
    Hence $T_k\xi\in L^\infty$. (Such operator is probably not compact).
\end{example}

If $K\in L^1(X,Y)$, then for almost every $x$, $K(x,\cdot)$ (viewed as a function of $y$), if $K(x,\cdot)\in L^1$, and $\xi\in L^\infty(Y)$, then 
\begin{equation*}
    T_K\xi(x)=\int K(x-y)\xi(y)dy
\end{equation*}
and 
\begin{equation*}
    \|T_K\xi\|_{L^1}\leq \|K\|_{L^1}\|\xi\|_{L^\infty}
\end{equation*}
\begin{proposition}
    $T_K: L^\infty(Y)\to L^1(X)$ is compact.
\end{proposition}
\begin{proof}
    If $K(x,y)=\chi_E(x)\chi_F(y)$, and $Range(T_k)=\R\chi_E$. This is of rank 1, hence compact. If 
    \begin{equation*}
        K=\sum_{j=1}^n \alpha_j\chi_{E_j}\chi_{F_j}
    \end{equation*}
For $K\in L^1(X,Y)$, approximate by simple functions above, in the $L^1$ norm. This implies that 
\begin{equation*}
    T_{K_n}\to T_K
\end{equation*}
in operator norm, and by the previous proposition, $T_K$ is compact.
\end{proof}
\qed

Let $K\in L^2(X\times Y)$, so 
\begin{equation*}
    \int |K|^2 dxdy<\infty
\end{equation*}
For almost every $x$, $K(x,\cdot)\in L^2(Y)$. Hence if $\xi\in L^2(Y)$, 
\begin{equation*}
    (T_K\xi)(x)=\int K(x,y)\xi(y)dy
\end{equation*}
This integral makes sense for almost every $x$.
\begin{equation*}
    |T_k\xi(x)|=\left|\int K(x,y)\xi(y)\right|\leq \int |K(x,y)||\xi(y)| dy \leq \|K(x,y)\|_{L^2(Y)}\|\xi\|_{L^2}<\infty
\end{equation*}
Now
\begin{equation*}
    \|T_K\xi\|_{L^2(X\times Y)}^2\leq \|K(x,y)\|_{L^2(X\times Y)}^2\|\xi\|_{L^2}^2
\end{equation*}
This gives us 
\begin{equation*}
    \|T_K\|\leq \|K\|_{L^2}
\end{equation*}
Hence we again approximate with simple functions, and by the same proof that we gave for $L^1$.
\begin{corollary}
    $T_K$ with $K\in L^2(X\times Y)$ defined by 
    \begin{equation*}
        T_Kf(x)=\int K(x,y)f(y)dy
    \end{equation*}
    is compact.
\end{corollary}

\section{Lecture Nov 8}
We talked about self-adjoint compact operators last time. Let $T\in B(\mathcal{H})$, and $T^*=T$. 
\begin{proposition}
    For $T$ bounded and self-adjoint, then we have  
    \begin{equation*}
        \|T\|=\sup\{|\la T\xi, \xi\ra|: \|\xi\|\leq 1\}
    \end{equation*}
\end{proposition}
\begin{proof}
    \begin{equation*}
        \la\xi, \eta\ra=\frac{1}{4}\sum_{n=0}^3 i^n\la \xi+i^n\eta, \xi+i^n\xi\ra
    \end{equation*}
    Apply $T\xi$ to the first coordinate, and the fact that $T^*=T$, take the real part.
\end{proof}
We present another proof.
\begin{proof}
    $T\geq 0$, such that $T=S^2$, for some $S\geq 0$, then 
    \begin{equation*}
        \la T\xi, \xi\ra=\la S\xi, S\xi\ra=\|S\xi\|^2
    \end{equation*}
    The taking the sup over $\|\xi\|\leq 1$, we just get $\|S\xi\|^2=\|S\|^2=\|T\|$.
\end{proof}
\qed


\begin{proposition}
    We prove $T$ self-adjoint has an approximate eigvenvector.
\end{proposition}
Fix $T, \sigma(T)$, we consider the projection to $[0,\infty)$, denote the projection operator as $P^+$, and projection to $(-\infty, 0]$ as $P^-$. Note that 
\begin{equation*}
    P^++P^-=I 
\end{equation*}
Hence for a Hilbert space $\mathcal{H}$, we can decompose it,
\begin{equation*}
    \mathcal{H}=P^+\mathcal{H}+P^-\mathcal{H}
\end{equation*}
Then there exists $\{\xi_n\}, \|\xi_n\|=1$, such that 
\begin{equation*}
    |\la T\xi_n, \xi_n\ra|\to \|T\|\neq 0
\end{equation*}
And $\|T\xi_n\|\to \|T\|$. So one can assume that 
\begin{equation*}
    \la T\xi_n, \xi_n\ra\to \|T\|
\end{equation*}
Let $\lambda=\|T\|$, and now look at 
\begin{equation*}
    \|(T-\lambda I)\xi_n\|^2=\la (T-\lambda)\xi_n, (T-\lambda)\xi_n\ra=\la T\xi_n, T\xi_n\ra-2\lambda\la T\xi_n, \xi_n\ra +\lambda^2\la \xi_n, \xi_n\ra
\end{equation*}
Now we take the limit, $n\to\infty$, we get
\begin{equation*}
    \|T\|^2-2\|T\|^2+\|T\|^2=0
\end{equation*}
\begin{definition}[approximate eigenvector]
    For any $T\in B(\mathcal{H})$, if we have $\lambda$, and $\{\xi_n\}$, with $\|\xi_n\|=1$, and 
    \begin{equation*}
        \|(T-\lambda)\xi_n\|\to 0
    \end{equation*}
    We then say that $\{\xi_n\}$ is an approximate eigenvector for $\lambda\in\sigma(T)$.
\end{definition}
\begin{corollary}
    We see from above, that for $T$ self-adjoint, either $\|T\|$ or $-\|T\|$, one can show for any $\lambda\in\sigma(T)$, $T$ has an approximate eigevnvector.
\end{corollary}
\begin{proof}
    Above.
\end{proof}
\begin{proposition}
    Compact operators have an eigenvector.
\end{proposition}

Let $T\in B_0(\mathcal{H})$, a compact operator, and $T^*=T$. Assume $\|T\|$ that has an approximate eigenvector $\{\xi_n\}$, with $\|\xi_n\|=1$. Then $\{\xi_n\}\subset\mathcal{H}$, $\{T\xi_n\}$ is totally bounded.

And as a subsequence converges to some vector $\eta$, so assume that $T\xi_n\to \eta$, then 
\begin{equation*}
    \|(T-\lambda)\xi_n\|\to 0
\end{equation*}
 This implies that 
 \begin{equation*}
    (T-\lambda)\xi_n\to 0, T\xi_n-\lambda\xi_n\to 0
 \end{equation*}
 But we know $T\xi_n\to\eta$, 
 \begin{equation*}
    (T-\lambda)\eta
 \end{equation*}
 Let $T\lambda\xi_n-\lambda\lambda\xi_n=\lambda(T\xi_n-\lambda\xi_n)\to 0$, for $\lambda\neq 0$.

For $T$ compact, let $\lambda$ not be any eigenvalue, then the eigenspace $\mathcal{H}_\lambda$ must be finite dimensional. For any $r>0$, let $H_r$ be the direct sum of all the eigen-subspaces for eigenvalues $\lambda$ with $|\lambda|\geq r$. Then  $T$ on $\mathcal{H}_r$ is commutative, with norm $\leq\frac{1}{r}$. This implies that $H_r$ is finite dimensional. This has bounded inverse. 

Then $T\vert_{\mathcal{H}_r}S=I_\mathcal{H}$ (the identity opeartor is compact). $T$ acts on $H_r$ into itself, and $T^*=T$. Note that $T\vert_{H_r^\perp}$ is compact, if $\|T\vert_{H_R^\perp}\|\geq r$, then $H^+$ contains an eigenvector for an eigenvalue $\lambda$ with $\lambda\geq r$.

This gives that $\|T\vert_{H_r^\perp}\|<r$. And we take a sequence $r_n\to 0$, note that all $H_{r_n}$ are finite dimensional, so get a sequence $\{\lambda_n\}$, and $|\lambda_n|\to 0$. And the eigenspaces are finite dimensional, so $\bigoplus\mathcal{H}_{\lambda_n}$ is all of $\mathcal{H}$ except for elements in the kernel of $T$, which may be infinite-dimensional, or can just be $\{0\}$.
 
From this, we get there is an orthonormal basis for $\mathcal{H}$ consisting of eigenvalues.
\begin{note}
    Any compact operator can be diagonalized, with a countable number of eigenspaces.
\end{note}

\section{Lecture Nov 15}
We say $T\in B(\mathcal{H})$ is compact if $T(Ball)$ is totally bounded. The finite rank operator form a dense ideal in $B_0(\mathcal{\mathcal{H}})$. 

Fact: every self-adjoint compact operator can be approximated in norm by finite rank (self-adjoint) operators. Given $T$, we have 
\begin{equation*}
    T=\frac{T+T^*}{2}+i\frac{T-T^*}{2i}
\end{equation*}
So if we have $T$ is compact, then $T^*$ is also compact.

\begin{definition}
    By a partial isometry on $\mathcal{H}$, we mean an operator $W$ such that $W$ is an isometry on $(ker W)^\perp$, and onto some other closed subspace of $\mathcal{H}$. We have $W^*W$ is the projection on $(ker W)^\perp$, and $WW^*$ is the projection on the range of $W$.
\end{definition}
For $T\in B(\mathcal{H})$, define $|T|=(T^*T)^\frac{1}{2}$. 
\begin{theorem}[Polar Decomposition]
    For any given $T\in B(\mathcal{H})$, then there is a partial isometry $W$, such that
    \begin{equation*}
        T=W|T|, |T|=\sqrt{T^*T}
    \end{equation*}
\end{theorem}
\begin{proof}
    For $\xi\in\mathcal{H}$, 
    \begin{equation*}
        \|T\xi\|^2=\la T\xi, T\xi\ra=\la T^*T\xi, \xi\ra=\la |T|^2\xi, \xi\ra=\la |T|\xi, |T|\xi\ra=\||T|\xi\|^2
    \end{equation*}
    We have 
    \begin{equation*}
        ker(T)=(range T^*)^\perp
    \end{equation*}
    Hence 
    \begin{equation*}
        ker T=ker|T|=(range|T|)^\perp
    \end{equation*}
    Set for any $\xi$, 
    \begin{equation*}
        W(|T|\xi)=T\xi
    \end{equation*}
    And $W|T|\xi=T\xi, W|T|=T$. This extends to an isometry from the $\overline{range(|T|)}$, and onto the $\overline{range(T)}$.

    Define $W$ such that on $ker(T)$, $W=0$. If $T\in B_0(\mathcal{H})$, $T^*T\in B(\mathcal{H})$ since it is an ideal. $|T|\in B_0(\mathcal{H})$ as well. If we take $T=W|T|$, $T^*=|T|W^*$. 
\end{proof}

From last calss,$\mathcal{A}$ is a $C^*$-algebra, and $\omega$ is a weight on $\mathcal{A}$. We have $m_\omega, n_\omega$, and $n_\omega$ is a left ideal in $\mathcal{A}$, and $m_\omega$ is a right ideal in $\mathcal{A}$. $m_a$ is a two-sided ideal of $\mathcal{A}$, and 
\begin{equation*}
    m_a=n_a^*n_a
\end{equation*}
\begin{definition}
    A weight $\omega$ is tracial if for all $a\in\mathcal{A}$,
    \begin{equation*}
        \omega(a^*a)=\omega(aa^*)
    \end{equation*}
\end{definition}
\begin{proposition}
    If $a\in N_\omega$, then $a^*\in n_\omega$. So $n_\omega$ is a 2-sided * ideal in $\mathcal{A}$, then $m_\omega$ is a 2-sided * ideal in $\mathcal{A}$.

    If $a,b\in n_\omega$, then 
    \begin{equation*}
        \omega(ab)=\omega(ba)
    \end{equation*}
\end{proposition}

\begin{proposition}
    If $b\in m_w^+$, and $a\in\mathcal{A}$, and let $c=\sqrt{b}\in n_\omega$, then 
    \begin{equation*}
        \omega(ab)=\omega( acc)=\omega(cac\leq\omega(\|a\|c^2))=\|a\|\omega(b)
    \end{equation*}
    Thus $b\in m_\omega^\perp$ determines a continuous linear functional on $\mathcal{A}$ of nomr $\omega(b)$, such that $a\mapsto \omega(ab)$.
\end{proposition}

Let $\mathcal{A}=B(\mathcal{H})$, and $\omega=\tau$ for $T\in B(\mathcal{H})$, and we define
\begin{equation*}
    \tau(T):=\sum\la T\xi_j, \xi_j\ra
\end{equation*}
for some orthonormal basis, and $\tau(T^*T)=\tau(TT^*)$. We have 
\begin{equation*}
    \tau(T^*T)=\sum\la T^*T\xi, \xi\ra=\sum\|T\xi_j\|^2
\end{equation*}
We claim the following:
\begin{lemma}
    If $\{b_j\}$ is any other o.n. basis, then 
    \begin{equation*}
        \sum\|T\xi_j\|^2=\sum\|T^*h_j\|^2
    \end{equation*}
\end{lemma}

\section{Lecture Nov 17}
For $B(\mathcal{H})$, and $\{\xi_j\}$ is an o.n.b, and for $T\geq 0$, 
\begin{equation*}
    \tau(T)=\sum\la T\xi_j,\xi_j\ra
\end{equation*}
and we would like to know if we have 
\begin{equation*}
    \tau(T^*T)=\tau(TT^*)
\end{equation*}
And let $\{\eta_k\}$ be another set of o.n.b, then for any $j$, we have 
\begin{equation*}
    T\xi_j=\sum\la T\xi_j, \eta_k\ra\eta_k
\end{equation*}
And Parsevel's identity states that 
\begin{equation*}
    \|T\xi_j\|^2=\sum_k|\la T\xi_j, \eta_k\ra|^2
\end{equation*}
And 
\begin{align*}
    \tau(T^*T)&=\sum\la T^*T\xi_j, \xi_j\ra\\
    &=\sum\|T\xi_j\|^2=\sum_j\sum_k|\la T\xi_j, \eta_k\ra|^2\\
    &= \sum_k\left(\sum_j|\la\xi_j, T^*\eta_k\ra|\right)^2\\
    &=\sum\|T^*\eta_k\|^2\\
    &=\tau(TT^*)
\end{align*}
\begin{corollary}
    $\tau$ defined above is indeed a trace.
\end{corollary}
And if we define 
\begin{equation*}
    \eta_\tau=\{T: \tau(T^*T)<\infty\} 
\end{equation*}
And $T^*T=|T|^2$, hence equivalently, we have
\begin{equation*}
    \eta_\tau=\{T: \tau(|T|^2)<\infty\}
\end{equation*}
And thus defines a norm via this inner product by 
\begin{equation*}
    \|T\|_\tau=\left(\tau(T^*t)\right)^{1/2}
\end{equation*}

\begin{definition}
    The opeartors $T$ such that $\tau(T^*T)<\infty$ is called Hilbert-Schmidt operators, denoted as $B_2(\mathcal{H})$, where 
    \begin{equation*}
        B_\infty(\mathcal{H})=B(\mathcal{H}) \text{ with  operator norm } \|\cdot\|_\infty
    \end{equation*}
\end{definition}

If $S\in B(\mathcal{H})$, and $S\geq 0$, then for any $\epsilon>0$, there is an $\xi\in\mathcal{H}$ such that $\|\xi\|=1$, and $\|S\xi\|\geq\|S\|_\infty-\epsilon$. So if use $\xi$ so part of an o.n. basis, such that 
\begin{equation*}
    \tau(S)\geq\|S\|_\infty
\end{equation*}
So far any $T\in\mathcal{H}$, 
\begin{equation*}
    \tau(T^*T)\geq\|T^*T\|_\infty=\|T\|_\infty^2
\end{equation*}
-evaluatioIf $T\in B_2(\mathcal{H})$, then 
\begin{equation*}
    \|T\|_{L^2}\geq\|T\|_\infty
\end{equation*}

\begin{proposition}
    If $T\in B_2(\mathcal{H})$, i.e. it is a Hilbert-Schmidt operator, then $T$ is compact.
\end{proposition}
\begin{proof}
    Let $T\in B_2(\mathcal{H})$, and $\tau(T^*T)<\infty$. 
    \begin{equation*}
        \tau(T^*T)=\sum_j\|T\xi_j\|^2<\infty
    \end{equation*}
    Let $\epsilon>0$ be given, and there exists $N$ such that if $n\geq N$, then 
    \begin{equation*}
        \sum_{j=n}^\infty \|T_j\|^2<\epsilon
    \end{equation*}
    For any orthogonal projection $P$ of finite rank, 
    \begin{equation*}
        \|T-TP\|_\infty\leq\|T-TP\|_2
    \end{equation*}
    Note that $\xi_j$ is an o.n.b, If we let $P$ be the projection on $\xi_1, ..., \xi_{n-1}$, 
    \begin{equation*}
        \sum_{j=1}^\infty \|T(1-P)\xi_j\|=\sum_{j=n}^\infty\|T\xi_j\|<\epsilon
    \end{equation*}
\end{proof}
\qed

\begin{theorem}
    The space of Hilbert-Schmidt operators, $B_2(\mathcal{H})$, is complete for the $\|\cdot\|_2$, so $B_2(\mathcal{H})$ is a Hilbert space.
\end{theorem}
\begin{proof}
    Let $\{T_n\}\subset B_2(\mathcal{H})$ be a Cauchy sequence for $\|\cdot\|_2$. Thus $\{T_n\}$ is Cauchy for the operator norm, and in the operator norm, we have $B(\mathcal{H})$ is complete. So there is a $T\in B(\mathcal{H})$ such that $T_n\to T$ for $\|\cdot\|_\infty$. 

    Now we want is that it converges for the $\|\cdot\|_2$ norm. Let $\epsilon>0$ be given, let $P$ be any finite rank projection. And let $N$ be such that if $m,n\geq N$, then $\|T_m-T_n\|_2<\epsilon$. For $m\geq N$,
    \begin{equation*}
        \|(T_m-T)P\|_2\leq\|(T_n-T)P\|_2+\|(T_m-T_n)P\|_2
    \end{equation*}
    So the second term is bounded by $\epsilon/2$.
    Now we can choose $n$ such that $\|T-T_n\|_\infty<\epsilon/2$, and $n\geq N$, claim:
    \begin{equation*}
        \|SP\|_2^2=\sum\|S\xi_n\|^2\lesssim \|S\|_\infty
    \end{equation*}
    Hence by choosing $n$ this way, we get the first term is also bounded by $\epsilon/2$.

    Now we prove the claim: if $S\in B(\mathcal{H})$, such that $\|SP\|2<\epsilon$ for all projections.
    \begin{equation*}
    \tau(S^*S)=\sum_{j=1}^\infty\|S\xi_j\|^2
    \end{equation*}
    And you take the partial sum 
    \begin{equation*}
    \sum_{j=1}^k\|S\xi_j\|^2=\|SP\|2<\epsilon
    \end{equation*}

    All the partial sums are bounded by $\epsilon$, hence 
    \begin{equation*}
    \|S\|_2^2<\epsilon
    \end{equation*}
\end{proof}
\qed

Next thing on Monday: every Hilbert Schmidt operator can be expressed by the kernels $K\in L^2(X\times X)$.


\section{Lecture Nov 20}
\begin{proposition}
    Let $B_f(\mathcal{H})$ be the space of finite rank operators (range is finite dimension, and can be written as a sum of rank 1 operators), $B_f(\mathcal{H})\subset B_2(\mathcal{H})$, and $B_f(\mathcal{H})$ is dense in $B_2(\mathcal{H})$ for the $\|\cdot\|_2$ norm.
\end{proposition}
\begin{proof}
    If $T\in B_2(\mathcal{H})$, then for an o.b. basis $\{\xi_j\}$, we have 
    \begin{equation*}
        \sum_{j=1}^\infty\|T\xi_j\|^2<\infty
    \end{equation*}
    So given $\epsilon>0$, we can find $N$ such that 
    \begin{equation*}
        \sum_{j=N}^\infty\|T\xi_j\|^2<\epsilon
    \end{equation*}
    Then let $P$ be the orthogonal projection on $\xi_1, ..., \xi_{N-1}$ ($P$ is finite rank), then 
    \begin{equation*}
        \|T-TP\|_2^2=\sum_{j=1}^\infty\|(T-TP)\xi_j\|^2
    \end{equation*}
    for the first $N-1$ temrs, we get 0 contribution, hence 
    \begin{equation*}
        \|T-TP\|_2^2=\sum_{j=N}^\infty\|(T-TP)\xi_j\|^2=\sum_{j=N}^\infty\|T\xi_j\|^2<\epsilon
    \end{equation*}
\end{proof}
\qed


Let $\mathcal{H}=L^2(X,\mu)$, and let $K\in L^2(X\times X, \mu\times\mu)$, and let 
\begin{equation*}
    (T_k\xi)(x)=\int_XK(x,y)\xi(y)dy
\end{equation*}
Let $\{\xi_j\}$ be an o.n.b. for $L^2(X,\mu)$, and we would like to show these $T_k$ are Hilbert-Schmidt operators. Then 
\begin{equation*}
    \|T_K\xi_j\|^2=\sum_{k=1}^\infty |\la T\xi_j, \xi_k\ra|^2=\sum_{k=1}^\infty|\la \int K(x,y)\xi_j(y)dy, \xi_k\ra|^2
\end{equation*}
Summing over $j$, we get 
\begin{equation*}
    \sum_{j}\sum_k|\int K(x,y)\xi_j(y)\xi_k(x)dydx|^2=\sum_{j,k}|\la K, \xi_j(y)\xi_k(x)\ra|^2=\|K\|_{L^2}<\infty
\end{equation*}
And by Parsevel's identity, since $\{\xi_j(y)\xi_k(x)\}$ form an o.n.b for $L^2(X\times X, \mu\times\mu)$, we get the last equality.

\begin{note}
    You can run the argument backwards, and cna show that every Hilbert-Schimidt opeartor on $L^2(X,\mu)$ is of the form $T_k$ for some $K\in L^2(X\times X)$.
\end{note}
Recall that $m_\omega$, where $\omega$ is tracial, (on $n_\omega$, we showed that there exists an inner product-induced norm), and now we discuss $m_\omega$. Let $\mathcal{A}$ be an algebra, and if $a\in\mathcal{A}$, and $b\in m_\omega$, $b\geq0$, then 
\begin{equation*}
    |\omega(ab)|\leq\|a\||\omega(b)\|
\end{equation*}
For a trace $\tau$on $B(\mathcal{H})$, we have polar decomposition for $T\in B(\mathcal{H})$. If $T\in m_\tau$, we have $T=V|T|$, where $V$ is a partial isometry, and $|T|=\sqrt{T^*T}$., and 
\begin{equation*}
    V^*T=V^*V|T|=|T|
\end{equation*}
Then for $A\in B(\mathcal{H})$, 
\begin{equation*}
    |\tau(AT)|=|\tau(aV|T|)|\leq \|AV\|_\infty\tau(|T|)\leq\|A\|\tau(|T|)
\end{equation*}
\begin{proposition}
    For $A\in B(\mathcal{H})$, $T\in m_\tau$we have 
    \begin{equation*}
        |\tau(AT)|\leq\|A\|\tau(|T|)
    \end{equation*}
\end{proposition}
If $T\in B(\mathcal{H})$, and $|T|\in m_\tau$, then $T=V|T|$, and $|T|=V^*T$, so $T\in m_\tau$. 
\begin{proposition}
    We have 
    \begin{equation*}
        m_\tau=\{T\in B(\mathcal{H}): \tau(|T|)<\infty\}
    \end{equation*}
    is a two-sided ideal in $B(\mathcal{H})$.
\end{proposition}
So on $m_\tau$, define 
\begin{equation*}
    \|T\|_1=\tau(|T|)
\end{equation*}
\begin{proposition}
    If $S,T\in m_\tau$, then 
    \begin{equation*}
        \|S+T\|_1\leq\|S\|_1+\|T\|_1
    \end{equation*}
    The space $B_1(\mathcal{H})$ which is finite for the 1-norm, is called the trace-class operators.
\end{proposition}
\begin{proof}
    This would like the 1-norm defined above is indeed a norm. For $S,T\in m_\tau$, we have 
    \begin{equation*}
        S+T=W|S+T|
    \end{equation*} 
    Hence $|S+T|=W^*(S+T)$, so 
    \begin{equation*}
        \tau(|S+T|)=\tau(W^*(S+T))=\tau(W^*S)+\tau(W^*T)
    \end{equation*}
    but note that each term on the right does not need to be nonnegative, even though the sum is nonnegative. Hence 
    \begin{equation*}
        \|S+T\|_1=\tau(|S+T|)\leq|\tau(W^*S)|+|\tau(W^*T)|\leq\|W^*\||\tau(S)|+\|W^*\||\tau(T)|=\|S\|_1+\|T\|_1
    \end{equation*}
\end{proof}
\qed

It is therefore natural to move from 1 to $p$.
\begin{definition}
    For $1\leq p<\infty$, we have 
\begin{equation*}
    B_p(\mathcal{H})=\{T\in B_0(\mathcal{H}): \tau(|T|^p)<\infty\}
\end{equation*}
and we define 
\begin{equation*}
    \|T\|_p=(\tau(|T|^p))^{1/p} \text{ is a norm }
\end{equation*}
The space $B_p(\mathcal{H})$ is also called the Shatter ideals. And we define the dual of $B_p$ as $B_q$ via the following relation $\frac{1}{p}+\frac{1}{q}=1$
\end{definition}

Given $\mathcal{H}$, and an o.n.b $\{\xi_j\}$, then you can write an operator as an infinite matrix, and look at the ones that are diagonal. Then $B_p(\mathcal{H}) \cap \text{ diagonal matrices }=l^p$.

We first observe that
\begin{equation*}
    \|T\|_1\geq\|T\|_\infty
\end{equation*}
\begin{proposition}
    $B_1(\mathcal{H})$ is complete for the $\|\cdot\|_1$ norm.
\end{proposition}
\begin{proof}
    This is quite analogous to the proof $B_2(\mathcal{H})$ is complete for $\|\cdot\|_2$. Let $\{T_n\}\subset B_1(\mathcal{H})$ be a Cauchy sequence for $\|\cdot\|_1$, then it is Cauchy for $\|\cdot\|_\infty$ norm, and so there is $T\in B(\mathcal{H})$ such that 
    \begin{equation*}
        \|T-T_n\|_\infty\to 0
    \end{equation*}
    This implies that $T\in B_0(\mathcal{H})$, and $B_0(\mathcal{H})\cap \text{ diagonal }\cong c_0$. Let $\epsilon>0$ be given, then we can find $N$ such that for $m,n\geq N$, 
    \begin{equation*}
        \|T_m-T_n\|_1<\epsilon
    \end{equation*}
    For any projection $P$ of finite rank, for a fixed $m$, we look at the following finite rank operator,
    \begin{equation*}
        \|P(T-T_m)\|_1=\|PW^*|T-T_m|\|_1\leq\|PW^*(T-T_n)\|_1+\|PW^*(T_n-T_m)\|_1
    \end{equation*}
    (unfinished, the class ended here).
\end{proof}


\section{Lecture Nov 27}
We introduced $B(\mathcal{H}), B_2(\mathcal{H}), B_1(\mathcal{H})$. For $T\in B_1(\mathcal{H})$, let $\|T\|_1=\tau(|T|)$, and we've shown this is a norm. As a theorem, we were in the middle of showing that $B(\mathcal{H})$ is complete for the $\|\cdot\|_1$ norm.

If $S=0$, then 
\begin{equation*}
    \tau(S)=\sum_{j=1}^\infty\la S\xi_j,\xi_j\ra
\end{equation*}
If we let $P_k$ be the orthogonal projection onto $\xi_k$. 
\begin{equation*}
    \tau(PS)=\sum\la PS\xi_j, \xi_j\ra=\sum\la S\xi_j, P\xi_j\ra=\sum^k\la SP\xi_j, P\xi_j\ra=\sum^k\la PSP\xi_j, \xi_j\ra
\end{equation*}
Let $\{T_n\}\subset B(\mathcal{H})$ be a Cauchy sequence for $\| \|_1$, then $\{T_n\}$ is a Cauchy sequence for $\| \|_\infty$. So there is $T\in B(\mathcal{H})$ such that $T_n\to T$ in $\| \|_\infty$. Let $\epsilon>0$ be given, for any finite dimensional projection $P$, we choose $N$ so that for $m,n\geq N$, $\|T_m-T_n\|_1<\epsilon/2$. Choose $m\geq N$. Then we have 
\begin{equation*}
    \tau(P|T-T_m|P)=\tau(PV^*(T-T_m)P)\leq|\tau(PV^*(T-T_n)P)|+|\tau(PV^*(T_n-T_m)P)|
\end{equation*}
We can choose $n$ such that 
\begin{equation*}
    \tau(PV^*(T-T_n)P)<\epsilon/2
\end{equation*}
For $S,A\in B(\mathcal{H})$, then 
\begin{equation*}
    |\tau(AS)|\leq\|A\|_\infty\|S\|_1, |\tau(SA)|\leq\|S\|_\infty\|A\|_1
\end{equation*}
And notice that we have 
\begin{equation*}
    |\tau(PV^*(T_n-T_m)P)|\leq\|OV^*\|_\infty\|T_n-T_m\|_1\leq\epsilon/2
\end{equation*}
Then we have 
\begin{equation*}
    \tau(P_k|T-T_m|P_k)<\epsilon, \forall P
\end{equation*}
This gives that $\|T-T_m\|_1<\infty$ so $T-T_m\in B(\mathcal{H})$, $T_m\in B_1(\mathcal{H})$, so $T\in B_1(\mathcal{H})$.

\begin{theorem}
    The dual Banach space to $B_0(\mathcal{H})$ is, via the map $|\tau(AT)\|\leq \|A\|\|T\|_1$, $B_1(\mathcal{H})$. This implies that for all $T\in B_1(\mathcal{H})$, define 
    \begin{equation*}
        \varphi_T(A)=\tau(AT)
    \end{equation*}
    for all $A\in B_0(\mathcal{H})$, with $\| \|_\infty$.

    In other words, every element is dual of $B_0(\mathcal{H})$ is of the form $\varphi_T$ for $T\in B_1(\mathcal{H})$.
\end{theorem}
\begin{remark}
    The dual of $c_0$ is $l^1$.    
\end{remark}
\begin{proof}
    Let $B_0(\mathcal{H})\supset B_2(\mathcal{H})$, and if $A\in B_2(\mathcal{H})$, we have 
    \begin{equation*}
        \varphi(A)\leq\|\varphi\|\|A\|_\infty\leq\|\varphi\|\|A\|_2
    \end{equation*}
So there is a $T\in B_2(\mathcal{H})$, such that 
\begin{equation*}
    \varphi(A)=\la A, T\ra_2=\tau(AT^*)
\end{equation*}
To show that $T\in B_1(\mathcal{H})$. Note that we have 
\begin{equation*}
    |\varphi(P|T|)|=|\varphi(PV^*T)|=|\varphi(PV^*)|\leq \|\varphi\|\|PV^*\|=\|\varphi\|
\end{equation*}
Then we have 
\begin{equation*}
    |\tau(P|T|)|=|\tau(PV^*T)|=|\varphi(PV^*)|\leq\|\varphi\|\|PV^*\|_\infty\leq\|\varphi\|
\end{equation*}
for all $P$. Hence $T\in B_1(\mathcal{H})$, and $\|T\|_1\leq\|\varphi\|$.
\end{proof}
\qed

\begin{theorem}
    The dual of $B_1(\mathcal{H})$ is $B(\mathcal{H})$ (note that the dual of $l^1$ is $l^\infty$).
\end{theorem}
\begin{corollary}
    The unit ball of $B(\mathcal{H})$ is compact for the weak-* topology. By definition, a von Neumann algebra is a unital *-algebra of $B(\mathcal{H})$ that is closed for the weak-* topology. Then we look at the set
    \begin{equation*}
        \{\varphi\in B_1(\mathcal{H}):\varphi(N)=0\}=N^\perp
    \end{equation*}
    And 
    \begin{equation*}
        \left( B_1(\mathcal{H})/N^\perp\right)^*=N
    \end{equation*}
\end{corollary}
Hence every von Neumann algebra has a pre-dual, hence the closed unit ball in a von Neumann algebra is compact in the weak-* topology.

\begin{proposition}
    The above is the ultra-weak opeartor topology on $B(\mathcal{H})$. If we view that $B_f(\mathcal{H})\subset B_1(\mathcal{H}$), and use elements of $B_f(\mathcal{H})$ to get linear functionals on $\mathcal{B}(\mathcal{H})$, that is the weak operator topology.
\end{proposition}

\section{Last Lecture}
One can show that 
\begin{equation*}
    \tau(\la\eta, \eta\ra_0)=\la\eta,\xi\ra_{\mathcal{H}}
\end{equation*}
\begin{definition}
    Let $V,W$ be vector spaces, $T$ is said to be Fredholm if $\dim(ker(T))<\infty$, and $\dim(coker(T))<\infty$, where $coker=W/range(T)$.
\end{definition}
\begin{definition}
    The index of $T$ is the dimension of $Ker(T)-coKer(T)$.
\end{definition}
\begin{proposition}
    If for $i=1,2$, $T_i: V_i\to W_i$, and 
    \begin{equation*}
        T_1\bigoplus T_2: V_1\bigoplus V_2\to W_1\bigoplus W_2
    \end{equation*}
    then we have $T_1\bigoplus T_2$ is Fredholm and $index(T_1\bigoplus T_2)=index(T_1)+index(T_2)$.
\end{proposition}
Notation: $Fred(V,W)=$ set of $F$ such that Fredholm from $V$ to $W$.
\begin{proposition}
    If $T\in F(V,W)$, and if $S\in F(W,Z)$, then $ST\in Fred(V,Z)$, and $index(ST)=index(S)+index(T)$.
\end{proposition}
\begin{proof}
    Exercise.
\end{proof}
\begin{proposition}
    If $T\in End(V,W)$, and if $index(T)=0$, then either (1) $T$ is invertible, or (2) $kernel(T)\neq\{0\}$, and $range(T)\neq V$.
\end{proposition}
In (1), the equation $Tx=w$ has a solution, and it is unique. In (2), the equation $Tx=w$ won't have a solution for some $w$. If it has a solution to some $w$, then the solution is not unique (you can add something in the kernel). There exists $w_1, ..., w_j$, such that $Tx_j=w_j$ has a solution, for $j=1, ..., n$.

If $V,W$ are Banach spaces, let $Fred(V,W)$ be the bounded Fredholm operators. 
\begin{theorem}
    If $T\in Fred(V,W)$, and if $K\in B_0(V,W)$, then $T+K\in Fred(V,W)$. And we have $index(T+K)=index(T)$.
\end{theorem}
\begin{corollary}
    Let $K\in B_0(V)$, then $\lambda\neq 0$, then if we look at $\lambda I-K$ is Fredholm, and $index(\lambda I-K)=0$.

    So either $(\lambda I-K)$ is invertible, so $ker(\lambda I-K)\neq \{0\}$, i.e. $\lambda$ is an eigenvalue for $K$, and $\lambda\in\sigma(K)$.
\end{corollary}

\begin{theorem}
    For $K\in B_0(V)$, and $\lambda$ an eigenvalue, is $(\lambda I-K)$ is not invertible, there is an $N<\infty$ such that $ker(\lambda I-K)^{N+n}=ker(\lambda I-K)^N$.   
\end{theorem}

\begin{definition}
    Psedodifferential operators: On $\R^n$, given by a symbol on $\mathcal{S}(\R^{2n})$, define $T_a$ on $\mathcal{S}(\R^n)$, and for $f\in\mathcal{S}(\R^n)$, 
    \begin{equation*}
        \widehat{T_af(x)}=a(x,t)\hat{f}(t)
    \end{equation*}
\end{definition}
On $l^2(\mathbb{N})$, let $T$ be the left shift operator, $Te_n=e_{n+1}$, the kernel is 0, but the cokernel is $\{e_1\}$. This is Fredholm of index $-1$.

\begin{remark}
    $B_(\mathcal{H})/B_0(\mathcal{H})$, and this is called the cackelim algebra, is a $C^*$-algebra. $T\in F(\mathcal{H})$ if and only if the image of $T$ is invertible. Index exactly consists of $GL(calkim)$. 
\end{remark}
\begin{remark}
    The following isomorphisms: $B(\mathcal{H})\sim l^\infty$, and $B_0(\mathcal{H})\sim c_0$, and $B(\mathcal{H})/B_0(\mathcal{H})\sim  l^\infty/c_0$.
\end{remark}


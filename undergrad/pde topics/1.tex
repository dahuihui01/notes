\chapter{Lecture 1}

here we go.

\section*{Course overview}
We will be discussing the nonlinear Schrodinger quations, which is a subcategory of nonlinear pde's, nonlinear dispersive equations, and infinite speed of propogation, 

Let's start with the linear Schrondinger equation.

\begin{equation*}
    i\partial_tu+\Delta u=0 \text{ in } \R\times\R^n, u(t=0)=u_0
\end{equation*}
The fundamental solution to a Schrondinger equation, is the $K(t,x)$ is such that $u_0=\delta_0$.

Instead, one could look at other intial data, for exmaple, $\widehat{u}_0=\delta_{\xi_0}$, or $u_0=e^{ix\xi_0}$.

\begin{remark}
    If you localize the initial data in the physical space, then the fourier transform is constant and therefore cannot be localized in the Fourier space. The reverse is also true if you try to localize in the Foureir space.
\end{remark}

If we have
\begin{equation*}
    u_0=e^{-\frac{(x-x_0)^2}{2}}e^{i(x-x_0)\cdot\xi_0}
\end{equation*}
For this type of initial data, we call it the coherent state, localized at $(x_0, \xi_0)$

In non-coherent state, the solution spreads out immediately; in the coherent state, the solution remains nicely behaved and coherent for a period of time, then it spreads out evenetually.

\begin{remark}
    This is the idea of group velocity, waves with frequence $\xi_0$ move with velocity $2\xi_0$. This $2\xi_0$ is called the group velocity. 
\end{remark}

Dispersive equation: waves with different frequencies travel in different directions.


\section{Nonlinear}
We will start with the nonlinear boys now.
\begin{equation*}
    i\partial_tu+\Delta u=\lambda u\cdot |u|^p
\end{equation*}
We will ask the following standard pde questions.
\begin{enumerate}
    \item existence
    \item uniqueness
    \item continuous dependent
    \item global in time behavior, i.e. linear vs nonlinear effects
\end{enumerate}
\begin{remark}
    If one just observes the RHS, then there is linear and nonlinear contributions, and one probalby would expect that one dominates over the other over time.
\end{remark}

\textbf{linear}: scattering. nonlinear solution looks like the linear solution

\textbf{nonlinear}: solitons (solutions that remain concentrated for a very long time, such as a bump function), blow-ups.

We will comment on the dispersive aspect of the Schrondinger equation before the nonlinear aspect.


\section{Dispersion}
Here are ways to measure dispersion. Given nicely behaved initial data, $u(t=0)=u_0\in H^s$.
\begin{enumerate}
    \item  dispersive estimates $\|u\|_{L^\infty}\leq t^{O(1)}\|u_0\|_{L^1}$
    \item Strichartz estimates $\|u\|_{L_t^pL_x^q}\leq \|u_0\|_{L^2}$
    \item Lateral Strichartz esiamtes, exchanging the role of $t, x$.
    \item Improved function spaces (Bourgain spaces, $U^p$, $V^p$)
    \item Local energy decay. If you have a dispersive solution, instead of measuring the solution everywhere, say, you measure it in the vertical cylinder.
\end{enumerate}

\textbf{Back to NLS.}
\begin{equation*}
    i\partial_t u+\Delta u=\lambda u|u|^p
\end{equation*}

We will talk about the following:
\begin{enumerate}
    \item local well-posedness
    \item global well-posedness for small initial data
    \item large initial data problem 
    \item energy critical problem $\int|\nabla u|^2$ and the mass critical problem $\int|u|^2$
\end{enumerate}
\begin{remark}
    The exponenet $p$ that we put on the RHS plays an important role int he above questions.
\end{remark}
Some topics in the foreseeable future: Littlewood-Paley theory, Bessel's problem, etc

\textbf{References}: Tao's on nonlinear and dispersive pde.

Now we will talk about Schrondinger maps
\begin{equation*}
    u: \R\times \R^n\to (M, g)
\end{equation*}
Sasy we have $u_t=i\Delta u$, then $u_t\in TM$, where $T$ stands for tangent, as we have rotated $\Delta u$ 90 degrees hence should live in the tangent of the manifold.
\begin{equation*}
    u_t=P\Delta u, P \text{ projection on } TM
\end{equation*}
The RHS $P\Delta u$ is called the heat flow. Let $M$ be a kahlan manifold.

Spherical case, $(M,g)=\mathbb{S}^2$. One can identify $\mathbb{S}^2$ as the comlex plane and compactified.
Hence if we would like an object that is perpendicular to both $u$ and $\Delta u$, and rotate by 90 degrees, then we look at the following equation
\begin{equation*}
    u_t=u\times \Delta u, u(t=0)=u_0
\end{equation*}


Then we come to the next section of the class, Quasilinear Schrondinger equations.
\begin{equation*}
    iu_t+g^{jk}(u)\partial_j\partial_k(u)=N(u, \nabla u), u(t=0)=u_0
\end{equation*}
Suppose $g^{jk}$ is a positive definite matrix, and the $N$ stands for nonlinear We will look at the local solvability. 

If we start with a simple guess, $N=\partial_j u$, and this becomes a ill-posed linear problem due to exponential growth (by taking the Fourier transform). Then we can probably repalce $N=(\nabla u)^2, N=(\nabla)^3$.

Another difficulty is how waves propogate, and ``trapping'' refers to when waves are localized eternally and do not propogate (sit in the vertical cylinder for example). This leads to the discussion of local well-posed theory.

For the \textbf{last part of the course}, we wil look at global solutions for quasilinear Schrondinger equations for small initial data, if $n\geq 3$, then somehow you can use the dispersive estimates mentioned above, via Strichartz. In higher dimension, the decay is faster, than the estimate is stronger, and the linear component plays more role. In low dimension, the nonlinear interactiosn are more prominennt. 

In $n=1$, there exists a following conjecture.
\begin{proposition}[Conjecture]
    If one has $1-d$ dispersive problem, that is cubic defocusing, then there exists a global solution for small data $u_0$.
\end{proposition}
In the case of QNLS, there is a proved theorem as above in 2023.



\section{Lecture 2}

We will now interpret the three quantities introduced above, mass, momentum and energy.

\textbf{First interpretation}
The Hamiltonian interpretation,

denote $H(u)=E(u)$, and $w(u,v)$ antisymmetric in $L^2$, and 
\begin{equation*}
    w(u,v)=\int Im(u\overline{v}), J=i
\end{equation*}
And $\partial_tu=JDH=-id\Delta u$, where $D$ is the differential form.

Given two Hamiltonians, $\{H_1, H_2\}=0$, can ask if they commute. This is to ask whether $H_1, H_2$ flows commute.

\begin{theorem}[Noether]
    Each sympletic symmetry of one Hamiltonian flow is generated by a commuting Hamiltonian.
\end{theorem}
\begin{remark}
    Sympletic refers to the solution preserving the sympletic form.
\end{remark}

$E$ generate the linear Schrodinger equation.

If we look at
\begin{equation*}
    \frac{\delta P_j}{\delta u}-i\partial_j u, \partial)t u-i\cdot i\partial_j u=-\partial_j u
\end{equation*}
This gives
\begin{equation*}
    \partial_t u+\partial u=0
\end{equation*}

This generates translations.

If we look at mass $M$, we have
\begin{equation*}
    \frac{\partial M}{\partial u}=2u, \partial_\theta u=i2u
\end{equation*}

This generates phase rotations.

We note that although mass is a conserved quantity, the mass is moving around. Hence, we associate a flux to it, i.e. a mass density. We define the mass density as follows
\begin{equation*}
    m(u)=|u|^2
\end{equation*}
And we take the time derivative
\begin{equation*}
    \partial_t m=\partial_jf_j
\end{equation*}
where $f_j$ is the mass transfer in the $j$-th direction.

\begin{equation*}
    \partial_tm=2Re(\partial_t u\cdot\overline{u})=2 Re(i\Delta u\cdot\overline{u})
\end{equation*}
Then by integration by parts, we have the above equal to
\begin{equation*}
    2Re(i\partial_j(\partial_j u\cdot\overline{u})-i\partial_ju\cdot\partial_j\overline{u})=\partial_j[2Im(\partial_ju\cdot\overline{u})]=-\partial_jp_j
\end{equation*}


We have shown that
\begin{equation*}
    \partial_jm(u)+\partial_jp_j=0
\end{equation*}
We could do similar computations for momentum.
\begin{equation*}
    \partial_tp_j+\partial_ke_{jk}=0
\end{equation*}
Where for the matrix $e_{jk}$, the trace of the matrix is equal to $e$, denoted as the energy density.
The above two equations give rise to the "Energy-momentum tensor is divergence free."?

$\begin{bmatrix}
    m & P \\
    P & e
\end{bmatrix}$
The divergence of the above matrix is equal to 0.

Solutions for the (LS).
We go back to the fundamental solution. For $u+0=\delta_0$. We have
\begin{equation*}
    \widehat{K}=e^{it\xi^2}\widehat{u}_0=e^{it\xi^2}
\end{equation*}
We thus have
\begin{equation*}
    K(t,x)=\frac{1}{(2\pi it)^{n/2}}e^{-ix^2/4t}
\end{equation*}

The dirac is Galilean invariant, and so is the fundamental solution, and $|K(t,x)|$ has to say constant due to Galilean invariance. Hence we have
\begin{equation*}
    |K(t,x)|=c_n\cdot t^{-n/2}
\end{equation*}

And we also have infinite speed of propogation, wave packets travel in all directions with the same speed, and do no discriminate different speeds.

Connection between propogation speed and frequency.
For
\begin{equation*}
    \partial_t\widehat{u}=it\xi^2\cdot u
\end{equation*}

Suppose $u$ only has frequencies close to $\xi_0$. Let's approximate $\xi$, Given
\begin{equation*}
    \xi^2=\xi_0^2+2\xi_0(\xi-\xi_0)
\end{equation*}

Approximate equation
\begin{equation*}
    \partial_t\widehat{u}=i[\xi_0^2+2\xi_0(\xi-\xi_0)]\widehat{u}=(2i\xi_0\cdot\xi-i\xi_0^2)\widehat{u}
\end{equation*}
Coming back to the physical space, we have
\begin{equation*}
    \partial_t{u}=2\xi_0\cdot\partial_xu-i\xi_0^2u
\end{equation*}
The first partial refers to the transport, and the second refers to the phase rotation.

This gives that $u(t,x)=u_0(x,x+2t\xi_0)e^{-it\xi_0^2}$. This gives the conclusion that waves with frequency $\xi_0$ now move with velocity $2\xi_0$.

(We may have a sign error, but imagine we have $\tau+\xi_0^2$), and the velocity $2\xi_0$ is called the roup velocity. If we denote $\tau+\xi^2$ as $\tau+\alpha(\xi)$ , then the group velocity is $\partial_\xi\alpha(\xi)$.

If the velocity of waves depends on frequency, we thus call this dispersive.

If I choose $u_0=e^{ix\xi_0}$, then we get
\begin{equation*}
    u(t)=e^{i(x_2t\xi_0)}\cdot e^{-it\xi_0^2}
\end{equation*}
The first part comes from the transport and the second part comes from the phase shift.

We have $\widehat{u}_0=\delta_{\xi_0}$. 

If we have $u_0=e^{-x^2/2}$, and $\widehat{u}_0=e^{-\xi^2/2}$, and $(x_0, \xi_0)=(0,0)$, and $(\delta x, \delta \xi)=(1,1)$.

Then $\widehat{u}(t,\xi)=e^{-it\xi^2}e^{-\xi^2/2}$. 

This gives
\begin{equation*}
    u(t,x)=\frac{1}{((1/2_it)2\pi)^{n/2}}e^{-x^2/(2-4it)}
\end{equation*}
Note that if $t\lesssim 1$, then it behaves nicely like a Gaussian, and if otherwise, we have waves spread out because the $4it$ term dominates.

Before a time threshold, we have the coherent state, where everything stays like a Gaussian, but becomes dispersive after some time.

Given Galilean invariance and translation invariance, we can move to $\xi_0$ and then to $x_0$. Hence now we have
\begin{equation*}
    u_0=e^{-(x-x_0)^2/2}e^{i(x-x_0)\xi_0^2}
\end{equation*}

These translations do not commute, however, it only varies our solution by a constnat factor, say $e^{i\xi_0^2}$ or something. The form of above $u_0$ is called the coherent state.

And we call the coherent state solutions, moving with velocity $2\xi_0$ as wave packets. And still $\delta x=1, \delta\xi=1$. And the time of coherent is 1, $\delta t=1$.

What if we want to change the scale, i.e. the sclaing symmetry. $(t,x)\mapsto (\lambda^2 t, \lambda x)$.

\begin{equation*}
    \delta t=T, \delta x=\sqrt{T}, \delta\xi=\frac{1}{\sqrt{T}}
\end{equation*}

By this scaling relation, We can adjust the time of the coherent state.

We can also think of LS solutions as superpositions of wave packets.

\section{Lecture 3}
We recall what we did last time.
\begin{equation*}
    (i\partial_t+\Delta)u=0, u(0)=u_0
\end{equation*}
And we have
\begin{equation*}
    u_0(x)=e^{-(x-x_0)^2/2}e^{ix_0(x-x_0)}
\end{equation*}
This refers to the coherent state, and it suffices to study $x_0=\xi_0=0$, and use translation invariance.


And note that we have $(x_0, \xi_0)$ as the center and the scales are $\delta x=1, \delta\xi=1$. 

We note this is not the only scale. We could instead have $\delta x=\sqrt{T}, \delta\xi=\frac{1}{\sqrt{T}}$, and for scale=1, we have coherent $T=1$. And for the other scale, we have the coherent time $T$ as $T$.

Now we ask the following questions:
Question: can we think of arbitrary solutions as superpositions of wave packets?

We want $u_0$= linear combination of coherent states. In other words, we now replace our typical $e^{-x^2/2}$ with any Schwartz function $\varphi$, and we have
\begin{equation*}
    u_0(x)=\varphi(x-x_0)e^{i\xi_0(x-x_0)}
\end{equation*}
Moreover, another justification to use arbitrary schwartz function is that if we are trying to solve
\begin{equation*}
    i\partial_tu-A(D)u=0, a\mapsto a(\xi)
\end{equation*}
Then there is no reason to use $u_0$ as the Gausssian $e^{-x^2/2}$ because the Gaussian does not stay Gaussian as it evolves.

We could use partition of unity. Let $\mathbb{Z}\subset\mathbb{R}^n$, we have
\begin{equation*}
    1=\sum_{j\in\mathbb{Z}^n}\chi_j(x)
\end{equation*}
And $\chi_j(x)=\chi(x-x_j)\in\mathcal{S}$. Now we have each $\chi_j$ contained in a unit cube.

And we have
\begin{equation*}
    u_0=\sum\chi_j(x)u_0=\sum_{k\in\mathbb{Z}^n}\sum_{j\in\mathbb{Z}^n}\chi_k(D)\chi_j(x)\cdot u_0
\end{equation*}
The above is called the spatial unit scale decomposition. However, this decomposition is not smooth compared to our initial form of the data.

Now we ask the question, how about a smooth wave packet decomposition.
\begin{equation*}
    u=\int f(x_0, \xi_0)u_{x_0, \xi_0}(x)dx_0d\xi_0
\end{equation*}
\begin{remark}
    The representation is not unique, and it one wishes to make this unique, they would have to have some sort of restriction on $f(x_0, \xi_0)$
\end{remark}

This is the Bargmann trnsform, or the Segal transform. If one includes the scaling, this is called FBi transform.

\begin{definition}
    Let $T$ be defined as follows: (using Gaussians)
    \begin{equation*}
        f(x_0, \xi_0)=Tu(x_0, \xi_0)=\int e^{-(x-x_0)^2/2}e^{-i\xi_0(x-x_0)}u(x)dx
    \end{equation*}
    Note we cannot hope this to be surjective, hence we have twice the amount of variables of $x_0, \xi_0$. Note we start with $x$, and end with a function in two variables.
\end{definition}

If we differentiate with respect to $\xi_0$, we get a $i(x-x_0)$ term, and if we differentiate with respect to $x_0$, we get a $(x-x_0)$ term, as well as $i \xi_0$ term, hence we have the following operator that kills the phase.
\begin{equation*}
    \left[\partial_{\xi_0}-i(\partial_{x_0}-\xi_0)\right]Tu=0
\end{equation*}

\begin{proposition}
    Such $T$ defined above, as the Bargmann transform, is an $L^2$ isometry.
    \begin{equation*}
        T*\circ T=I
    \end{equation*}
\end{proposition}


We define a slightly different transform:
\begin{equation*}
    \tilde{T}u(z)=\int e^{-1/2(x-z)^2}u(x)dx, z=x_0-i\xi_0
\end{equation*}
And now we have
\begin{equation*}
    \tilde{T}: L^2\to L^2(e^{-\xi_0^2})
\end{equation*}


\begin{definition}
    The FBi transform is simply a recaled version of the Bargmann transform.
    \begin{equation*}
        T_\lambda u(x_0, \xi_0)=\int e^{-(x-x_0)^2/2\lambda}e^{-i\xi_0(x-x_0)}u(x)dx
    \end{equation*}
\end{definition}
Now we have $\Delta x=\sqrt{\lambda}$, and $\xi=1/\sqrt{\lambda}$.

We have
\begin{equation*}
    u_0=\sum_{x_0, \xi_0\in\mathbb{Z}^n}c_{x_0, \xi_0}u_0^{x_0, \xi_0}
\end{equation*}
Then we have
\begin{equation*}
    u=\sum c_{x_0, \xi_0}e^{-itD^2}u_0(x_0, \xi_0)
\end{equation*}
The above is the solution to the linear Schrondinger. This is useful up to time 1, and it is viewed as a superposition of wave packets.

We shall approximate wave packets, we have $u_0$ localized at $(x_0, \xi_0)$. We approximate the solution as follows:
\begin{equation*}
    u(x,t)\sim u_0(x-2t\xi_0)e^{it\xi_0^2}
\end{equation*}
If we start with $e^{i(x-x_0)\xi_0}$, then roughtly it is $e^{i(x-2t\xi_0-x_0)}\xi_0$, where $\xi\sim\xi_0$, and $\tau\sim-\xi_0^2$. 

Then $u$ is a good approximate solution, you can verify this by 
\begin{equation*}
    (i\partial_t+\Delta)u\sim O(1)
\end{equation*}
However, this error adds up and is acceptable if $t<< 1$. Especially if you have nonhomogenous equation, the error adds up as time progresses.

We have
\begin{equation*}
    u(t,x)=\sum_{x_0,\xi_0}c_{x_0, \xi_0}u_0(x-2t\xi_0)e^{it\xi_0^2}
\end{equation*}
And this is a good approxiamte solution up to time 1.

\begin{remark}
    We note that the composition here is almost orthogonal, hence we have different frequencies, just like we had agove when we had $u=\sum c_{x_0,\xi_0}e^{-itD^2}u_0(x_0, \xi_0)$
\end{remark}

In the constant coefficient case, you start with $(x_0, \xi_0)$, at $t=0$, you end up at $(x_0+2\xi_0, \xi_0)$
But in variable coefficients, you have
\begin{equation*}
    (x_0, \xi_0)\to (x_t, \xi_t)
\end{equation*}
We no longer move in the linear fashion.

We now explore the case where we don't assume infinitely many derivatives. 

Let's consider wave packets with less localization. Simply consider the case at $(0,0)$ and use translation invariance and Galilean symmetry.

Take $u_0\in L^2$, what does it mean for this to be localized at (0,0)?

One proposition could be
\begin{equation*}
    x\cdot u_0\in L^2
\end{equation*}
This means as long as you move away from (0,0), $u_0$ decays. And we would also like to have decay in frequence, hence
\begin{equation*}
    \partial_xu_0(x,\xi)\in L^2
\end{equation*}
The above implies decay in $\xi$. Together they imply the solution $u$ is localizated at $(0,0)$ up to time $O(1)$.

If you wish it to localize at $(x_0-2t\xi_0, \xi_0)$, then we can have
\begin{equation*}
    (x-x_0-2t\xi_0)u\in L^2, [D_x-\xi_0]u_0\in L^2
\end{equation*}

By energy estimates, we have if $u$ solves the equation, then $D_xu$ also solves the equation, we have
\begin{equation*}
    \|D_xu\|_{L^2}=\|D_xu(0)\|_{L^2}
\end{equation*}
So it remains to consider $xu$, and how it interacts with the equation. We have
\begin{equation*}
    (i\partial_t+\Delta)x_ju=x_j(i\partial_t+\Delta)u+2\partial_ju
\end{equation*}
And the first term is 0, hence we have
\begin{equation*}
    \frac{d}{dt}\|xu\|_{L^2}^2=Re\int 2\overline{u}\partial_j udx=O(1)
\end{equation*}
Then we have $\overline{u}\in O_{L^2}(1), \partial_j u\in O_{l^2}(1)$, hence the entire term is of $O(1)$ in $L^2$.

Recall the fundamental solution of linear Schrondinger equation.
\begin{equation*}
    K(t,x)=\frac{1}{(4\pi it)^{n/2}}e^{ix^2/4t}, |K|\lesssim t^{-n/2}
\end{equation*}
Hence we have $u(t)=K(t)\ast u_0$. 
And we have the dispersive estimate for linear Schrondinger
\begin{equation*}
    \|u(t)\|_{L^\infty}\leq\|K(t)\|_{L^\infty}\|u_0\|_{L^1}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}

Dispersive estimates via stationary phase.

Let's generalize to variable coefficents.
\begin{equation*}
    (i\partial_t+A(D)\Delta)u=0
\end{equation*}
And our solution is of the form
\begin{equation*}
    u(t)=e^{itA(D)}u(0)
\end{equation*}
and
\begin{equation*}
    K(t)=\int_{\R^n}e^{ix\xi}e^{-ita(\xi)}d\xi
\end{equation*}

We have the oscillatory integral
\begin{equation*}
    I_\lambda=\int e^{i\lambda \varphi(\xi)}a(\xi)d\xi
\end{equation*}
Where we assume $a(\xi)$ having compact support.


And the value of the integral depends on the stationary points, defined by $D\varphi=0$.

If there are no stationary points, then we get
\begin{equation*}
    |I_\lambda|\leq \lambda^{-N}
\end{equation*}

Replace $\varphi$ with a quadratic expansion, and ``replace'' with a Gaussian. If we have nondegenerate points, $D\varphi\neq 0$. We have
\begin{equation*}
    |I_\lambda|\leq\lambda^{-n/2}
\end{equation*}
It's like putting $\varphi$ in $n-1$ dimension and operate with separation of variables.

We now examine our solution to the Schrondinger equation, and find the critical points here. We differentiate with respect to $x_j$
\begin{equation*}
    x_j+t\partial_{\xi_j}a(\xi)=0
\end{equation*}
We have
\begin{equation*}
    v\sim x/t=a_\xi
\end{equation*}
where $a_\xi$ is our previous group velocity.

The nondegenerate points are characterized as nonvanishing Hessian, which is $\sim D^2a$.
\begin{definition}
    The nondegenerate points are defined by the Hessian $\sim D^2a$, being a nondegenerate matrix.
\end{definition}
In LS, we have
\begin{equation*}
    a=\xi^2, D^2a=2I
\end{equation*}

Now we introduce a third way of viewing dispersive estimates, which is via \textbf{wave packets}.

We first note that the dispersive estimate
\begin{equation*}
    \|u\|_{L^\infty}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}
is scale invariant.  Hence it suffices to focus at $t=1$.

Let's take
\begin{equation*}
    u_0=\delta_0=\sum_{x_0,\xi_0\in\mathbb{Z}^n}c_{x_0, \xi_0}\varphi_{x_0, \xi_0}
\end{equation*}
we have
\begin{equation*}
    u_0=\sum\chi_j(x)u_0=u_0
\end{equation*}
And we want to localize frequency
\begin{equation*}
    \widehat{u_0}=\widehat{\delta_0}=1=\sum_{k\in\mathbb{Z}^n}\chi_k(\xi)
\end{equation*}
We have the $\|\chi_k\|_{L^2}=1$, and this says the Fourier coefficents are of $O(1)$.

Then
\begin{equation*}
    u=\sum_{x_0=0,\xi_0\in\mathbb{Z}^n}c u_{x_0, \xi_0}
\end{equation*}
At time $t=1$, we get one of the wave packet each, hence we have
\begin{equation*}
    |K(t=1)|\leq \sup_{\xi_0}|u_{x_0,\xi_0}|=1
\end{equation*}
\begin{remark}
    This no longe words for $t<<1$, hence there exists overlappings now. But to fix this, we rescale $\delta x=\sqrt{T}$, to get smaller and thinner tubes, nonoverlapping at time $T$.
\end{remark}

Now we ask the question, what is the good way to measure dispersive decay for $u_0\in L^2$.

\textbf{A1}: there is no uniform decay bound of the form
\begin{equation*}
    \|u(t)\|_{Sobolev}\leq C(t)\|u_0\|_{L^2}, \lim_{t\to\infty}C(t)=0
\end{equation*}

This is because $\|u(t)\|_{L^2}=\|u_0\|_{L^2}$, and taking $t$ infinitely large, $C(t)$ tends to 0, and we would get 
\begin{equation*}
    \|u\|_{sobolev}\leq 0, t\to\infty
\end{equation*}

Next time, we will talk about Strichartaz estimates, not in a uniform way, but in an average sense of $\|u\|_{L_t^pL_x^2}$. 


\section{Lecture 4}
We will talk about Strichartz estimates this time. Suppose $u$ is a solution to 
\begin{equation*}
    iu_t+\Delta u=0, u(0)=u_0
\end{equation*}
We ask if there exists a following bound
\begin{equation*}
    \|u\|_{L_{t,x}^p}\lesssim \|u_0\|_{L_x^2}
\end{equation*}
We cannot expect to use the same exponents for $t,x$ hence we will attempt to put $L_t^pL_x^q$ instead.

Note we can also interchange the role of $t,x$, which are probably called maximal inequalities, but for now, we stick to this order for $t,x$. Sobolev embeddings in $\R^n$ also relates $L^p$ norms with $L^2$, such as
\begin{equation*}
    \|u\|_{L^p}\lesssim \|u\|_{\dot{H}^s}=\||D|^su\|_{L^2}
\end{equation*}
except having derivatives on the RHS. Hence in general, we look for inequalities of the form
\begin{equation*}
    \|u\|_{L_t^pL_x^q}\lesssim \||D|^su_0\|_{L^2}
\end{equation*}
Before trying to figure out the indices $p,q,s$, we first note the symmetries of the Schrodinger equations. We use the scaling symmetry first. In other words, we want both spaces invariant under the transformation
\begin{equation*}
    u(t,x)\mapsto u(\lambda^2t, \lambda x)
\end{equation*}
We end up with the following scaling relation.
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}-s
\end{equation*}
The other piece of information can be derived from wave packets and the Galilean symmetry. What we saw last time is that we can produce wave packets $u_p\approx 1$ of size 1 in a rectangle $(T^{1/2})^\times T$, where $T^{1/2}$ is the spatial $\delta x$, and $\delta t\approx T$. The dual scale is $\delta\xi\approx T^{-1/2}$ due to the uncertainty principle. We can put $\delta\xi$ to localize at anywhere in the Fourier space, so if we restrict to $|\xi|\approx 1$, then we would want $\delta\xi\ll 1$, hence $T\gg 1$. This implies the following relationship:
\begin{equation*}
    T^{\frac{1}{p}}T^{\frac{n}{2q}}\lesssim T^\frac{n}{4}
\end{equation*}
for $T\gg 1$. Hence in fact we have
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}\leq\frac{n}{2}
\end{equation*}
If you were to compare these two, then $s\geq 0$. We thus name them:
\begin{enumerate}
    \item sharp Strichartz: $s=0$
    \item non-sharp Strichartz: $s>0$
\end{enumerate}
From the sharp to non-sharp, we will use Sobolev embeddings. Though it seems like the derivation with $s$ included is redundant, if you take wave equations or the KDV equations instead, then there exists a number of derivatives $s$ there for these kinds of Strichartz estimates.

\subsection{Strichartz estimates, restriction theorems in Harmonic analysis}
We will now focus on $\widehat{u}=\delta_{T=-|\xi|^2}\widehat{u_0}(\xi)$, which are $L^2$ measures on the paraboloids.
\begin{equation*}
    \widehat{u_0}\mapsto\mathcal{F}^{-1}\delta_{\tau=-|\xi|^2}\widehat{u_0}: L^2\to L_t^pL_x^q
\end{equation*}
The adjoint operator is $f\mapsto (\mathcal{F}_{t,x}f)\vert_{\tau=-|\xi|^2}: L^{p'}L^{q'}\to L^2$, trace of this Fourier transform on the paraboloids, we want it to be from $L^{p'}L^{q'}\to L^2$.

Strichartz estiamtes $L^2\to L^pL^q$, the second one is called the restriction theorem. In PDE's, we are looking for $L^2$ and harmonic analysts want to change $L^2$ to other exponents and look for the range of it, and don't care about different exponents $p', q'$, hence choosing them to be equal. 

Also, in harmonic analysis, one may not only consider the case for paraboloids.
\begin{enumerate}
    \item sphere: Stein-Thomas theorem, 70s
    \item cone: Strichartz, 80s
    \item paraboloids, 80s
\end{enumerate}
\begin{remark}
    All the above shapes considered have nonvanishing curavture, both sphere and hyperboloids have maximal number of nonvanishing curvature while the cone has one less.
\end{remark}

\subsection{Visualization, $p\geq 2$}
Before we prove anything, we make one more observation. We look at the scaling relationship:
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}
\end{equation*}
When $n=1$, we draw a graph with $1/p-1/q$ coordinates. The $L^\infty L^2$ endpoints is invariant regardless of the dimension, due to the $L^2$ norm being preserved. When $n\geq 3$, one of the endpoints is $\frac{4}{n}$, which might be less than 1.

What if we try to construct various wave packets $u_j$ of size 1 inductively (where each is far away from the previous ones both in space and frequency)? If we measure $u=\sum c_ju_j$, then 
\begin{equation*}
    \|u\|_{L^2}^2=\sum_jc_j^2
\end{equation*}
However, we also have
\begin{equation*}
    \|u\|_{L^pL^q}^p=\sum c_j^pl^2
\end{equation*}
which controls $l^p$, hence we would want $p\geq 2$. 

For $n=1$, we have the full range. For $n=2$, we have one forbidden endpoint; for $n=3$, we only care about the RHS of the shadow region, and we also have endpoint estimates.

\subsection{$T^*T$-method}
Last time, we proved the following dispersive estimates:
\begin{equation*}
    \|e^{itD^2}u_0\|_{L^\infty}\lesssim t^{-n/2}\|u_0\|_{L^1}
\end{equation*}
We want $u_0\to e^{itD^2}u_0$ is $L^2\to L^pL^q$. Combining with the trivial $L^2$ bound (isometry), we interpolate them to obtain the following
\begin{equation*}
    \|e^{itD^2}u_0\|_{L^p}\lesssim t^{-\frac{n}{2}(\frac{1}{p'}-\frac{1}{p})}\|u_0\|_{L^{p'}}
\end{equation*}
note that the exponent of $t$ is determined by scaling. Note this holds for $(L^1)'=L^\infty$, and $(L^2)'=L^2$.

Let us denote the operator $T: u_0\to e^{itD^2}u_0$. (The LHS has duality in $n$-dim, the RHS has duality in $n+1$-dim). Having this operator from $L^2\to L^pL^q$ is the same as having the dual operator:
\begin{equation*}
    T^*: f\mapsto \int e^{-itD^2}f(t)dt, T^*: L^{p'}L^{q'}\to L^2
\end{equation*}
A fundamental result in functional analysis is that $T$ is bounded if and only if $T^*$ is bounded.

\begin{definition}[$TT^*$-method]
    Given $T: L^2\to L^pL^q$, we consider the following operator:
    \begin{equation*}
        TT^*: L^{p'}L^{q'}\to L^pL^q
    \end{equation*}
    We have $T$ is bounded if and only if $T^*$ is bounded, if and only if $TT^*$ is bounded.
    \begin{equation*}
        \langle TT^*(f), g\rangle=\langle T^*(f), T^*(g)\rangle
    \end{equation*}
    where $g\in L^{p'}L^{q'}$, and taking $f=g$, we have
    \begin{equation*}
        \|T^*(f)\|_{L^2}^2\lesssim \|f\|_{L^pL^q}^2\|TT^*\|
    \end{equation*}
    This is called the $TT^*$ argument.
\end{definition}
\begin{remark}
    The essence of this method is that one of the spaces is $L^2$.
\end{remark}

We write
\begin{equation*}
    TT^*(f)(t)=e^{itD^2}T^*f=\int_\R e^{i(t-s)D^2}f(s)ds
\end{equation*}
where $t,s$ are arbitrary instead of the actual fundamental solution for the Schrodinger equation. So 
\begin{equation*}
    \|TT^*(f)\|_{L^q}\lesssim\int_\R|t-s|^{-\frac{n}{2}(\frac{1}{q'}-\frac{1}{q})}\|f(s)\|_{L^{q'}}ds
\end{equation*}
By Young's inequality, we have the exponents
\begin{equation*}
    \frac{n}{2}\left(\frac{1}{q'}-\frac{1}{q} \right)\in (0,1)
\end{equation*}
hence $2<p<\infty$. 

\begin{remark}
    The convolution with $1/|t|: L^2\to L^2$ is not true for Young's inequality, hence in Hilbert transform, we want to use p.v. instead of absolute value.
\end{remark}

So far, we have looked at only homogeneous euqations. For inhomogeneous ones, i.e. $iu_t+\Delta u=f$, we can write the solution into two components,
\begin{equation*}
    u(t)=e^{itD^2}u_0+\int_0^te^{i(t-s)D^2}f(s)ds
\end{equation*}
which is the standard Duhamel's formula. For the first component, we know the mapping property from $L^2$. For the second one, if we want $u\in L_t^\infty L_x^2$, it is enough to fix $t$, then we look at the map
\begin{equation*}
    f\mapsto \int_0^te^{i(t-s)D^2}f(s)ds
\end{equation*}
We want to compare this with the operator $T^*$. In fact, the time range 0 to $t$ does nothing, so this maps from $L^{p'}L^{q'}\to L^2$. You might conjecture the correct form for the estimates are
\begin{equation*}
    \|u\|_s\leq\|u_0\|_{L^2}+\|f\|_{s'}
\end{equation*}
where $s$ is our favorite Strichartz norm. We have proved the case for $f=0$. Also, when $f\neq 0$, we also proved for $s=L^\infty L^2$. However, the nontrivial Strichartz norms can also be proved. In fact, we have more general forms:
\begin{equation*}
    \|u\|_{L^pL^q}\lesssim \|f\|_{L^{p_1'}L^{q_1'}}
\end{equation*}

For forward problems,
\begin{equation*}
    u(t)=\int_{-\infty}^t e^{i(t-s)D^2}f(s)ds
\end{equation*}
is a convolutional operator and the kernel for this is 
\begin{equation*}
    1_{t\geq s}e^{i(t-s)D^2}
\end{equation*}
where restricting $1_{t\geq s}$ also means you are viewing the forward problem. Note that the difference between this and the kernel for $TT^*$  operator is that the kernel for $TT^*$ is $e^{i(t-s)D^2}$ without restriction.

\subsection{Christ-Kiselev Lemma}
We now state a classical lemma:
\begin{lemma}[Christ-Kiselev]
    Suppose the operators
    \begin{equation*}
        L: f\mapsto \int K(t,s)f(s)ds, L^r: f\mapsto \int_{t\geq s}K(t,s)f(s)ds
    \end{equation*}
    which satisfy $L: L^{p_1}\to L^{p_2}$, then if $p_1<p_2$, then we have
    \begin{equation*}
        L^r: L^{p_1}\to L^{p_2}
    \end{equation*}
\end{lemma}
\begin{proof}
    For $1_{t\geq s}$, and $t,s\in [0,1]$, a rectangle $R$ is easy to manipulate since $1_R=1_{t\in I}\times 1_{s\in J}$. However for $t\geq s$, it is not a rectangle.

    The problem of choosing this: we cannot ensure the same amount of $f$ being split inot different intervals. Instead of making a equipartition of the interval, we split the intervals containing the same amount of $f$. Assume $\|f\|_{L^{p'}}=1$, and $[0,1]_s=I_0\cup I_1$ such that $\|f\|_{I_0}=\|f\|_{I_1}=\frac{1}{2^{p_1}}$. Then we split to $I_0=I_{00}\cup I_{01}$.

    Hence we write
    \begin{equation*}
        I_{t\geq s}=\cup_k\cup_{R\in R_k}I_R\times J_R
    \end{equation*}
    where $k$ tells us which layer we are at, and $R_k$ are rectangles at level $k$. All disjoint, both horizontally and vertically. We want to write $L^r(f)=\sum_k\sum_{R\in R_k}1_{I_R}L1_{J_R}f$, where we want to estimate for each $k$,
    \begin{equation*}
        \sum_k\sum_{R\in R_k}1_{I_R}L1_{J_R}f:=\sum_k L_k^rf
    \end{equation*}
    In each layer, we gain something in size. Our claim is that 
    \begin{equation*}
        \|L_k^r\|\lesssim 2^{1/p_2-1/p_1}k
    \end{equation*}
    then this sums in a good way. We know the size $1_{J_R}f$ and mapping property of $L$. For $1_{I_R}'s$. they are disjoint, so the $L^q$ norms add nicely. By composing these three, we get the desired result.
\end{proof}
\qed



This will not cover the double endpoint case where $p=p'=2$. Once you have bounds $TT^*$, you can consider $T,T^*$, to vary $q, q_1'$ to have two different pair of admissible $(p,q)$ and $(p_1, q_1)$. 

Note it is easy to handle the direction from $1_{t\geq s}e^{i(t-s)D^2}$ to $e^{i(t-s)D^2}$ just by time reversal. We just handle two parts and add them together but this is not the direction that we want.

By next time, this C-K will become obselete in the context of the Schrodinger equation. In $n\geq 3$, we need to discuss the endpoint case.

\subsection{The forbidden endpoint in $n=2$}
We start with $n\geq 2$. The endpoint when $n\geq 3$ is resolved by Keel-Tao in 1996. When $n\geq 3$, the endpoint case is
\begin{equation*}
    \mathcal{S}=L_t^2L_x^\frac{2n}{n-2}
\end{equation*}
There is not much difference from looking at the inhomogeneous or homogeneous operator. We consider
\begin{equation*}
    f(s)\mapsto \int e^{i(t-s)D^2}f(s)ds, L^2L^\frac{2n}{n+2}\to L^2L^\frac{2n}{n-2}
\end{equation*}
where the integral is over $\R$ or $t>s$ dependeing on inhomogeneous or homogeneous case. To avoid writing notations, we note $q_c=\frac{2n}{n-2}$, the difficulty is that
\begin{equation*}
    \|e^{it D^2}\|_{L^{q_c'\to L_{q_c}}}\lesssim\frac{1}{t}
\end{equation*}
where the convolution with $\frac{1}{t}$ does not have the mapping property $L^2\to L^2$, so we cannot apply Young's inequality in this case directly. This is also the reason why the endpoint case fails is dimension 2 (forbidden endpoint) since the kernel $K(t,x=0)=\frac{1}{t}1_{t\geq 0}$.

If we focus on the integral over domain over $\R$, then it is just the $TT^*$ operator, which is expected to have the mapping property $L^2L^1\to L^2L^\infty$ in dimension 2.

Suppose by contradiction that it is, then one looks at $*K; L^2L^1\to L^2L^\infty$, $f(t)\delta_{x=0}\to u(t,x=0)$, where $\delta_{x=0}$ can be chosen to be a limit of $L^1$ functions.
\begin{equation*}
    u(t,x=0)=\left(\frac{1}{t}1_{t\geq 0} \right)\ast f(t)
\end{equation*}
where does not map $L_t^2\to L_t^2$. Also, the first term, if one tries to make sense of it as a distribution, then its Fourier transform will not have a log component on it.

However, $\ast\frac{1}{t}:L^2\to L^2$, which is called the Hilbert transform.

\section{Lecture 5}
\subsection{Endpoint case when $n=3$}
We prove the case in $n\geq 3$ by restricting $t$ to $t\approx 2^j$
\begin{equation*}
    \frac{1}{t}1_{t\approx 2^j}\in L^1
\end{equation*}
To ge from fixed dyadic scale to various ones, we draw a picture.
Suppose we focus on the case $t>s$, unlike the proof of CK lemma, we want to split inot equal pieces. We write
\begin{equation*}
    T=\sum_j T_j, T_j=\sum_{Q\in 2_j}1_Q\cdot e^{i(t-s)D^2}
\end{equation*}
where we let the output restricted to $Q$. In $Q_j$, $t-s\approx 2^j$. Using notations from last time, we have
\begin{equation*}
    1_Q\cdot e^{i(t-s)D^2}=1_{I_q}(t)1_{J_Q}(s)e^{i(t-s)D^2}
\end{equation*}
so we can apply Young's inequality:
\begin{equation*}
    \|T_j\|_{L^2L^{q_c'}\to L^2L^{q_c}}\lesssim 1(R)
\end{equation*}
which is called the restricted inequality. Now we want to add up different pieces but we cannot so far.

In $(R)$, we cannot sum up. The idea of Keel-Tao is to expand the restricted inequality. We not only have this for $T_j$, instead of thinking of these as a linear operator $L^2L^{q_c'}\to L^2L^{q_c}$, we test the element in the dual space.
\begin{equation*}
    f\mapsto T_jf
\end{equation*}
changes to
\begin{equation*}
    \langle f,g\rangle \mapsto \langle T_jf, g\rangle
\end{equation*}
The restricted inequlaity $(R)$ tells us
\begin{equation*}
    |\langle T_jf, g\rangle|\leq\|f\|_{L^2L^{a_c'}}\|g\|_{L^2L^{q_c'}}
\end{equation*}
and what we want is to have
\begin{equation*}
    \sum_j|\langle T_jf, g\rangle|\leq \|f\|_{L^2L^{q_c'}}\|g\|_{L^2L^{q_c'}}
\end{equation*}
which is praphrased into a bilinear setting instead of a linear fashion. This idea is useful in nonlinear PDE's. You can match the properties of $f$ with properties of $g$ in some sense and to play with.

As an intermediate step, we are going to have $(E)$.
\begin{equation*}
    |\langle T_jf, g\rangle|\leq 2^{j\beta(q_1,q_2)}\|f\|_{L^2L^{q_1}}\|g\|_{L^2L^{q_2}} (E)
\end{equation*}
the scale of rectangle will be changed if you change the scaling, so this can hold if one puts a factor in front. The factor contains a function $\beta$, which is nontrivial and linear in $1/q_1$ and linear in $1/q_2$. $\beta$ is also symmetric and is zero when $q_1=q_2=q_c$. So $\beta(q_1, q_2)$ is of the form $c(1/q_1+1/q_2-2/q_c)$.
\begin{proof}[E]
    We want to have enough points so that the convex hull contains the point $(1/q_c, 1/q_c)$ so that we can obtain the desired result by interpolation.

    Since $|K(t,x)|\leq 1/t^{n/2}$, it maps $L^2L^1\to L^2L^\infty$ and mapping $L^2$ to $L^2$ since we are in a finite interval $(q_1'=1, q_2=\infty)$.

    On the other hand, we want to use the nonendpoint estimates
    \begin{equation*}
        \langle T_jf, g\rangle \leq\|f\|_{L^{p_1'}L^{q_1'}}\|g\|_{L^{p_2'}L^{q_2'}}
    \end{equation*}
    Also we can restrict to intervals $t-s\approx 2^j$, and in such intervals, we can replace $p_1', p_2'$ by 2 using Holder inequality.
    \begin{equation*}
        \langle T_jf, g\rangle\leq 2^j\|f\|_{L^2L^{q_1'}}\|g\|_{L^2L^{q_2'}}
    \end{equation*}
    which holds for all $2\leq q_1,q_2\leq<q_c$.

    Now we know $l_j^\infty$ estimates and we want $l_1^j$ estimates, interpolation theory would allow to replace $l^\infty$ by $l^1$, where one can find in Bergh-Loefstrom/ Triebel.

    We can think of this in a concrete way. We look at spatial support of $f,g$:
    \begin{equation*}
        f=f_k(t)1_{I(t)}, g=g_l(s)1_{J(s)}, |I(t)|=2^k, |J(t)|=2^l
    \end{equation*}
    We thus have
    \begin{equation*}
        \|f\|_{L^2L^{q_1'}}=\|f_k\|_{L^2}e^{k/q_1'},  \|g\|_{L^2L^{q_2'}}=\|g_l\|_{L^2}e^{l/q_2'}
    \end{equation*}
    (E) implies
    \begin{equation*}
        |\langle T_jf, g\rangle|\leq 2^{j\beta(q_1,q_2)}\|f\|_{L^2L^{q_1}}\|g\|_{L^2L^{q_2}}\leq 2^{j\beta(q_1,q_2)}\|f_k\|_{L^2}e^{k/q_1'}\|g_l\|_{L^2}e^{l/q_2'}
    \end{equation*}
    We write $f=\sum f_k(t)1_{I_k(t)}, g=\sum g_l(s)1_{J_l(s)}$, and apply the upgraded version of estimate above to obtain. Last task: to decompose
    \begin{equation*}
        f=\sum f_k1_{I_k}, |I_k|=2^k, \|f\|_{L^{q'}}^{q'}\approx 2^k\|f_k\|_{L^\infty}^{q'}
    \end{equation*}
    suppose $f\in\R^+$ by replacing to $|f|f\to f^*$ a nondecreasing rearrangement of $f$, where the way to choose $F^*$ is
    \begin{equation*}
        |\{f^*\geq\lambda\}|=|\{|f|\geq\lambda\}|
    \end{equation*}
    Here, the dyadic decomposition is done on the base.
    \begin{equation*}
        |\langle T_jf, g\rangle|\leq \|(\|f_k2^{k/{q_c'}}\|_{l_k^2})\|_{L_t^2}\|(\|g_l2^{l/{q_c'}}\|_{l_l^2})\|_{L_t^2}
    \end{equation*}
    where we interchange $l, L^2$ and apply the estimate obtained from rearrangements and then we take advantage of $q_c'<2$, so we have $l^{q_c'}\subset l^2$.

    Strichartz estimates are sharp for wave packets, and no other things make these sharp.
\end{proof}


\section{Lecture 6}
We look at the Schrodinger equation $iu_t+\Delta u=f, u(t=0)=u_0$. Last time, we looked at Strichartz estimates:
\begin{equation*}
    \|u\|_S\leq \|u_0\|_{L^2}+\|f\|_{S'}
\end{equation*}
where $S=\cap_{(p,q)}L_t^pL_x^q$, is the Strichartz norm, where the exponents satisfy the scaling relation, $2/p+n/2=n/2$. 

Note that if $u\in C(L^2)$, then $u\in S$. The first thing we note that the Strichartz estiamtes are not specific to the Schrodinger equation, but rather, we can apply it to the more general setting:
\begin{equation*}
    i\partial_t u+A(D)u=f
\end{equation*}
we need $a(\xi)$ to have dispersive relation, and $\partial^2a$, i.e. the Hessian, nondegenerate.

Back to linear Schrodinger. In $n=1$, if we draw the dispersive relation of the Schrodinger (Figure 1). The idea now is to exchange the role of $t$ and $x$. We get 
\begin{equation*}
    \tau+\xi^2=0\Rightarrow \xi=\pm\sqrt{-\tau}
\end{equation*}
Hence we now obtain two solutions $u_R, u_L$, and we take $u=u_L+u_R$.
\begin{equation*}
    (i\partial_x-\sqrt{-D_\tau})u^R=0, (i\partial_x-\sqrt{-D_\tau})u^L=0
\end{equation*}
Recall the (lateral) Strichartz estimates:
\begin{equation*}
    \||D_x|^Su\|_{L_x^pL_t^q}\leq\|u_0\|_{L^2}
\end{equation*}
Note that for the Schrodinger equation, we do not have any derivatives on the LHS, however, derivatives should arise when we change different $p,q$. 

Recall the curvature relation: (we are still in $n=1$)
\begin{equation*}
    \frac{2}{p}+\frac{n}{q}=\frac{n}{2}
\end{equation*}
Now the scaling relation, time counts as two space dimension, hence
\begin{equation*}
    \frac{1}{p}+\frac{2}{q}-s=\frac{1}{2}
\end{equation*}

If we take $(p,q)=(\infty,2)$, then $s=1/2$. This is one endpoint, and this is a gain. The other endpoint, $(p,q)=(4,\infty)$, we have $s=-1/4$, which is a loss.

\begin{proposition}
    By lateral Strichartz estimates, we have the following:
    \begin{equation*}
        \|D^{1/2}u\|_{L_x^\infty L_t^2}\leq\|u_0\|_{L^2}
    \end{equation*}
    \begin{equation*}
        \|D^{-1/4}u\|_{L_x^4 L_t^\infty}\leq\|u_0\|_{L^2}
    \end{equation*}
\end{proposition}


What happens when $n>1$? We gain have
\begin{equation*}
    \tau+\xi^2=0
\end{equation*}
Choose one distinct direction $\xi_1$, and $x_1$ as the evolutionary variable.
\begin{equation*}
    \tau+\xi_1^2+(\xi')^2=0 \Rightarrow \xi_1=\pm\sqrt{-\tau-(\xi')^2}
\end{equation*}
Note the RHS can vanish now, which creates problems. In other words, previously, $\xi$ or $\xi_1$ could not be 0, since it would require $\tau=0$ as well. Now if we are unlucky, and $\xi_1=0$ for some choice of $\tau, \xi'$, then there are waves that do not travel in the $x_1$ direction. (Figure 4)

In figure 5, we avoid this issue by restricting our solution to a cone, for example. Hence if we only look at solutiosn located in this region, we get
\begin{equation*}
    u\to P_1(D)u
\end{equation*}
we have a solution that is dispersive in the $x_1$ direction. Apply the lateral Strichartz estimates:
\begin{equation*}
    \||D_x|^sP_1u\|_{L_{x_1}^pL_{x',t}^q}\leq\|u_0\|_{L^2}
\end{equation*}
Note that we have the same curvature relation, but for the scaling relation, we have (since time acts as two variable and $x'$ has $n-1$, hence get $n+1$ for the second term)
\begin{equation*}
    \frac{1}{p}+\frac{n+1}{q}-s=\frac{n}{2}
\end{equation*}

\begin{remark}
    We make note that there exists gain and there exists loss, since one can always take $p=q$, which is a middle point. And this is like the Strichartz estimate that we had before, where we have no derivatives.
\end{remark}

\begin{proposition}
    We have the more refined lateral Strichartz estimates where we have gains and losses;
    \begin{equation*}
        \|D_x^+u\|_{L_x^\infty L_t^2}\leq\|u_0\|_{L^2}
    \end{equation*}
    Note that this one has nothing to do with dispersion, due to $L^2$ norm being perserved.
    \begin{equation*}
        \|u\|_{L^pL^p}\leq \|u_0\|_{L^2}
    \end{equation*}
    This one does not see direction of travel, and it only sees curvature.
    \begin{equation*}
        \|D_x^- u\|_{L_x^2L_{x',t}^q}\leq\|u_0\|_{L^2}
    \end{equation*}
    This also depends on the curvature
\end{proposition}
\begin{remark}
    We say it depends on curvature when it does not depend on the angular decomposition like in Figure 5. And thus the middlepoint, the bottom endpoint does not depend on the angular decay.
\end{remark}

Note there is something missing in the Strichartz estimates that need to be compensated for having something else.

Note that $L_x^p L_t^q$ are spaces that are invariant to translations and phase shifts.
\begin{equation*}
    \|u\|_{L^pL^q}=\|e^{ix\xi}u\|_{L^pL^q}
\end{equation*}
However, the phase shift generated by multiplying $e^{ix\xi}$ changes where the solution lies in the Fourier space. In other words, the Strichartz estimates do not see where the solution lies in the Fourier space.

\begin{equation*}
    i\partial_t u+\Delta u=u^2=u\cdot u
\end{equation*}
where the first $u$ localized in $\xi_1$, and second $u$ localized in $\xi_2$. We multiply them together, hence get a convolution in the Fourier space, $(\xi_{11}-\xi_1^2), (\xi_{21}-\xi_2^2)$. Then we would add these to up due to convolution. And note that for paraboloids, which are convex, hence adding two points on the characteristic set would give you a point strictly inside the paraboloid.

Now Bourgain.
\begin{equation*}
    \Delta u=f, \dot{H}^s, |\xi|^s
\end{equation*}
And our characteristic set $\tau+\xi^2=0$, we use $|\tau+\xi^2|^b$, and $|\xi|^s$, where $|\tau+\xi^2|^b$ is the distance from the characteristic set in the verticle direction.

\begin{definition}[Bourgain space]
    We define a norm as follows:
    \begin{equation*}
        \|\widehat{u}\cdot|\xi|^s|\tau+\xi^2|^b\|_{L^2}=\|u\|_{\dot{X}^{S,b}}
    \end{equation*}
\end{definition}
\begin{remark}
    $s$ refers to the intial data regularity, $u_0\in H^s$. and $b$ refers to the Sobolev regularity away from the chraactersitic set.
\end{remark}
Let's now interpret $b$. Fix $|\xi|=1$, and set $s=0$.
\begin{equation*}
    \widehat{u}\cdot |\tau+\xi^2|^n=f, \text{ where } f\in L^2
\end{equation*}
Does this definition make sense?
\begin{equation*}
    \widehat{u}=\frac{f}{|\tau+\xi^2|^b}
\end{equation*}
If we ignore $\xi$, i.e., $L^2/\tau^b$, and $L^2$ is closed under multiplication of two $L^2$ functions, hence this makes sense as long as $1/\tau^b\in L^2$, i.e. $b<1/2$. This gives an upperbound for $b$. Does there exist a lower bound?

If $b<0$, then $\widehat{u}$ vanishes on $\tau+\xi^2=0$. Hence the worst $f$ you could have is
\begin{equation*}
    f\approx |\tau+\xi^2|^{-\frac{1}{2}+}
\end{equation*}
If the exponent goes below $-1/2$, then $f\not\in L^2$. Hence $b\geq -1/2$.

To sum up, we have two choices: in homogeneous spaces, we require $-1/2<b<1/2$;  in inhomogeneous spaces, there is not restriction. We also consider scaling:
\begin{equation*}
    (i\partial_t+\Delta)u=0, u(0)=u_0\in\dot{H}^s, \Rightarrow \|u\|_{L^\infty\dot{H}^s}
\end{equation*}
Now we ask how does $X^{S,b}$ scale?
\begin{equation*}
    \frac{n+2}{2}-s-2b=\frac{n}{2}-s
\end{equation*}
This gives $b=1/2$.

\begin{remark}
    This is a major downside of Bourgain spaces, since scaling wouldnt' work since $b=1/2$ is not allowed.
\end{remark}
We connect them with the Strichartz spaces.
\begin{equation*}
    S\leftarrow X^{0,1/2}, S^s\leftarrow X^{s,1/2}
\end{equation*}
Hence the dual $S'$ corresponds to the dual $X^{0,-1/2}$.

\begin{remark}
    One could work in Bourgain spaces if they care about resonant interactions, and Strichartz estimates if they don't...
\end{remark}

Now we ask the question, can we find a middle ground between $X^{0,1/2}$ and Strichartz. Note that 
\begin{equation*}
    X^{0,1/2}\subset S, X^{0,0}=L^2
\end{equation*}
We could interpolate in between
\begin{equation*}
    X^{0,b}\subset L^{p_1}L^{q_1}, \text{ where } \frac{1}{p_1}=(1-2b)\frac{1}{2}+2b\frac{1}{p}
\end{equation*}
and the same relation holds for $q$. However, note that $\dot{X}^{0,1/2}\subset S$ is not well-defined. However, the above $X^{0,b}$ is true. Hence, we interpolate, again.

\begin{theorem}
    $X^{s,b}$ to Strichartz embedding holds, where $b\in [0,1/2)$.
\end{theorem}
We would like to prove something like $X^{0,b}\subset L^{p_1}L^{q_1}$, then we look at the map
\begin{equation*}
    u\to\frac{1}{|D_t+D_x^2|^b}u, L^2\to L^{p_1}L^{q_1}
\end{equation*}
\begin{proof}
    We shall do a $TT^*$ argument.
    \begin{equation*}
        Q_b=T_bT_b^*: f\mapsto\frac{1}{|D_t+D_x^2|^{2b}}f
    \end{equation*}
    where $\frac{1}{|D_t+D_x^2|^{2b}}$ is a multiplier, and has a proper symbol in the dual space. And we would want
    \begin{equation*}
        Q_b=TT^*: L^{p_1'}L^{q_1'}\to L^pL^q
    \end{equation*}
    Note that $T: X_0\to Y_0$, and $T: X_1\to Y_1$, then we can interpolate to have $X_\theta\to Y_\theta$. For our purposes, we consider a different interpolation, known as Stein's interpolation (for strips in the complex plane), shown in Figure 8.

    We apply Stein's interpolation. $Re(b)=0$, and $T_b: L^2\to L^2$. $Q_b$, multipliers with symbol: (we would like to extend the range of $b$)
    \begin{equation*}
        \Gamma(2b)=(\tau+\xi^2+i0)^{2b}
    \end{equation*}
    This homogeneous expression does not have constraint on $b$. We can increase $b$ until $q\to\infty$.

    Note homogeneous functions act funny when the exponents are integers, hence we use the Gamma function $\Gamma$ to kill the integers. Then $p_1=q_1$ at endpoint, $p=q=\infty$. Now we just need to bound the Fourier transform of $\tau_\xi^2$
    \begin{equation*}
        Q_b=\ast (\tau+\xi^2)^{2b}: L^1\to L^\infty
    \end{equation*}

\end{proof}



\section{Lecture 7}
$X^{s,b}$ Bourgain spaces and
\begin{equation*}
    u\in X^{S,b} if \widehat{u}\langle\xi\rangle^x \langle \tau+\xi^2\rangle^b\in L^2
\end{equation*}

\begin{equation*}
    \frac{i\partial_t+\Delta}{-\tau-\xi^2}: X^{S,b}\to X^{S,b-1}
\end{equation*}
Bouragin  solve in inhomogeneous spaces
\begin{equation*}
    (i\partial_t+\Delta)u-f, u(0)=u_0
\end{equation*}
\begin{equation*}
    (u_0, f)\to u
\end{equation*}
where $u_0\in H^s$, and $f\in X^{S,b-1}$, where $u\in X^{S,b}$.

Now we ask the question: is the follwoing bound true?
\begin{equation*}
    \|u\|_{X^{S,b}}\leq \|u_0\|_{H^s}+\|f\|_{X^{S,b-1}}
\end{equation*}
Suppose $f=0, s=0$, then we have
\begin{equation*}
    \widehat{u}=\widehat{u_0}(\xi)\cdot\delta_{\tau=|\xi|^2}\not\in X^{S,b}, \text{ for all } s, b
\end{equation*}

Hence, we only look at solutions that are local in time, i.e. we insert a cutoff funciton.

Hence we ask if the following bound holds:
\begin{equation*}
    \|\chi u\|_{X^{S,b}}\leq \|u_0\|_{H^s}+\|f\|_{X^{S,b-1}}
\end{equation*}

\begin{equation*}
    \widehat{\chi u}=\widehat{\chi}\ast_\tau\widehat{u}=\widehat{\chi}\ast_\tau\widehat{u_0}(\xi)\delta_{\tau+|\xi^2}=\widehat{u_0}(\xi)\widehat{\chi}(\tau+\xi^2)
\end{equation*}

Now we get
\begin{equation*}
    \|\chi u\|_{X^{0,b}}=\|\widehat{u_0}(\xi)\widehat{\chi}(\tau+\xi^2)\langle \tau+\xi^2\rangle^b\|_{L^2}\leq \|\widehat{u_0}\|_{L^2}
\end{equation*}
Note this is because $\widehat{\chi}(\tau+\xi^2)\langle \tau+\xi^2\rangle^b\in\mathcal{S}$, and $\mathcal{S}\subset L^2$. Hence, we lok at the contribution of $f$,
\begin{equation*}
    (i\partial_t+\Delta)(\chi u)=\chi(i\partial_t+\Delta)u_i\chi_t u
\end{equation*}

We would like to separate $\|\chi u\|_{X^{S,b}}$ into two parts into $\langle \tau+\xi^2\rangle>1$ or not.
\begin{equation*}
    \|\chi u\|_{X^{S,b}}=\|(i\partial_t+\Delta)(\chi u)\|_{X^{S,b-1}}+\|\chi u\|_{X^{S,0}}
\end{equation*}
For $\langle \tau+\xi^2\rangle<1$, we have the second term in $L^2$.

\begin{equation*}
    \|\chi u\|_{X^{S,b}}\leq \|f\|_{X^{S,b-1}}+\|u\|_{X^{S,0}}
\end{equation*}
Hence it remains to show
\begin{equation*}
    \|\chi u\|_{L^2H^s}\leq\|f\|_{X^{S,b-1}}+\|u_0\|_{H^s}
\end{equation*}
We will replace $\|\chi u\|_{L^2H^s}$ with $\|\chi u\|_{L^\infty H^s}$.
Note that if we have $u_0\in H^s$, we have $\chi u\in L^\infty H^s$. Now it remains to examine the contribution of $f$.
\begin{equation*}
    u(t)=\int_0^t e^{i(t-s)D^2}f(s)ds
\end{equation*}
Note that
\begin{equation*}
    \widehat{u}(t)=\int_0^t e^{i(t-s)\xi^2}\widehat{f}(s)ds
\end{equation*}
Now it's enough to consider fixed $\xi$. Hence we have
\begin{equation*}
    \widehat{u}(t,\xi)=e^{it\xi^2}\int_0^t e^{-is\xi^2}\widehat{f}(s,\xi)ds
\end{equation*}
Let
\begin{equation*}
    \widehat{g}(s,\xi)=e^{-is\xi^2}\widehat{f}(s,\xi)
\end{equation*}
Now we ask, where is $\widehat{g}$?
Note $e^{-is\xi^2}$ is a translation in the Fourier time varialbe.
\begin{equation*}
    \widehat{g}(\tau,\xi)=\widehat{f}(\tau-\xi^2,\xi)
\end{equation*}
where $\widehat{f}\in L_{\langle\xi\rangle^s, \langle\tau+\xi^2\rangle^{b-1}}^2$, hence this puts $\widehat{g}$ in $L_{\langle\xi\rangle^s, \langle\tau\rangle^{b-1}}^2$. This gives $g\in H_t^{b-1}H_x^S$.

We have shown we are trying to bound the following in $L_{loc}^\infty$.
\begin{equation*}
    \int_0^tg(s)ds
\end{equation*}
If $b=1$, then this is $L^2$, hence is computable. If $b<1$, consider
\begin{equation*}
    I=\langle g, 1_{[0,t]}\rangle
\end{equation*}
For $g\in H^{b-1}$, we would like to have $1_{[0,t]}\in H^{1-b}$.

\begin{equation*}
    \mathcal{F}_{1_{[0,t]}}=\frac{1}{\tau}(1-e^{it\tau})
\end{equation*}
and this gives $\frac{1}{\tau^{1/2+}}\in L^2$.
\begin{proposition}
    We have
    \begin{equation*}
        1_{[0,t]}\in H^s, \text{ for } s<1/2
    \end{equation*}
\end{proposition}
\begin{remark}
$H^s$ embeds into $C^0$ the space of continuous functions, for $s>1/2$, hence agrees with our computation.
\end{remark}

Now we come back and consider
\begin{equation*}
    \begin{cases}
    iu_t+\Delta u=u^2\\
    u(0)=u_0\in H^S
    \end{cases}
\end{equation*}
Goal: show there is a local solution in $X^{S,b}$. Note that
\begin{equation*}
    u=e^{itD^2}u_0+\int_0^te^{i(t-s)D^2}u^2ds
\end{equation*}
where we think of $u= N(\chi u)$, and try to apply the contraction principle in $X^{S,b}$. We can make $\chi(0)=1$ such that $\chi u(0)=u_0$, i.e. it agrees with our initial data. However, this is not the solution to our original problem anymore.
\begin{equation*}
    \begin{cases}
        (i\partial_t+\Delta)u=(\chi u)^2\\
        u(0)=u_0
    \end{cases}
\end{equation*}
This coincides with the original solution as along as $\chi(t)=1$. Now we consider
\begin{equation*}
    \chi u=\chi N(\chi u)
\end{equation*}
And we apply contraction principle for $\chi u$. However, this contraction defeats scaling. 

Now we ask the question, is there a counterpart of the Bourgain space which works at $b=\pm\frac{1}{2}$. These spaces are important because scaling works and linear equations are taken into consideration.

For $u\in X^{S,b}$, we consider
\begin{equation*}
    v(t)=e^{-itD^2}u(t), u(t)=e^{itD^2}v(t)
\end{equation*}
This multiplier pushes $u$ back to time 0 along the Schrodinger flow. For example, if $u$ solves the homogeneous equation, then
\begin{equation*}
    u(t)=e^{itD^2}u_0\Rightarrow v(t)=u_0
\end{equation*}

If we try to measure $\|u\|_{X^{S,b}}$, it is like measuring 
\begin{equation*}
    \|u\|_{L_{\langle\xi\rangle^s, \langle\tau+\xi^2\rangle^{b-1}}^2}=\|v\|_{L_{\langle \xi\rangle^2\langle \tau\rangle^b}^2}
\end{equation*}
This is to say
\begin{equation*}
    \|u\|_{X^{S,b}}=\|v\|_{H_t^b\dot{H}_x^s}
\end{equation*}
Hence we get,
\begin{equation*}
    \|v\|_{L^\infty H^s}=\|u\|_{L^\infty H^s}\leq\|u\|_{X^{S,b}}, b>1/2
\end{equation*}
Writing this in terms of $v$, we get
\begin{equation*}
    \|v\|_{L^\infty H^s}\leq \|v\|_{H_t^bH_x^s}
\end{equation*}
And note $H^b\subset L^\infty$, when $b>1/2$. 

Note that if $b=1/2$, we have
\begin{equation*}
    \dot{H}^{1/2}\not\subset L^\infty, \dot{H}^{1/2}\subset BMO
\end{equation*}

Now can we find a space where $b=1/2$ and is scale invariant?
\begin{equation*}
    \begin{cases}
        L^\infty\subset L^\infty\\
        \dot{W}^{1,1}\subset L^\infty
    \end{cases}
\end{equation*}
$W^{1,1}$ is the space of functions with continuous derivatives. We interpolate between $L^\infty$ and $\dot{W}^{1,1}$. And note 2 is between 1 and $\infty$, we have
\begin{equation*}
    [L^\infty, \dot{W}^{1,1}]_{[1/2]}
\end{equation*}

However, there are spaces that come very close to it.
\begin{equation*}
    []_{[1/2]}\sim V^2, U^2\subset L^\infty
\end{equation*}
And $V^1=BV$, the space of functions of boudned variation. 
We have the norm defined as follows:
\begin{equation*}
    \|u\|_{V^1}=\sup_{t_j}\sum|u(t_{j+1})-u(t_j)|
\end{equation*}
Note that
\begin{equation*}
    W^{1,1}\subset BV
\end{equation*}
We would like to replace 1 with $p$,
\begin{equation*}
    \|u\|_{V^p}^p=\sup_{t_j}\sum|u(t_{j+1})-u(t_j)|^p
\end{equation*}
As $p\to\infty$, we have that this resembles the $L^\infty$ norm.
Note that the pointwise values of functions in $u\in V^p$ is important, but we only care about functions that are defined almost everywhere.

Hence to avoid this issue, we know for any $u$ of boudned variation, we could have a left and right limit, hence we can enforce $u$ to be left or right continuous.

Thus, we have
\begin{equation*}
    BV=V^1\subset V^p\subset V^q\subset L^\infty
\end{equation*}
for any $p,q$, and we do not care about the distance between $p$ and $q$.

Note that
\begin{equation*}
    U^2\subset [L^\infty, W^{1,1}]_{1/2}\subset V^2
\end{equation*}
And for the LHS inclusion, we have $U^2$, which is an atomic space.

Atoms $a\in\mathcal{A}$, are objects of size 1. and for every $u$ in the space,
\begin{equation*}
    u=\sum c_ja_j, a_j\in\mathcal{A}
\end{equation*}
We can think of $c_j$'s as basis of our space. We would like the sum to converge, hence we have
\begin{equation*}
    \|u\|=\inf\sum|c_j|
\end{equation*}
taking the infimimum to ensure this is unique.

Now it remains to specify the atoms.
\begin{equation*}
    a=\sum_j b_j1_{I_j}, \text{ where } I_j \text{ are disjoint }
\end{equation*}
And we would like to have $a$ to have size 1, hence we have
\begin{equation*}
    \sum_j|b_j|^2=1, i.e. l^2
\end{equation*}
Note $I_j$'s can be as large and as small as you want.

\begin{example}
    $l^1$ is an atomic space, with $a=\delta_{j=j_0}$. (can also heuristically think of $L^1$ as an atomic space, with atoms being the dirac delta functions)
\end{example}
\begin{lemma}
    We have
    \begin{equation*}
        U^2\subset V^2
    \end{equation*}
\end{lemma}
\begin{proof}
    Take $a\in U^2$, do we have $a\in V^2$? Note that 
    \begin{equation*}
        \sum_j|a(t_{j+1})-a(t_j)^2\leq\sum|b_{j_{k+1}}-b_{jk}|^2\leq\sum b_j^2=1
    \end{equation*}
\end{proof}

Now consider $U^2(\R), V^2(\R)$, and recall the transformation:
\begin{equation*}
    u\to v=e^{-itD^2}u
\end{equation*}
where $u\in X^{S,b}$, and $v\in H^bH^S$, and 
\begin{equation*}
    u\in U_\Delta ^pH^s\iff v\in U^pH^s
\end{equation*}
and 
\begin{equation*}
    \|u\|_{V_\Delta^pH^s}^p=\|v\|_{V^pH^s}^2=\inf \sum\|v(t_{j+1})-v(t_j)\|_{H^s}^p=\inf\sum\|u(t_{j+1})-e^{i(t_{j+1}-t_j)D^2}u(t_j)\|_{H^s}^p
\end{equation*}

\section{Lecture 8}
We will continue our discussion of $U^p, V^p$ spaces, and they are defined for functions defined on $\R$.

\begin{definition}[$U^p, V^p$]
    $V^p$ is the bounded $p$ variation, and we have the norm as follows:
    \begin{equation*}
        \|u\|_{V^p}^p=\sup_{t_k}\sum|u(t_{k+1}-u(t_k))|^p
    \end{equation*}
    Note that we include left continuous in the definition for $V^p$ since they have only countably many jump discontinuities and we define the value at that point to be the left limit.

    $U^p$ is the atomic space, and the atoms are define as
    \begin{equation*}
        a=\sum c_k1_{[t_k, t_{k+1}]}, \sum_k c_k^p=1
    \end{equation*}
    And for $u\in U^p$, we have
    \begin{equation*}
        u=\sum_k\lambda_k a_k, \|u\|=\inf\sum_k|\lambda_k|
    \end{equation*}
\end{definition}

Last time we have
\begin{equation*}
    U^p\subset V^p
\end{equation*}
The reverse inclusion is not correct, but we have the following proposition if we change up the exponents a bit.
\begin{proposition}
    We have
    \begin{equation*}
        V^p\subset U^q, \text{ if } p>q
    \end{equation*}
\end{proposition}
Suppose that $\|v\|_{V^p}=1$ and the range of $v$, $Range(v)\subset [0,1]$, and our first guess is that $u_1$ is a step function so that $|v-u_1|\leq\frac{1}{2}$. And we look at the number of steps, in each step, we produce a difference of $1/2$, by the norm, $\left(\frac{1}{2}\right)^p$. If we denote the number of steps as $N_1$, we thus have
\begin{equation*}
    \left(\frac{1}{2}\right)^pN_1\leq 1\Rightarrow N_1\leq 2^p
\end{equation*}

Every step if we divide the range in 2, we get a sequence $v_n$ such that (we increase our accuracy by $1/2$ at each step)
\begin{equation*}\leq 2^{-n}
    v-(u_1+... u_n)
\end{equation*}
and $u_n$ is a step function with steps $\leq 2^{-n+1}$. Then we count the number of steps $N_n$,
\begin{equation*}
    2^{-np}N_n\leq 1\Rightarrow N_n\leq 2^{np}
\end{equation*}
These steps have preassigned dyadic size. Now we compute $\|u_n\|_{U^q}$, we have
\begin{equation*}
    \|u_n\|_{U^q}^q\leq 2^{(-n+1)q}\cdot N_n\approx 2^{n(p-q)}
\end{equation*}
Since we have $p<q$, hence we have the converges absolutely.
\begin{equation*}
    \|v\|_{U^q}\leq\sum 2^{n(p-q)}\lesssim 1
\end{equation*}
\qed

\begin{remark}
    Just like Christ-Kiselev lemma, we don't split the function based on equidistant intervals, but instead, we split the intervals based on the size of the function $|f(x)|$.
\end{remark}

We discuss the connection with the Schrodinger.
\begin{equation*}
    U_\Delta^p L^2=\{u\in L^\infty L^2: e^{-itD^2}u\in U^pL^2\}
\end{equation*}
For $u\in U_\Delta^p$, we have
\begin{equation*}
    e^{-itD^2}(i\partial_t+\Delta)u=i\partial_t e^{-itD^2}u
\end{equation*}
Hence we have 
\begin{equation*}
    (i\partial_t+\Delta), \text{ and } e^{itD^2}
\end{equation*}
as conjugate operators with respect to $e^{-itD^2}$.

Note that we have
\begin{equation*}
    i\partial_t+\Delta: \dot{X}^{S,b}\to\dot{X}^{S, b-1}, \partial_t: \dot{H}^b\to \dot{H}^{b-1}
\end{equation*}
And we have the following duality relation:
\begin{equation*}
    \left(X^{S,b} \right)^*=X^{-S, -b}
\end{equation*}
Similarly, we have the following duality relations:
\begin{equation*}
    \left(\dot{H} \right)^*=\dot{H}^{-b}
\end{equation*}
And
\begin{equation*}
    \partial_t: H^b\to H^{b-1}, \left(\dot{H}^\frac{1}{2} \right)^*=\dot{H}^\frac{1}{2}, \partial\dot{H}^\frac{1}{2}=\dot{H}^\frac{-1}{2}
\end{equation*}
Moreover, we would like
\begin{equation*}
    U^2, V^2\approx \dot{H}^\frac{1}{2}
\end{equation*}

\begin{proposition}
    We have
    \begin{equation*}
        (\partial U^2)^*=V^2
    \end{equation*}
\end{proposition}
First we observe that, for the Schrodinger equaiton, we have
\begin{equation*}
    \left[(i\partial_t+\Delta)U_\Delta^2L^2 \right]^*=V_\Delta^2L^2
\end{equation*}
And
\begin{equation*}
    \begin{cases}
        (i\partial_t+\Delta)u=f\\
        u(0)=u_0
    \end{cases}
\end{equation*}
Hence we have
\begin{equation*}
    \|u\|_{U_\Delta^2L^2}\leq\|u_0\|_{L^2}+\|f\|_{DU_\Delta L^2}
\end{equation*}
Note that we have $U_\Delta L^2$ as our $X^{S,b}$, and $S$ the Strichartz space, and $DU_\Delta^2L^2$ as $S'$, and $X^{S,b-1}$.

We look at the Riemann-Stiegjer integral, 
\begin{equation*}
    \langle \partial_t u, v\rangle=\int vdu=\lim_{\Delta t_n\to 0}\sum v(t_j)\left(u(t_{j+1}-u(t_j)) \right)=\lim_{\Delta t_n\to 0}\sum u(t_{j+1})(v(t_{j+1})-v(t_j))
\end{equation*}
where $u\in U^2, v\in V^2$, we take a sequence of points $t_n$ increasing, and $t_{j+1}-t_j\to 0.$ (Exactly how we defined the Riemann integral).

We have
\begin{equation*}
    \|v\|_{(\partial U^2)^*}=\sup_{\|u\|\leq 1}\langle \partial_t u, v\rangle=\sup_{atoms}\langle \partial_t a, v\rangle
\end{equation*}
hence we have
\begin{equation*}
    \langle \partial_ta, v\rangle=\sum c_j(v(t_{j+1})-v(t_j)), a=\sum c_j1_{[t_j, t_{j+1})}\leq\left(\sum(v(t_{j+1})-v(t_j))^2 \right)^\frac{1}{2}
\end{equation*}
due to $(l^2)^*=l^2$, hence it embeds into $V^2$, as this is exactly the $V^2$ norm.
\qed


\begin{equation*}
    \begin{cases}
        U^p\subset V^p\\
        (DU^p)^*=V^{p'}
    \end{cases}
\end{equation*}
These are called Besov norms.
And we have $U^2, V^2\approx \dot{H}^\frac{1}{2}$. Dyadic definition of $\dot{H}^\frac{1}{2}$, and $u\in\dot{H}^\frac{1}{2}$, this implies $\hat{u}|\xi|^\frac{1}{2}\in L^2$, we have
\begin{equation*}
    |\xi|\approx 2^j, 1=\sum_j\chi_j(\xi)
\end{equation*}
and we have
\begin{equation*}
    \hat{u}=\sum\chi_j\hat{u}=\sum\hat{u}_j
\end{equation*}

\begin{definition}[Besov norm]
    $B_{p,q}^s$ is defined as 
    \begin{equation*}
        \|u\|_{B_{p,q}^s}=\sum\left( 2^\frac{j}{s}\|u_j\|_{L^2}\right)^q
    \end{equation*}
    Hence we have
    \begin{equation*}
        \|u\|_{B_{2p}^\frac{1}{2}}=\sum\left( 2^{j/2}\|u_j\|_{L^2}\right)^p
    \end{equation*}
\end{definition}
Note that we have
\begin{equation*}
    \dot{B}_{2,1}^\frac{1}{2}\subset \dot{H}^\frac{1}{2}=\dot{B}_{2,2}^\frac{1}{2}\subset\dot{B}_{2,\infty}^{1/2}
\end{equation*}
For the above, we used the following embedding:
\begin{equation*}
    l^1\subset l^2\subset l^\infty
\end{equation*}
and we have
\begin{equation*}
    \partial\dot{H}^\frac{1}{2}\to\dot{H}^{-1/2}=(H^\frac{1}{2})^*
\end{equation*}
And 


\begin{proposition}
    We have the following embedding:
    \begin{equation*}
        \dot{B}_{2,1}^\frac{1}{2}\subset U^2\subset V^2\subset \dot{B}_{2,\infty}^\frac{1}{2}
    \end{equation*}
\end{proposition}
\begin{proof}
    It suffices to prove the first embedding, since if we have
    \begin{equation*}
        B_{2,1}^\frac{1}{2}\subset U^2\Rightarrow \subset DU^2\Rightarrow V^2\subset B_{2,\infty}^\frac{1}{2}
    \end{equation*}
\end{proof}
Recall we have
\begin{equation*}
    \|u\|_{B_{2,1}^\frac{1}{2}}=\sum_j2^{j/2}\|u_j\|_{L^2}
\end{equation*}
We have
\begin{equation*}
    \|u\|_{U^2}\leq\|u\|_{B_{2,1}^\frac{1}{2}}
\end{equation*}
by triangle inequality, this gets reduced to the following:
\begin{equation*}
    \|u_j\|_{U^2}\leq 2^{j/2}\|u_j\|_{L^2}
\end{equation*}
By rescaling, we could take $j\to 0$. And we look at $u_0=u\in L^2$, localized in 
\begin{equation*}
    \{|\xi|=1\}\Rightarrow u\in U^2
\end{equation*}
Enough to look at $u\in H^1\Rightarrow u\in H^2$, and we decompose $u$ based on unit intervals,
\begin{equation*}
    u=\sum_k u_k
\end{equation*}
where $supp(u_k)\subset [k-1, k]$. Hence if we take $u_k\in V^1$, and $\{u_k\}\in l_k^2V^1\subset U^2$, where we used the embedding $V^1\subset U^2$. Hence we are done.

Local orthogonality gives us
\begin{equation*}
    \|u\|_{L^2}^2\approx\sum_k\|u_k\|_{L^2}^2
\end{equation*}
\qed

\begin{corollary}
    We have $U_\Delta^2L^2\approx V_\Delta^2L^2\approx\dot{X}^{0,\frac{1}{2}}$ for functions localized in $|\tau^2+\xi^2|\approx 2^j$.
\end{corollary}

\begin{proposition}
    Suppose $L^pL^q$ is a Strichartz esimate, then we have
    \begin{equation*}
        U_\Delta^pL^2\subset L^pL^q
    \end{equation*}
\end{proposition}
\begin{proof}
    It is enough to show it for atoms, and the same $p$ allows us to use Strichartz.
\end{proof}

\begin{corollary}
    For $p_1<p$, we have
    \begin{equation*}
        V_\Delta^{p_1}L^2\subset L^pL^q
    \end{equation*}
\end{corollary}
\begin{equation*}
    \|u\|_{L^{p_1}L^{q_1}}\leq \|u_0\|_{L^2}+\|f\|_{L^{p_2'}L^{q_2'}}\Rightarrow \text{ Christ-Kiselev} p_1>p_2'
\end{equation*}

And note that we have
\begin{equation*}
    \|u\|_{U_\Delta^r L^2}\leq\|u_0\|_{L^2}+\|f\|_{DU_\Delta^rL^2}
\end{equation*}
where $r\leq p_1$ this implies
\begin{equation*}
    U_\Delta^rL^2\subset L^{p_1}L^{q_1}
\end{equation*}
And for $r>p_2'$, this implies
\begin{equation*}
    L^{p_2'L^{q_2'}}\subset DU_\Delta^rL^2
\end{equation*}
And this gives
\begin{equation*}
    V_\Delta^{r_1}L^2\subset L^{L^{p_2}}L^{q_2}
\end{equation*}



\section{Lecture 10}
Next we make the transition from linear to nonlinear Schrodinger equations (NLS).
\begin{equation*}
    \begin{cases}
        iu_t+\Delta u=\pm u|u|^p, p>0,1\\
        u(t=0)=u_0, u_0\in H^s, \text{ or } \dot{H}^s
    \end{cases}
\end{equation*}
Next we ask the question, is this question well-posed? and is it globally well-posed?

We first begin with $u_0\in L^2$, and try to find if we can solutions $u\in C(L^2)$. 
\begin{equation*}
    \begin{cases}
        iu_t+\Delta u=f\\
        u(0)=u_0
    \end{cases}
\end{equation*}
And we have the Strichartz estimates:
\begin{equation*}
    \|u\|_{L^\infty L^2}+\|u\|_{S}\leq\|u_0\|_{L^2}+\|f\|_{S'}
\end{equation*}
where $S=\cap L_t^pL_x^q$, and $S'$ is the dual Strichartz space.

We will ``replace the line with a number,'' namely, we will choose $p=q$, and
\begin{equation*}
    S=L_{t,x}^{\frac{2(n+2)}{n}}, S'=L_{t,x}^\frac{2(n+2)}{(n+4)}
\end{equation*}
where our $f=u\cdot|u|^p$.

\begin{equation*}
    u\rightarrow |u|^p\cdot u, L_{t,x}^{\frac{2(n+2)}{n}}\to L_{t,x}^\frac{2(n+2)}{(n+4)}
\end{equation*}
hence we obtain, $p=\frac{4}{n}$. 

\textbf{Using the contraction principle} to solve the NLS.

We have the solution in the form:
\begin{equation*}
    u(t)=e^{itD^2}u_0+\int_0^te^{i(t-s)D^2}u\cdot |u|^pds:= N(u)
\end{equation*}
\begin{note}
    Why do we pick out $f=u\cdot|u|^p$ instead of, say $|u|^{p+1}$, this is because this $u\cdot|u|^p$ preserves all the nice properties of solutions to the equation, such as the rotation symmetry, Galilean symmetry, etc. For example, 
    $\overline{u}$ kills the phase rotation, Galilean symmetry.
\end{note}

\begin{proposition}
    $u\mapsto N(u)$ is a contraction, i.e. it converges to a fixed point.
\end{proposition}
First we would like to define the notion of ``contraction'' given a metric, we pick our Banach space to be the Strichartz estimate $S$.

By the linear Strichartz estimate, it suffices to look at the source term:
\begin{align*}
    \|N(u)-N(v)\|_S&\leq \|u|u|^p-v|v|^p\|_{S'}\\
    &\leq\||u-v|\cdot(|u|^p+|v|^p)\|_{S'}\\
    &\leq\|u-v\|_{L^\frac{2n+1}{n}}\|(u,v)\|_[L^\frac{2n+2}{n}]
\end{align*}
Instead of $S'$. we replace it with $L^\frac{2(n+2)}{n+4}$, where the last term is the Lipschitz solution, hence we look for small data solutions.

Assume $\|u_0\|_{L^2}<\epsilon$, then we look for solutions in $B_{L^\frac{2(n+1)}{n}}(0,100\epsilon)$.

\begin{theorem}
    NLS with $p=\frac{4}{n}$ is \textbf{globally} well posed for initial data $u_0$ which is small in $L^2$. 
\end{theorem}
\begin{note}
    Two caveats: we fixed $p$, do not have understanding of other $p$'s, and we can only work with small initial data $u_0$.
\end{note}
\begin{remark}
    When $p$ is even, we are given the nice properties that $u$ could be made analytic, hence $n=1, 2$ cases are interesting.
\end{remark}
\begin{problem}
    How do we proceed with other $p$'s?
\end{problem}

\textbf{n=1} $p=4$. Can $p$ go lower? $0<p<4$. Say, we pick $p=2$. Hence we estimate: $u\cdot|u|^2$. The Strichartz space:
\begin{equation*}
    L^\infty L^2\to L^4L^\infty, S': L^1L^2\to L^\frac{4}{3}L^1
\end{equation*}

For the following:
\begin{equation*}
    |u|^2\cdot u=\overline{u}\cdot u\cdot u
\end{equation*}
where $\overline{u}, u\in L^4L^\infty$, and the third $u\in L^\infty L^2$, hence taking the produt of both in time and space, we get our $|u|^2\cdot u\in L^2L^2$, and for fixed time interval $T$, we have
\begin{equation*}
    L^2L^2\subset L^1L^2
\end{equation*}

Now going back to the contraction $N(u)$, we get 
\begin{align*}
    \|N(u)-N(v)\|_S&\leq\||u|^2u-|v|^2v\|_{L^1L^2}\\
    &\leq\sqrt{T}\|\cdot\|_{L^2L^2}\\
    &\leq \sqrt{T}\|(u,v)\|_S^2\\
\end{align*}
Hence now, our Lipschitz constant is
\begin{equation*}
    L=\sqrt{T}\left(\|(u,v)\|_S^2 \right)^2
\end{equation*}
Hence we can choose our $T$ corresponding to kill the contribution of the rightmost term.

\begin{corollary}
    For $\|u_0\|_{L^2}\leq M$, and $\|u\|_S\leq 10^5M$, we can choose $T=10^{-10}M^{-4}$, then $u$ exists by the contraction principle.
\end{corollary}

Hence we have the theorem.
\begin{theorem}
    For the above NLS, with $0<p<\frac{4}{n}$, it is locally (then globally) well-posed for initial data $u_0\in L^2$. 
\end{theorem}
\begin{remark}
    We recall, if our ODE solution exists locally, and does not increase after that local time period, then the solution exists globally. Hence we check if solution $u$ grows, we have $\frac{d}{dt}\|u\|_{L^2}^2=0$, as for the nonlinear portion, we have $\int Im(\pm u|u|^p\overline{u})$, hence picking $u$ to be real, we have that NLS is well-posed globally.
\end{remark}

Note that under scaling, the linear Schrodinger:
\begin{equation*}
    u(t,x)\to\mu u(\lambda^2t, \lambda x)
\end{equation*}
and for the nonlinear equation it is the same, however, $t,x$ are coupled:
\begin{equation*}
    (iu_t+\Delta u)=|u|^p\cdot u
\end{equation*}
Hence we have
\begin{equation*}
    u-\lambda^2=\mu^{p+1}\Rightarrow \mu=\lambda^\frac{2}{p}
\end{equation*}

Then we ask the question: how about the $L^2$ norm of the data?
\begin{equation*}
    \|u_\lambda\|_{L^2}^2=\int\mu^2|u(\lambda x)|^2dx=\mu^2\lambda^{-n}\|u\|_{L^2}^2=\lambda^\frac{4}{p}\lambda^{-n}\|u\|_{L^2}^2
\end{equation*}
Note that when $p=\frac{4}{n}$, the magical exponent for $p$!
\begin{corollary}[$L^2$ critical]
    When $p=\frac{n}{4}$, the $L^2$ problem is scale-invariant. (The $L^2$ norm does not change when you scale the solution). 

    This is called the $L^2$ critical problem, and we get global well-posedness for small data.
\end{corollary}

Now suppose $p<\frac{4}{n}$, this is called the \textbf{subcritical} problem, and $u(t)\in [0,T]$, and $u_\lambda$ lives for $[0,\lambda^{-2}T]$. We could scale our data to preserve the size, we could have the data live longer by scaling the size at particular $t$ to be smaller; or have the data live shorter by increasing the size.

Now suppose $p>\frac{4}{n}$ , this is called the \textbf{supercritical} $L^2$ problem, and this problem is ill-posed. this is because the scaling is reversed as in the subcritical case. We obtain a ``better'' solution, larger and lives longer by scaling, which should be impossible.

\begin{note}
    What do we mean by saying a problem is ill-posed? It means the nonexistence (where), or nonuniqueness. And maybe a third one is the continuous dependence on the initial data. This could happen with two initial data that start really close together, but the solution differs a lot.
\end{note}

One could define well-posedness in $S$ the Strichartz space, or one could talk about the unconditional uniqueness in $C(L^2)$, where it is continuous in $L^2$. One could surely do a combination of the two, where one compares $S$ and one $C(L^2)$.

Recall we came up with $p=\frac{4}{n}$, since we look at $u_0\in L^2$, (and we did this because the conservation law holds in $L^2$), and used the Strichartz estimate given that our intial data is in $L^2$.

Now we would like to move $u_0$ away from $L^2\to \dot{H}^s$, and the reason for homogeneous Sobolev space is that we would like to do scaling. Now how does $\|u\|_{H^s}$ change under sclaing?
\begin{equation*}
    \|u_\lambda\|_{H^s}^2\approx \|D^su_\lambda\|_{L^2}^2\approx \int u^2\lambda^{2s}|D^su(\lambda x)|^2dx\approx \lambda^{\frac{4}{p}}\lambda^{-n}\lambda^{2s}\|u\|_{H^s}^2
\end{equation*}
Hence the dependence now also includes $s$. This gives us $\frac{4}{p}=n-2s$, and $p_s=\frac{4}{n-2s}$. Now we again separate into three cases, and the only thing we no longer have the conservation in $H^s$.
\begin{enumerate}
    \item $p<p_s$
    \item $p=p_s$
    \item $p>p_s$
\end{enumerate}
\begin{remark}
    Subcritical means everything nice, and critical is when it is scale-invariant, and supercritical is ill-posed.
\end{remark}

\textbf{s=1} This gives rise to another conservation situation.
\begin{equation*}
    iu_t+\Delta u=u\cdot|u|^p
\end{equation*}
$H^1$ conservation law is the following: recall the mass $M=\frac{1}{2}\int |u|^2dx$,
\begin{equation*}
    E=\int\frac{1}{2}|\nabla u|^2+\frac{1}{p+2}|u|^{p+2}dx
\end{equation*}
Hence for $H^1$ critical, we have $p_c=\frac{4}{n-2}$, and this only makes sense when $n\geq 3$.

\begin{note}
    In $n=2$, $H^1$ is almost like $L^\infty$, and hence loses meaning.
\end{note}
Note
\begin{equation*}
    0<\frac{4}{n-2}<\frac{4}{n}
\end{equation*}
and the middle one is the energy critical point, and the right $4/n$ is the mass critical point.


\section{Lecture 11}
We've been discussing the semi-linear equation:
\begin{equation*}
    \begin{cases}
        iu_t+\Delta u=\pm|u|^p\cdot u\\
        u(0)=u_0
    \end{cases}
\end{equation*}
And we've seen the operator $P\to S_p$, where $p=\frac{4}{n-2}$, and we separate them into three cases, the $s>s_p, s=s_p, s<s_p$, where we have $s>s_p$ is LWP, the second being GWP for small dadta, and $s<s_p$ is ill-posed.

We also discussed the conservation of mass
\begin{equation*}
    M=\frac{1}{2}\int|u|^2dx
\end{equation*}
And the conservation of energy
\begin{equation*}
    E=\int\frac{1}{2}|\nabla u|^2\pm \frac{1}{p+2}|u|^{p+2}dx
\end{equation*}

The conservation of mass lives in $L^2$, where $p=\frac{4}{n}$, and $n\geq 1$, and we call this the mass critical problem; and the conservation of energy, we want it to be $\dot{H}^1$, where $p\frac{4}{n-2}$, and $n\geq 3$, and we call this is the mass critical problem.

Next we discuss the Hamiltonian structure: we have
\begin{equation*}
    w(u,v)=\int Im(u\cdot\overline{v})\Rightarrow J=i
\end{equation*}
where $J$ denotes the sympletic form. If we have the Hamiltonian form $H=H(x)$, relaxed to the sympletic form $J$, and we should have
\begin{equation*}
    u_t=JDH(u)
\end{equation*}
We take the flow associated to the mass, $u_t=iu, u(t)=u(0)e^{it}$ where this acts as a phase rotation. Then if we take the energy:
\begin{equation*}
    u_t=i\left(-\Delta u\pm u|u|^{p-1}\right)\rightarrow (NLS)
\end{equation*}
\begin{theorem}[Noether's theorem]
    Phase rotation symmetry corresponds exactly to mass conservation.
\end{theorem}
We have another version of symmetry, the translation symmetry, where we have $u(t,x)\to u(t,x+he_j)$, and we thus have $u_t=-u_{x_j}$. 


\begin{proposition}[The mass critical case. ]
    If we start with $\|u_0\|\ll 1$, then we have $u\in S$.
\end{proposition}
we considered the Strichartz space, where $p=q$, and thus consider $L_{t,x}^\frac{2(n+2)}{n}$, and have $u\cdot |u|^p\in S'$.

Once we obtain a global solution. This gives rise to our discussion of scattering, which is how the solution behaves at infinity.
\begin{remark}
    We would like to say this $u$ to the NLS behaves just like the solution to the linear equation at $\infty$.
\end{remark}
\begin{theorem}[scattering]
    If $u$ is a small $L^2$ solution to mass critical problem. Then there exists $u^+\in L^2$ such that 
    \begin{equation*}
        \lim_{t\to\infty}u(t)-e^{it\Delta}u^+=0 \text{ in } L^2
    \end{equation*}
    where we have $e^{it\Delta}u^+$ is our solution to the linear equation.
\end{theorem}
\begin{proof}
    We should have 
    \begin{equation*}
        u^+=\lim_{t\to\infty}e^{-it\Delta}u(t)
    \end{equation*}
    We first have $u(t)$ the nonliear flow at time $t$, then we come back to $u_0$ for NLS, and also back to $t=0$ for th linear flow, then we push it to $t\to\infty$. 

    $u(t)=e^{it\Delta}u(0)+\int_0^te^{i(t-s)\Delta}f(s)ds$. Applying $e^{-it\Delta}$, we have
    \begin{equation*}
        e^{-it\Delta}u(t)=u(0)+\int_0^te^{-is\Delta}f(s)ds
    \end{equation*}
    where the RHS, we have $f\in S'$, and $e^{-is\Delta}$ send it back to dual Strichartz, and land in $L^2$.

    Then $f\in L^\frac{2(n+2)}{n}([0,\infty)\times \R^n)$, hence
    \begin{equation*}
        1_{[0,t]}f\to f \text{ as } t\to\infty
    \end{equation*}
    Hence we get our scattering property.
\end{proof}
\qed

\begin{note}
    If $p<\frac{4}{n}$, this is our subcritical problem, then local well-posedness implies global well-poseness, this gives us $u|u|^p\in S'$ on $I$. 
\end{note}
We are still a bit unhappy since for mass critical problem, we are only working with small intiial data $\|u_0\|_{L^2}\ll 1$. 
\begin{problem}
    What if our initial data is large?
\end{problem}
Let's start witht he easier version: local well-posedness.

\begin{theorem}
    If $u_0\in L^2$, then there exists some time $T=T(u_0)$ such that the problem has a solution in $[0,T]$. (By having a solution, we again mean we can put the source term $f$ in the dual Strichartz estimate).
\end{theorem}
\begin{proof}
    We formulate this as a fixed point problem. 
    \begin{equation*}
        u(t)=e^{it\Delta}u_0+\int_00^t e^{i(t-s)\Delta}u\cdot|u|^{p-1}(s)ds
    \end{equation*}
    If $u=N(u)$, then you need some $X$ such that $N: X\to X$, and such that $N$ is a contraction. If you start with a small initial data, then there is no bad way to choose $X$. 

    Again we would like to look at the Lipschitz constant for $u\cdot|u|^{p-1}$, because we need $u$ to be small in $X$. Note that we would like
    \begin{equation*}
        L^\infty L^2\not\subset X
    \end{equation*}
    We choose $X=B(0,\epsilon)$ in $L_{t,x}^\frac{2(n+2)}{n}$, to have a small Lipschitz constant for nonliearity.

    Note that we have
    \begin{equation*}
        \|e^{it\Delta}u_0\|_{L^2}\leq\|u_0\|_{L^2}
    \end{equation*}
    But note that our RHS could be large, then we could choose $T$ such that
    \begin{equation*}
        \|e^{it\Delta}u_0\|_{L^\frac{2(n+2)}{n}}\leq\epsilon
    \end{equation*}
    Note that we have $L^\frac{2(n+2)}{n}([0,T]\times\R^n)$.
    Wave packets can live on any time scale, and depending on how we choose the scale, we might stop at a very very small $T$, yet it is positive.
\end{proof}
\qed

The scattering we had is $t\to\infty$, and we could also investigate $t\to -\infty$. 
\begin{equation*}
    u_0\to u^+(\infty), u_0\to u^-(-\infty), L^2\to L^2
\end{equation*}
Then we have a reverse problem (asymptotic completeness).
\begin{problem}
    Given $u^+\in L^2$, is there a solution $u$ that matches our $u^+$ at infinity.
\end{problem}

\begin{theorem}
    Given $u^+\in L^2$, then there exists $T$ and a solution $u$ in $[T,\infty)$.
\end{theorem}
\begin{proof}
    We apply the exact same argument, but just writing it from $\infty$.
    \begin{equation*}
        u=e^{it\Delta}u^+-\int_t^\infty e^{i(t-s)\Delta}u\cdot|u|^p(s)ds
    \end{equation*}
    Choose $T$ such that 
    \begin{equation*}
        \|e^{it\Delta}u^+\|_{L^\frac{2(n+2)}{n}([T,\infty)\times\R^n}\leq\epsilon
    \end{equation*}
    We choose $T$ for as long as it keeps the norm small.
\end{proof}
\qed

\begin{note}
    The solution $u$ is global if our $u^+$ is small.
\end{note}
We know how to solve for $u_0$ is large from $t=0$, and from $\infty$. Now we ask if we can have \textbf{blow-up} if the initial data $u_0$ is large?

First we need to identify ``blow-up.'' It is impossible to have $\|u(t)\|_{L^2}\to\infty$. Find maximal $T$ such that $[0,T)$ maximal time interval of existence (not specified which space yet). Then
\begin{equation*}
    \lim_{t\to T}u(t):=u(T) \in L^2
\end{equation*}
If we above limit exists, then we could denote it as $u(T)$, and it leaves in $L^2$ since it is a limit of an $L^2$ sequence. Then we could continue to extend our solution for larger $T$.

\begin{proposition}
    If the solution $u: [0,T)\to L^2$ is a maximal solution, then
    \begin{equation*}
        \lim_{t\to T}u(T)
    \end{equation*}
    does not exist.
\end{proposition}
\begin{note}
    We also mean the limit does not even exist for any subsequence. However, this is not a good enough criterion, since all continuous functions are by definition, cannot blow up.
\end{note}

Next we introduce a better blow-up criterion. 

We have $\|e^{it\Delta}u_0\|_{L^\frac{2(n+2)}{n}}=\epsilon$, and note now we use this as an initial data, and extend our solution, hence we have $T(u_0), T(u_1), ...$.

If we don't have a global solution, then we must have stopped somwhere, then we get a solution on $[0,T)$, and then we have
\begin{equation*}
    \|u\|_{L^\frac{2(n+2)}{n}([0,T)}=\infty
\end{equation*}
\begin{theorem}
    The solution $u$ blows up at time $T$ if and only if 
    \begin{equation*}
        \|u\|_{L^\frac{2(n+2)}{n}([0,T)\times\R^n}=\infty
    \end{equation*}
\end{theorem}
Same at $\infty$, where either $ \|u\|_{L^\frac{2(n+2)}{n}([0,T)\times\R^n}<\infty$ with scattering or $ \|u\|_{L^\frac{2(n+2)}{n}([0,T)\times\R^n}=\infty$ in which case we have no scattering.

The magical signs:
\begin{equation*}
    E(u)=\frac{1}{2}\int|\nabla u|^2\pm\frac{1}{p+2}|u|^{p+2}dx
\end{equation*}
For $u\in L^2$, we have the GNS inequality:
\begin{equation*}
    \|u\|_{L^2*}\leq\|\nabla u\|_{L^2}
\end{equation*}
where
\begin{equation*}
    \frac{1}{2}>\frac{1}{p+2}=\frac{1}{2}-\frac{1}{n+2}>\frac{1}{2^*}=\frac{1}{2}-\frac{1}{n}
\end{equation*}
Note that we have the interpolation inequality.
\begin{equation*}
    \|u\|_{L^{p+2}}^{p+2}\leq\|\nabla u\|_{L^2}^2\|u\|_{L^2}^p
\end{equation*}

Let's think about global solutions, and those that scatter and those that don't. 

The simplest solution that does not scatter is those that are constant in time, and we call them the \textbf{ steady state}. 
\begin{equation*}
    u_t=i\cdot\frac{\delta E(u)}{\delta u}
\end{equation*}
Steady state is if and only if critical points for $E$.

In the sign in the energy formula is +, then $E$ is convex and there is no steady state; if the sign is -, then we have the mountain pass lemma. After we cross a critical convex point, then we pass the hill, and look for the smallest height that we can reach.

\begin{lemma}
    There exists a smallest size steady state $Q$, the ground state, which is
    \begin{equation*}
        \Delta Q=-|Q|^p\cdot Q
    \end{equation*}
    where $Q$ is real-valued.
\end{lemma}
And we come to the conjecture that for the $+$ sign, we have the defocusing problem:  we have well-posedness and scattering for large data; the $-$ sign, we have the focusing problem, and we have scattering and global solution for $\|u_0\|_{L^2}\leq\|Q\|_{L^2}$. (i.e. if you are stuck in the bowl) This is a theorem by Dodsin.


\section{Lecture 10/3}
We were looking at the mass critical problem:
\begin{equation*}
    \begin{cases}
        i u_t+\Delta u=|u|^p, p=\frac{4}{n}
    \end{cases}
\end{equation*}
where we have GWP fro small data, and LWP for large initial data, and blow up at $\|u\|_[L^\frac{2(n+2)}{n}]=\infty$. 

We now talk about focusing and defocusing. The energy is
\begin{equation*}
    E(u)=\int \frac{1}{2}|\Delta u|^2\pm \frac{1}{p+2}|u|^{p+2}dx
\end{equation*}
where we noted that if we have $+$, then it is defocusing and it is convex and coercive, and focusing when we have $-$.

\begin{equation*}
    \int|u|^{p+2}\lesssim \int |\Delta u|^2\left(\int|u|^2\right)^\frac{p}{2}
\end{equation*}
Hence the energy is controlled by $|u|_{L^2}$ then $E$ is coercive, and but not if $\|u\|_{L^2}$ gets large.

Now we ask the question how exactly is $\|u\|_{L^2}$ small, and what is the \textbf{threshold} for $\|u\|_{L^2}$ such that the energy stays positive definite? And for this, we need to find the sharp constant such that inequality in G-N
\begin{equation*}
    \int|u|^{p+2}\leq C\int|\Delta u|^2\left(\int|\nabla u|^2 \right)^\frac{p}{2}
\end{equation*}

And we look for the smallest constant such that the above holds, or equivalently,
\begin{equation*}
    \max\frac{\int\frac{1}{p+2}|u|^{p+2}}{\int\frac{1}{2}|\nabla u|^2}:=H(u)
\end{equation*} 
with $\|u\|_{L^2}=c$. This should remind you of the Lagrange multipliers, subject to some constraint.The existence of the maximizer will be delayed till later discussions.

Now we look at the following and would like to set this to 0.
\begin{equation*}
    \frac{d}{dh}H(u+hv)=\frac{d}{dh}\log H(i+hv)=\frac{\int |u|^pRe(u\overline{v})}{\int\frac{1}{p+2}|u|^{p+2}}-\frac{\int Re(\nabla u\nabla \overline{v})}{\int\frac{1}{2}|\nabla u|^2}
\end{equation*}
And $v\perp u$, hence we get 
\begin{equation*}
    Re\int \left(\frac{|u|^pu}{\int\frac{1}{p+2}|u|^{p+2}dx}+\frac{\int\Delta x}{\int\frac{1}{2}|\nabla u|^2} \right)\cdot\overline{u}dx=0
\end{equation*}
This gives that
\begin{equation*}
    \frac{|u|^pu}{\int\frac{1}{p+2}|u|^{p+2}dx}+\frac{\int\Delta x}{\int\frac{1}{2}|\nabla u|^2}=\lambda u
\end{equation*}
where $\lambda$ is the Lagrange multiplier. As we move away from 0, i.e. $u\mapsto au$, as $a$ increases, we get a positive power of $a$, $a^p$

We choose $c$ such that the maximum is exactly 1. Then the denominators in the above equation are exactly equal, hence we move them to the RHS into $\lambda$, thus
\begin{equation*}
    |u|^pu+\Delta u=\lambda u, \lambda>0
\end{equation*}
Because of the presence of $\lambda u$, this is not a steady state problem. However, $u$
\begin{equation*}
    v(x,t)=u(x)e^{i\lambda t}
\end{equation*}
solves the NLS. This is called a soliton.
\begin{equation*}
    iv_t+\Delta v=(-\lambda u+\Delta u)e^{i\lambda t}=|u|^p ue^{i\lambda t}=v^p\cdot v
\end{equation*}
Hence we get the conclusion that there exists some $c_0$ such that at $c_0$, the max is 1, $E(v)\geq 0$, and the maximizer, $E(Q)=0$, and $Qe^{i\lambda t}$ then solves the NLS.

\begin{proposition}
    $c_0=\|Q\|_{L^2}$ is the critical mass. And $\|u\|_{L^2}< c_0$ implies that $E$ is coercive, and $\|u\|_{L^2}=c_0$ we have the extreme case where $u=Q_1$, and $E(Q)=0$. 
\end{proposition}
\begin{equation*}
    \max\frac{|u|^{p+2}}{\int|\nabla u|^2}dx
\end{equation*}
First by separating $u$ into real and imaginary parts, we conclude that $u$ is real. Then notice the quantity does not change if we replace $u$ with $|u|$, then we can take $u\geq 0$. And we do the rearrangement: we take the decreasing rearrangement of $\lambda$, And we have $|\{u\geq\lambda\}|=|\{u^*\geq\lambda\}|$, and we want $u^*$ in 1-d, and to generalize, we want $u^*$ to be spherically symmetric in n-dim.

First we rewrite
\begin{equation*}
    -\Delta u+\lambda u=|u|^p\cdot u
\end{equation*}
And we take the Fourier transform: where the LHS is $\xi^2+\lambda$. This implies exponential decay for the fundamental solution. This implies that $u$ is smooth and decays exponentially at $\infty$.
\begin{equation*}
    (\partial_r+\frac{r}{r-1}\partial_r+\lambda)u=u^{p+1}
\end{equation*}
This gives the solution in the form:
\begin{equation*}
    u\approx cr^{-\frac{n-1}{2}}e^{-\sqrt{\lambda}r}
\end{equation*}
\begin{note}
    This is the shooting problem, and usually, the slope is not zero, and this ensures the uniqueness of solution.
\end{note}

\begin{theorem}
    There is a unique smooth nonnegative radial ground state.
\end{theorem}

Our first soliton is as follows: $u=e^{it}Q$, and we could do the following:
\begin{enumerate}
    \item translate it
    \item rescale it, making it wider and shorter
    \item Galilean motion/transform, due to Galilean invariance. 
\end{enumerate}
To summerize, we can choose scale, position and velocity.  These are the enemies of scattering.

There is a Schrodinger counterpart to Euclidean inversion:
Euclidean:$ x\mapsto\frac{1}{x}$, where the Schrodinger is
\begin{equation*}
    (t,x)\mapsto \left(\frac{1}{t}, \frac{x}{t}\right)
\end{equation*}
And 
\begin{equation*}
    u(t,x)\mapsto \frac{1}{t^{-\frac{n}{2}}}e^{i(x^2+4)/(4t)}u(\frac{1}{t}, \frac{x}{t})
\end{equation*}
This is calle dhte pseudoconformal transformation. If $u=Q$, then $\tilde{Q}$ and note that $\tilde{Q}$ blows up at $t=0$, and 
\begin{equation*}
    \|\tilde{u}\|_{L^2}=\|u|_{L^2}
\end{equation*}
We have the solitons, and solutions that blow up at finite times. 

\begin{equation*}
    iu_t=-\Delta u\pm|u|^{p-1}u
\end{equation*}
On the RHS, $-\Delta u$ is the linear part, and it wants to disperse, the second term is $|u|^{p-1}u$, and wants to behave, together with the LHS, like an ODE.

And suppose $u_0=A\cdot e^\frac{(x-x_0)^2}{T}e^{i(x-x_0)\cdot\xi_0}$, where $A$ is some amplitude:
\begin{equation*}
    \delta_x\approx\sqrt{T}, \delta_\xi=\frac{1}{\sqrt{T}}
\end{equation*}
And linear flow stays coherent up to time $T$.

We note that $|u|^p$ is a conserved quantity, and we have
\begin{equation*}
    iu_t=\pm|u|^p\cdot u
\end{equation*}
and we have
\begin{equation*}
    u(t,x)=u_0(t,x)\cdot e^{\pm it|u_0(t,x)|^p}
\end{equation*}
We solved it using the fact it is now an ODE.

Now we ask the question, is the nonlinear effect slower of faster than the linear one?

We assumed $x_0=0$, and $\xi_0=0$. and note that the size of the phase is up to $T\cdot A^p$, and we have
\begin{equation*}
    T\cdot A^p\begin{cases}
        \ll 1, \text{ linear } wins\\
        \approx 1, \text{ balance }\\
        \gg 1, \text{ Nonlinear wins}
    \end{cases}
\end{equation*}
And 
\begin{equation*}
    \|u_0\|_{L^2}\approx 1\approx A(\sqrt{T})^\frac{n}{2}=AT^\frac{n}{4}\approx 1
\end{equation*}

If we have $p>\frac{4}{n}$, the linear part wins and you expect scattering, and $p=\frac{4}{n}$ (we assume $\|u_0\|_{L^2}\approx 1$), and if we drop the assumption, it depends on the size of the initial data, and $p<\frac{4}{n}$, and nonlinear wins, and expect no classical scattering.

You start with a bump funciton for initial data, and the nonlinear portion turns into quite oscillatory, then linear makes waves move along their group velocity. 


\section{Lecture 10/5}
If we look at the energy critical problem, re call the equal of interest, for $p=\frac{4}{n-2}$, and $n\geq 3$:
\begin{equation*}
    iu_t+\Delta u=\pm|u|^p\cdot u
\end{equation*}
and $\dot{H}^1$ is critical , recall the energy is defined as 
\begin{equation*}
    E(u)=\int\frac{1}{2}|\nabla u|^2\pm \frac{1}{p+2}|u|^{p+2}dx
\end{equation*}
and we noted that the energy is conserved and scale invariant for this choice of $p$.

Local well-posedness gives us $u_0\in H^1$, and gives $u\in S'$. Where $S$ is the strichartz space, and $S=\cap L^pL^q$, and $S'=\{u, \nabla_x u\in S\}$. 

We also introduced the following theorem.
\begin{theorem}
    If $\|u_0\|_{\dot{H}^1}\ll 1$, then there exists a global solution $u\in S'$. 
\end{theorem}
\begin{proof}
    We gave this proof before, via the contraction principle, and with the same  term in $N'=(S')^1$.
\end{proof}
We would like $u\in S'$, and $|u|^p\cdot u\in N'$, and note
\begin{equation*}
    \||u|^p u\|_{N'}\leq\|u\|_S^{p+1}
\end{equation*}
And we would like to minimize this strichartz norm.
\begin{equation*}
    \||u|^pu\|_{N'}=\|\nabla (|u|^p\cdot u)\|_N=\|\nabla u u^p\|_N
\end{equation*}
where $\nabla u\in L^\infty L^2$, hence to put it in a good space, we would also like $u^p$ to be in the mixed $L^p$ norm.
We have
\begin{equation*}
    \nabla u \in L^2L^r, u\in L^qL^{r^*}\Rightarrow |u|^p\in L^{q/p}L^{r^*/p}
\end{equation*}
We make the choice that $q=r^*$, and 
\begin{equation*}
    u_0\in H^1, u\in L_t^q L_x^2
\end{equation*}
Hence by the scaling relation:
\begin{equation*}
    \frac{n}{2}-1=\frac{2}{q}+\frac{n}{q}
\end{equation*}
This gives that 
\begin{equation*}
    \frac{r^*}{p}=\frac{2(n+2)}{n}\geq 2
\end{equation*}
where $u\in L^\frac{2(n+2)}{2}$, and is $\geq 2$, when $n\geq 3$. Hence the solution does not blow up.

\begin{theorem}
    For $u_0\in\dot{H}^1$, there exists a unique local solution $u\in S^1[0,T]$, furthermore, this solution may be continued, for as long as $\|u\|_{L_{t,x}^\frac{2(n+2)}{n-2}}$ remains finite.
\end{theorem}

\begin{theorem}
    If $u$ is a global solution with $\|u\|_{L^\frac{2(n+2)}{2}}$, then the solution $u$ is scattering, and there exists $u^+\in \dot{H}^1$, such that 
    \begin{equation*}
        \lim_{t\to\infty}\|u(t)-e^{it\Delta^2}u^+\|_{\dot{H}^1}=0
    \end{equation*}
\end{theorem}

Now we investigate the main problem, namely what happens for large inital data? We have the following defocusing conjecture.
\begin{proposition}[Conjecture]
    There is well-posedness for large data (i.e. $u\in L^\frac{2(n+1)}{2}$).
\end{proposition}
For the focusing case, the energy is
\begin{equation*}
    E=\int\frac{1}{2}|\nabla u|^2-\frac{1}{p+2}|u|^{p+2}dx
\end{equation*}
$u_t=i\frac{\delta E}{\delta t}$, which gives us steady state, i.e. critical points for $E$.

By scaling, via GNS, we have
\begin{equation*}
    \|u\|_{L^{p+2}}\leq c\|\nabla u\|_{L^2}
\end{equation*}
Note that the second term in the energy is dominated by the first term. For $\|u\|_{\dot{H}^1}\ll 1$, the energy is essentially quadratic and coercive. For large $\|u\|$, we might have our $E$ being negative. Essentially by the mountain pass lemma, which states to cross a mountain, ``you must obtain a point where it is the lowest.''

Now we look at the best constant in GNS, i.e. the minimizer. And from the small data ball to $E(u)<0$, we cross the highest point, and the minimzer which gives the best constant is a scalar multiple of the lowest moutain pass. This gives us
\begin{equation*}
    -\Delta u=\lambda |u|^p u
\end{equation*}
and if we scale $u$ to $cu$, we could get $\lambda=1$, which gives our critical point. Via the above equation, we found the ground state to be $Q=(1+r^2)^\frac{-(n-2)}{2}$. Now for the threshold conjecture.
\begin{proposition}[Conjecture]
    Global well-posedness holds for $E(u)<E(Q)$ in the good region, where the good region includes the small initial data region, and the bad region is outside, where $E(u)<0$.

    furthermore, we ave finite time blowup holds for $E(u)<E(Q)$, in the good region as above.
\end{proposition}

The $L^2$ case, the defocusing conjecture by Dodson in the book, and the threshold conjecture is also done by Dodson.

The $\dot{H}^1$ case , the defocusing conjecture, we will follow Visann notes, and the threshold conjecture is only known for $n\geq 5$, where $n=3,4$ still remain open.

Now we look at the in-between cases, where $\dot{H}^s$, and $s\in (0,1)$, then $p=\frac{4}{n-2s}$. The defocusing conjecture remains largely open, but there is a note such that no type II blowup can occur(remain bounded on a finite time interval), but remains open for the type I blowup(where the solution grows). The threshold conjecture: 
\begin{equation*}
    -\Delta Q+Q=|Q|^pQ
\end{equation*}
where $Q$ is the critical point of $E$ on the level set of $M$.
\begin{equation*}
    -\Delta Q-Q^{p+1}=Q
\end{equation*}
where the LHS is $\delta E$, and RHS from $\delta M$. If we are limmited to $\dot{H}^s$, we do not know where mass or energy is finite. 

We ask the question for $H^1$, nonhomogenous initial data, $E<\infty, M<\infty$.
\begin{equation*}
    E^s M^{1-s}
\end{equation*}
and this is the scale invariant quantity. And the threshold conjecture asks
\begin{equation*}
    E^s(u)M^{1-s}(u)\leq E^s(Q)M^{1-s}(Q)
\end{equation*}

For $\|u_0\|\ll 1$, we have GWP. And
\begin{equation*}
    A=\{u_0\in L^2: \text{ we have GWP}\} 
\end{equation*}
note that
\begin{equation*}
    B(0,\epsilon)\subset A
\end{equation*}
\begin{proposition}
    $A$ is open.
\end{proposition}
\begin{proof}
    Exactly because $B(0,\epsilon)\subset A$. If you have an initial data such that you have GWP, then all data that lives in a small neigbhorhood of it, you still should get GWP.
\end{proof}

Now we try to move to the boundary of $A$, and $\|u\|_{L^p}\to\infty, p=\frac{2(n+2)}{n}$. Hence we take a point inside of $A$, very close to the boundary, and how can we make the $u$'s norm large?

We first note that we must have wave packets, and if we suppose that the wave packets are spread out in more than one direction: this is because we can separate the initial energy into these two packets, and their energy is small, and separate, they are nice solutions, with controlled strichartz norms. And our operator is sublienar, hence the overall strichartz norm is nicely bounded. When they intersect, the norm is already small due to decay, hence the norm is again, well-controlled. This cannot happen. (Hence there can exist only one wave packet in one direction at any given time, and that packet could propogate over time, but when you dissect it, you should still obtain a wave packet. )

And to prove the above, there are two approaches: one by Bourgain (95), which is the induction on energy; and the other is by contradiction, where we deal with the ``minimal enemy.''


\section{Lecture 10/17}
We were looking the two theorems last time.
\begin{theorem}[Mass critical NLS]
    \begin{enumerate}
        \item The defocusing problem is globally well-posed for any large $L^2$.
        \item The focusing problem is globally well-posed for any $L^2$ data with mass below the ground state.
    \end{enumerate}
\end{theorem}
The Strichartz norm $\|u\|_{L_{x,t}^\frac{2(n-2)}{n}}$, the proof for the theorem relies on
\begin{equation*}
    \|u\|_{L_{x,t}^\frac{2(n+2)}{n}}\leq F(\|u_0\|_{L^2})
\end{equation*}
Suppose we look at some mass, the conserved quantity
\begin{equation*}
    M=\int|u|^2dx
\end{equation*}
We now ask the \textbf{question}: for what mass $M(u_0)$ do we have a uniform bound for the above Strichartz norm.

From pertubation theory:
Suppose for some $M>0$, we have
\begin{equation*}\label{unifbound}
    \|u_0\|\leq M\Rightarrow \|u\|_{L^\frac{2(n+1)}{n}}\leq C
\end{equation*}
We then conclude there exists some small $\epsilon>0$, and $\tilde{c}\gg c$ such that
\begin{equation*}
    \|u_0\|\leq M+\epsilon\Rightarrow \|u\|_{L^\frac{2(n+1)}{n}}\leq\tilde{C}
\end{equation*}
We have that the set of $M$ which satisfies~\ref{unifbound}. This is done by the idea of Bourgain, i.e. \textbf{induction on energy}.
\begin{note}
    Perturbation is a good start, but does not solve the problem.
\end{note}

We shall now do a proof by contradiction. Denote by $\overline{M}$:
\begin{equation*}
    \overline{M}=\sup\{M\in\R^+: \text{~ref{unifbound} holds}\}
\end{equation*}
Assume \begin{equation*}
    \lim_{M\to\overline{M}}C(M)=\infty
\end{equation*}
then there exists a sequence of data $\{u_0^n\}$ such that
\begin{equation*}
    \|u_0^n\|\to\overline{M}, \|u^n\|_{L^\frac{2(n+2)}{n}}\to\infty
\end{equation*}
The following proof is separated into two steps:
The \textbf{first} is to look for a minimal blow-up solution
\begin{equation*}
    u=\lim_{n\to\inf}u_n
\end{equation*}
Then we show that such minimal blow up does not exist.

We begin the construction in step 1. The difficult question is that: how do we know that some sort of limiting solution $u$ exists? The answer is named ``concentration compactness argument.'' 

We first look at some solutions to the NLS, and use the fact that $L^2$ norm of $u_0^n$ converges to exactly $\tilde{M}$. Step 1 is compactness for solutions to linear Schrodinger. We ask the question can we have in general:
\begin{equation*}
    u^n\to u \text{ on a subsequence }
\end{equation*}
And normalize $\|u_0^n\|_{L^2}=1$. And such that $u_0^n\to u$ in $L^2$ weakly. But this limit can be 0, hence it cannot be done.

Now we assume $\|u^n\|_{L^p}\gtrsim 1$, and such subsequence still doesn't have to exist. Now we compile a list of obstructions to compactness:
\begin{enumerate}
    \item Spatial translations. Suppose you have a wave packet solution, and translate all the way to $\infty$, then in every weak limit, you get 0
    \item Time translations.
    \item Scaling symmetry. If we do \begin{equation*}
        u(t,x)\to\lambda^\alpha(\lambda^2t, \lambda x)
    \end{equation*} You can adjust the packet, making it thinner and longer or shorter and fatter, and still wouldn't converge.
    \item Galilean invariance. You can change the frequency
    \item Phase rotations. You can take $u\to ue^{i\theta}$. It doesn't obstruct compactness, but only gives you ways to extract subsequence.
\end{enumerate}
Let $g$ be the group of transformations, via compositions of elements of the above list. Each $G\in g$, we can have translation, scaling, change in velocity (i.e. translation in frequency $\xi_0$), $\theta_0$. Now we ask the better question: given our solutions $u^n$ to linear Schrodinger, can we find $G^n\in g$ such that
\begin{equation*}
    G^nu^n\to u\neq 0
\end{equation*}
\begin{note}
    This still doesn't work due to secondary obstructions.
\end{note}
Secondary obstruction: Let $u^1$ have two packets that are close to each other, $u^2$ has the same two packets, but are further and further away from one another, and $u^3$ even futher away. We call these packets profiles. 

Now our target has become: Profile decomposition. On a subsequence, we find some profiles $\phi_1, \phi_2, ...., \phi_k$ so that on a subsequence, we have
\begin{equation*}
    u^1=G^{11}\phi_1+G^{12}\phi_2+...+G^{1k}\phi_k+e^1
\end{equation*}
\begin{equation*}
    u^j=G^{j1}\phi_1+G^{j2}\phi_2+...+G^{jk}\phi_k+e^j
\end{equation*}
where $e_j$ denotes error. Now we ask how many profiles do we have, and the answer is that we can have infinitely many profiles, but if there are infinitely many ones, then we should expect some orthogonality among them.
\begin{equation*}
    \sum\|\phi_k(0)\|_{L^2}^2\leq 1
\end{equation*}
\begin{note}
    You don't want to deal with infinitely many of them, and we thus deal with this issue via controlling the error term. For all $\epsilon>0$, there exists $k_\epsilon$ such that
    \begin{equation*}
        \lim_{j\to\infty}\|e^j\|_{L^p}<\epsilon
    \end{equation*}
\end{note}

Of all the parameters, the scale parameter is the most important one $\lambda_0$. Once we have $\lambda\to (\delta_x)=\lambda^{-1}$, and $\delta\xi\approx\lambda$. Key condition is that $G^{jk}$ separates: different profiles go into different directions: so either we have
\begin{equation*}
    \lim_{j\to\infty}\left|\frac{\lambda^{j,k_1}}{\lambda^{j, k_2}}\right|+\left|\frac{\lambda^{j,k_2}}{\lambda^{j, k_1}}\right|=\infty
\end{equation*}
or we have
\begin{equation*}
    \frac{\lambda^{j,k_1}}{\lambda^{j,k_2}}\to (1, |x^{j, k_1}-x^{j, k_2}|)+|t^{j, k_1}-t^{j, k_2}|+|\xi^{j, k_1}-\xi^{j, k_2}|
\end{equation*}
\begin{note}
    The $L^2$ norm of $e_j$ does not go to zero.
\end{note}
And by almost orthogonality:
\begin{equation*}
    \|u^j\|_{L^2}^2\geq\|\phi_1\|_{L^2}^2+...\|\phi_k\|_{L^2}^2
\end{equation*}
where $\|u^j\|_{L^p}^p\approx\|\phi_1\|_{L^p}^p+...+\|\phi_k\|_{L^p}^p$. And some discussion for the energy critical problem, but without the Galilean invariance.

Stage 1: Sobolev embeddings. THere was a result by Gerand ('98). $\dot{H}^s\subset L^p$, and Gallaghea, $W^{s,p}$

Stage 2: Bahomi +Gerand ('99).
Stage 3: Schrodinger via energy
Stage 4: Schrodinger via mass.

Let's look at $H^1(\R^n)$ embeds into $L^p$, for $p=2^*$. And we have
\begin{equation*}
    \|u\|_{L^p}\leq\|u\|_{\dot{H}^1}
\end{equation*}
For $u^n\in\dot{H}^1$, we look for a convergence subsequence. For the group of symmetries: we have translations and scaling.

Each $g$, the group of symmetries, parametrized by $(x_0,\lambda_0)$, position and scale.
\begin{equation*}
    u(x)\to G_{x_0, \lambda_0, u}(x)=\lambda_0^\alpha\cdot u(\lambda(x-x_0))
\end{equation*}
Let $\|u^n\|_{\dot{H}^1}=1$, and look for
\begin{equation*}
    G^nu^n\to\phi_1
\end{equation*}
From all possible $G$'s, and choose the largest weak limit $\phi_1$.
\begin{equation*}
    u^n\to u^n-(G^n)^{-1}\phi_1=u^{n,1}
\end{equation*}
\begin{equation*}
    G^{n,1}u^{n,1}\to \phi_2 \text{ weakly in} H^1
\end{equation*}
First we would like to make sure that $\phi_j\neq 0$, and would also want profile separation.

How can we ensure that the $\phi_j$'s are not equal 0? We care about the $L^p$ norm, and if it is zero, it is fine, we just discard it. We would like dichotomy: either $\phi_1\neq 0$ or $\\u^n\|_{L^p}\to 0$ (the second case is where we have nothing to talk about).

Let's start with $u\in\dot{H}^1$, and we do Littlewood-Paley decomposition.
\begin{equation*}
    u=\sum_ku_k, \hat{u_k}\text{ supported in}|\xi|\approx 2^k
\end{equation*}
For
\begin{equation*}
    \|u\|_{\dot{H}^1}^2\approx\sum_k\|u_k\|_{\dot{H}^1}^2
\end{equation*}
where $\|u_k\|_{L^p}\lesssim \|u_k\|_{\dot{H}^1}\approx 2^k\|u_k\|_{L^2}$. First idea is that we look for $k$ where $u_k$ is largest. And we look at each $u_k$ one by one, and we have
\begin{equation*}
    \dot{H}^1\subset L^p\subset B_{\infty,\infty}^{1-\frac{n}{2}}
\end{equation*}
where $B$ stands for Bessel's space, and 
\begin{equation*}
    \|u\|_B=\sup_k\|u_k\|_{L^\infty}2^{k(1-\frac{n}{2})}
\end{equation*}
The key information is the following inequality, i.e. the interpolation inequality: \begin{proposition}[Gagliando-Niomeberg inequality]
    \begin{equation*}
        \|u\|_{L^p}^\frac{n}{2}\leq\|u\|_{\dot{H}^1}\|u\|_B^{\frac{n}{2}-1}
    \end{equation*}
    or for some $0<\theta<1$, we have
    \begin{equation*}
        \|u\|_{L^p}^\frac{n}{2}\leq\|u\|_{\dot{H}^1}^\theta\|u\|_B^{1-\theta}
    \end{equation*}
\end{proposition}
Suppose that we have the above inequality, and $\|u^n\|_{\dot{H}^1}=1$, and suppose that $\|u_n\|_{L^p}\geq\epsilon$, and GN implies that $\|u_n\|_B\geq\epsilon^a$. For the Bessel's norm being large, we have that there exists some $k$ such that $\|u_k\|_\infty$ is large. In other words, for each $n$, there exists $k_n$ such that $\|u_{k_n}^n\|_{L^\infty}\geq\epsilon^a 2^{k_n(1-n/2)}$. Then $u^n$ converges to $G_{2^k_n}u_n$, which we can assume for $k_n=1$.
Now $k_n=1$, and $\|u_1^n\|_{L^\infty}\geq\epsilon^a$, and there exists $x^n$ such that
\begin{equation*}
    |u_1^n(x_n)|>\epsilon^a
\end{equation*}
and translate by $x_n$, we have
\begin{equation*}
    |u_1^n(0)|\geq\epsilon^a
\end{equation*}
which implies $\phi_1(0)\neq 0$. And it does not go to 0.


\section{Lecture 10/19}

We will show the interpolation inequality:
\begin{equation*}
    \|u\|_{L^p}\leq\|u\|_{\dot{H}^1}^\theta\|u\|_{\dot{B}^{1-n/2}}^{1-\theta}
\end{equation*}
Easy case: let $p$ be an even integer.
We would like to evaluate: 
\begin{equation*}
    \int |u|^p dx
\end{equation*}
and for the Littlewood-Paley decomposition of it,
\begin{equation*}
    u=\sum_k u_k
\end{equation*}
where each $u_k$ is on the scale of $2^k$, and 
\begin{equation*}
    \|u\|_B\approx 2^{k(1-n/2)}\|u_k\|_{L^\alpha}
\end{equation*}
For different frequencies, we generate
\begin{equation*}
    \int |u|^pdx=\int u_{k_1}...u_{k_p}dx
\end{equation*}
where the first two frequencies dominate. Hence the RHS now is
\begin{align*}
    \|u_{k_1}\|_{L^2}\|u_{k_2}\|_{L^2}...\|u_{k_p}\|_\infty&\leq 2^{-k_1}2^{-k_2}\|u_{k_1}\|_{\dot{H}^1}\|u_{k_2}\|_{\dot{H}^1}\cdot\prod\|u_{k_j}\|_\infty\\
    &\leq 2^{-k_1}2^{-k_2}\|u_{k_1}\|_{\dot{H}^1}\|u_{k_2}\|_{\dot{H}^1}\|u\|_B^[p-2]\\
    &\leq\sum_{k_1=k_2}\|u_{k_1}\|_{\dot{H}^1}\|u_{k_2}\|_{\dot{H}^1}2^0\|u\|_B^{p-1}
\end{align*}
where the first term is just $\|u\|_{\dot{H}^1}^2$.

Now for noninteger $p$, we would like to do continuous Littlewood-Paley decomposition. The idea is $u=\sum_ku_k$.
\begin{equation*}
    u=\lim_{k\to\infty}P_{<k}u, k\in\R
\end{equation*}
\begin{equation*}
    u=\int_{-\infty}^\infty \frac{d}{dk}P_{<k}udk\Rightarrow u=\int u_kdk
\end{equation*}
Now we are integrating with respect to the frequency.
\begin{equation*}
    |u|^p=\int\frac{d}{dk}|u_{<k}|^pdk=\int u_k|u_{<k}|^{p-1}dk
\end{equation*}
This gives us that
\begin{equation*}
    \int_{-\infty}^\infty u_k\int_{-\infty}^\infty u_j|u_{<j}|^{p-2}dkdj
\end{equation*}
Which we have
\begin{equation*}
    \leq \int_{j<k}2^{-k}\|u_k\|_{\dot{H}^1}2^{-j}\|u_j\|_{\dot{H}^1}2^{<j}\|u\|_B^{p-2}\leq \int_{j<k}2^{j-k}\|u_k\|\|u_j\|dkdj\|u\|_B^{p-2}
\end{equation*}
\begin{note}
    The gives the restriction that $p\geq 2$, and we indeed have this for the Sobolev embedding to work.
\end{note}
The moment that $j,k$ separates, we get exponential decay, which essentially forces $j$ and $k$ to be equal (in some sense).

Now we ask the question: why are the $L^p$ norms separating? $\phi$ is the weak limit of $u^n$ (note $G^n$ do not do anything so we ignore it):
\begin{equation*}
    u^n=\phi+u^n-\phi
\end{equation*}
and 
\begin{equation*}
    |u^n|^p=|\phi|^p+|u^n-\phi|^p+\text{ mixed terms }\leq\delta
\end{equation*}
we have 
\begin{equation*}
    \|\phi_{\geq k_0}\|\leq\delta^100
\end{equation*}
\begin{equation*}
    u^n=u_{\geq k_1}^n+u_{\leq k_1}^n
\end{equation*}
and the second term $\|u_{\leq k_1}^n$ weakly converges to $\phi_{\leq k_1}$. For the mixed terms, we have
\begin{equation*}
    u_{\geq k_1}^n\cdot\phi_{\leq k_0}(\cdot)^{p-2}
\end{equation*}

\subsection{Profile decomposition for linear Schrodinger}
Suppose that we have
\begin{equation*}
    \|u_0^n\|_{L^2}=1, \|u^n\|_{L^p}=\epsilon, p=\frac{2(n+2)}{n}
\end{equation*}
You want to show your solution contains something that looks like a wave packet. To identify wave packets: we reply and frequency $\xi_0, \partial\xi$  and time
\begin{equation*}
    (t_0, x_0), \delta x=(\delta\xi)^{-1}
\end{equation*}
and $\delta t=(\delta x)^2$ by parabolic scaling.
\begin{equation*}
    G(e^{it\Delta}\phi)\phi\in L^2
\end{equation*}
and 
\begin{equation*}
    \|u\|_B=\sup_{Q\in\mathcal{Q}}|Q|^\alpha\|u_Q\|_{L^{p_1}}
\end{equation*}
where $\mathcal{Q}$ is the dyadic cubes. For $p_1>p$, we get the following Berstein inequality
\begin{equation*}
    \|u_Q\|_{L^{p_1}}\leq|Q|^\alpha\|u_Q\|_{L^p}
\end{equation*}
\begin{proposition}[Key estimate-Keenrani]
    \begin{equation*}
        \|u\|_{L^p}\leq\|u_0\|_{L^2}^{\theta}\|u\|_B^{1-\theta}
    \end{equation*}
\end{proposition}
Once we have the key estimate, we have $\|u\|_{L^p}=\epsilon$, and $\|u_0\|_{L^2}=1$, which makes
\begin{equation*}
    \|u\|_B^{1-\theta}\geq\epsilon^\alpha
\end{equation*}
by $\|u\|_B=\sup_Q|Q|^\alpha\|u_Q\|_{L^{p_1}}$, this implies there exists one $Q$ such that $u_Q$ concentrates.
\begin{proof}
    \begin{equation*}
        \|u\|_{L^p}^p=\|u\cdot u\|_{L^{p/2}}^{p/2}
    \end{equation*}
    Now the RHS turns into a bilinear estimate, where $u$ is concentrated at $\xi_1$, the next $u$ is concentrated at $\xi_2$.

    If $\xi_1$ and $\xi_2$ are far away from each other, then
    \begin{equation*}
        u\cdot u=\sum_{Q,Q'\in\mathcal{Q}}u_Q\cdot u_{Q'}
    \end{equation*}
    and $|Q|=|Q'|=d(Q,Q')^n$. Via computation, one could treat these sums as disjoint, and almost orthogonal in $L^2$ since their Fourier supports are disjoint.

    If you add two things of the same frequency up, you get outside the parabola $\tau=\xi^2$, but then you create a larger parabola. $1/2(\xi_1+\xi_2)^2$,
    \begin{equation*}
        (\xi_1, \xi_1^2)+(\xi_2, \xi_2^2)=(\xi_1+\xi_2, \frac{1}{2}(\xi_1+\xi_2)^2)+(0, \frac{1}{2}(\xi_1-\xi_2)^2)
    \end{equation*}
    If they are almost $L^2$ orthogonal, we have that
    \begin{equation*}
        \|u^2\|_{L^2}^2\lesssim \sum_{Q,Q'}\|u_Qu_{Q'}\|_{L^2}^2
    \end{equation*}
    We have the trivial estimates:
    \begin{equation*}
        \|u^2\|_{L^1}\lesssim \sum_{Q,Q'}\|u_Qu_{Q'}\|_[L^1]
    \end{equation*}
    By interpolation, we get that
    \begin{equation*}
        \|u^2\|_{L^r}^r\leq\sum_{Q,Q'}\|u_Qu_{Q'}\|_{L^r}^r, 1\leq r\leq 2
    \end{equation*}
    For $n=1$, $p=6$, and is an even number, so we argue as before. For $n=2$, $p=4$.

    And
    \begin{equation*}
        \|u_Qu_{Q'}\|_{L^{p/2}}
    \end{equation*}
    For $n=1$, we have
    \begin{equation*}
        \|u_Qu_{Q'}\|_{L^2}\leq|Q|^{-1/2}\|u_{0Q}\|_2\|u_{0Q'}\|_2
    \end{equation*}
    we compare this to
    \begin{equation*}
        \|u_Qu_{Q'}\|_{L^3}\leq\|u_{0Q}\|_{L^2}\|u_{0Q'}\|_{L^2} (Strichartz)
    \end{equation*}
    Now we use bilinear restriction theorem:
    \begin{equation*}
        \|u_Qu_{Q'}\|_{L^\frac{n+3}{n+1}}\leq |Q|^r\|u_{oQ}\|_{L^2}\|u_{0Q'}\|_{L^2}
    \end{equation*}
    And we further have
    \begin{equation*}
        \|u_Qu_{Q'}\|_{L^{p/2}-}\leq|Q|^r\|\widehat{u}_{0Q}\|_{L^{2-}}\|\widehat{u}_{0Q'}\|_{L^{2-}}
    \end{equation*}
    Hence 
    \begin{equation*}
        \|u_Q\|_{L^\infty}\leq|Q|^r\|\widehat{Q}_{0Q}\|_{L^1} (\check{L_1}\subset L^\infty)
    \end{equation*}
    and $\|u_Qu_{Q'}\|_{L^\infty}\leq |Q|^r\|\cdot\|_{L^1}\|\cdot\|_{L^1}$.
\end{proof}

\section{Lecture 10/26}
Enhanced version of strichartz estiamtes.
We would like to shwo the following: let $Q$ be cubes in the Fourier space, and for $p=\frac{2(n+2)}{n}$,
\begin{theorem}
   \begin{equation*}
     \|u\|_{L^p}\leq\|u_0\|_{L^2}^{1-\theta}\sup_Q|Q|^\alpha\|u_Q\|_{L^{p+}}
   \end{equation*}
\end{theorem}
Last time, we showed that
\begin{equation*}
    \|u\|_{L^p}^p=\|u\cdot\|_{L^{p/2}}^{p/2}\leq\sum_{Q, Q'\in\mathcal{Q}}\|u_Q\cdot u_{Q'}\|_{L^{p/2}}^{p/2}
\end{equation*}
where
\begin{equation*}
    \mathcal{Q}=\cup_jQ_j\to 2^j\mathbb{Z}^n
\end{equation*}
And
\begin{equation*}
    |Q|=|Q'|\approx d(Q,Q')
\end{equation*}
And the main tool that we used was the bilinear theorem.
\begin{theorem}[Bilinear restriction theorem]
    \begin{equation*}
        \|u_Q\cdot u_{Q'}\|_{L^\frac{n+3}{n+1}}\leq|Q|^\alpha\|u_Q(0)\|_{L^2}\|u_Q'(0)\|_{L^2}
    \end{equation*}
    where $\frac{n+3}{n+1}\leq\frac{p}{2}$, so this is a stronger estimate.
\end{theorem}

And we do the interpolation with the Berstein inequality:
\begin{equation*}
    \|u_Qu_{Q'}\|_{L^{p/2-}}\leq\|\hat{u}_Q(0)\|_{L^r}\|\hat{u}_{Q'}(0)\|_{L^r}, r=2-    
\end{equation*}
And note that we have
\begin{equation*}
    \|u\|_{L^p}^p\leq\sum_{Q,Q'}\|u_Qu_{Q'}\|_{L^{p/2}}^{p/2}\leq\sum_{Q,Q'}|Q|^\alpha\|u_Qu_{Q'}\|_{L^{p/2-}}^{1+}\|u_Qu_{Q'}\|_{L^{p/2}+}^{\beta}|Q|^{-\alpha}, \beta>0
\end{equation*}
Noet that now $L^{p/2+}, L^{p/2-}$ do not have the same scaling, hence we add some extra $|Q|^\alpha$ to keep the scaling the same.

Now we have, by Berstein's inequality,
\begin{equation*}
    \leq\sum_{Q,Q'}|Q|^\alpha\|\hat{u}_{Q}(0)\|_{L^r}^{1+}\|\hat{u}_{Q'}(0)\|_{L^r}^{1+}\cdot\sup|Q|^{-\alpha}\|u_Q\|_{L^{p+}}^p\leq\sum_Q|Q|^\alpha\|\hat{u}_Q(0)\|_{L^r}^{2+}\cdot\sup()
\end{equation*}
\begin{note}
    The sum is taken over dyadic cubes of all scale, i.e. a cube of size $2^n$, then $2^{n+1}$, etc.
\end{note}
Now it remains to show that
\begin{equation*}
    \sum_Q|Q|^\alpha\|\hat{u}_Q(0)\|_{L^r}^{2+}\leq\|\hat{u_0}\|_{L^2}^{2+}
\end{equation*}
Now in a single cube, we have
\begin{equation*}
    |Q|^\alpha\|\hat{u}_Q\|_{L^q}\leq\|u_Q\|_{L^2}
\end{equation*}
And 
\begin{equation*}
    u_Q=\sum_ku_{Q,k}, u_{Q,k}=u_Q\cdot 1_{\{|u_Q|\approx 2^k|Q|^\beta}
\end{equation*}
where $\beta=\alpha+\frac{1}{2}$. Now we would like to show
\begin{equation*}
    LHS(1)\leq\sum_k\sum_Q|Q|^\alpha\|\hat{u}_{Q,k}\|_{L^r}^{2+}\leq\sum_k2^{-c|k|}\|u_0\|_{L^2}^{2+}
\end{equation*}
Note that we have different gains from $k$ being positive and negative.

Now $k\geq 0$,
\begin{equation*}
    \||Q|^\alpha u_{Q,k}\|_{l_Q^{2+}L^{r}}^2\leq 2^{-c|k|}\|u_0\|_{L^2}^2
\end{equation*}
where $r=2-$
\begin{equation*}
    \|u_{Q,k}\|_{L^r}^4=\int_Qu_{Q,k}^r\leq\int_Qu_{Q,k}^2\cdot|u_{Q,k}|^{r-2}\leq\|u_{Q,k}\|_{L^2}^2\cdot 2^{-c|k|}|Q|^{?}
\end{equation*}
And we also have
\begin{equation*}
    \||Q|^\alpha u_{Q,k}\|_{l_Q^{2+}L^r}^r\leq\|Q^\alpha u_{Q,k}\|_[l^rL^r]^r\leq\sum_{Q}\int_Q|u_{Q,k}|^22^{-ck}\leq\|u\|_{L^2}^2\cdot 2^{-ck}
\end{equation*}
Note there is not power of $|Q|$ on the RHS here, hence by scaling, we also have $?=0$.
\begin{note}
    Note in the final equation, our $u_{Q,k}$ are no longer overlapping. If we have
    \begin{equation*}
        u_{Q,k}(x)\neq 0, \xi\in Q, \sim |Q|^\alpha
    \end{equation*}
\end{note}

For $k\leq 0$, we have
\begin{equation*}
    \|u_{Q,k}\|_{L^r}^{2+}\leq|Q_k|^?\|u_{Q,k}\|_{L^{2+}}^{2+}
\end{equation*}
And we have
\begin{equation*}
    \|Q^\alpha u_{Q_k}\|_{l_Q^{}L^r}^{2+}\leq\||Q^\alpha||Q_k|^?u_{Q,k}\|_{l^{2+}L^{2+}}^{2+}
\end{equation*}
Hence we have this 
\begin{equation*}
    =\sum_Q|Q|^\alpha|Q_k|^?|u_{Q,k}|^{2+}\leq\sum_Q|Q^\alpha||Q|^?\int u_{Q,k}^22^{ck}|Q|^?
\end{equation*}
Hence we've obtained a $2^{-c|k|}$ gain in both cases, proving the claim.
\qed

Now we go back to the profile decomposition for the energy critial problem.
\begin{equation*}
    \|u\|_{L^\frac{2(n+2)}{n-2}}\leq\|\nabla u(0)\|_{L^2}
\end{equation*}
and via scaling, the $p$ satisfies $n/2-1=(n+2)/p$. Now we ask what are the sharp counterexamples? Answer: wave packets! However, the exponent on LHS is not sharp, since the sharp strichartz does not have derivatives on the RHS.

Sharp Strichartz estimates, to go down a derivative, we apply Berstein's inequality. Hence in order for strichartz

Wave packets are supported in a cube, and consider fitting the cube in the annulus (dyadic annulua):
\begin{enumerate}
    \item If you have a small cube, then you a factor of the size of the cube (hence you gain if you use small cubes)
    \item If you have a tube exactly of the size of the frequency, if $l(Q)=\xi=2^k$, then $\delta_x\approx 2^{-k}$, then $\delta_t=2^{-2k}$
\end{enumerate}
If we look at
\begin{equation*}
    iu_t=\Delta u
\end{equation*}
and the $\Delta$ is $2^{2k}$ (almost like a diract mass, and doesn't spread for a while). 
\begin{note}
    We cannot apply Galilean invariance, since you might land in a dyadic interval that is too high of frequency.
\end{note}

Now we look at the group of symmetries,
\begin{equation*}
    g=\{translation, saling, phase rotation\} 
\end{equation*}
if you have the profile decomposition for $u$,
\begin{equation*}
    u=\sum G_k^j\phi_j+e_k
\end{equation*}
where the error $e_k\to 0$ in $L^\frac{2(n+2)}{n-2}$.

Recall that we have this critical mass:
\begin{proposition}
   For each $\epsilon>0$, there exists some $C_\epsilon$, such that
    \begin{equation*}
        M(u_0)\leq A-\epsilon
    \end{equation*}
    there exists a global solution $u$ such that
    \begin{equation*}
        \|u\|_{L^\frac{2(n+2)}{n}}\leq C_\epsilon
    \end{equation*}
    
\end{proposition}
Now the question is that: what happens at critical mass?

\textbf{Answer}: by perturbation theory, we should have 
\begin{equation*}
    \lim_{\epsilon\to 0}C_\epsilon=\infty
\end{equation*}
Because if it doens't, then we can push $A$ up. Let $\epsilon=\frac{1}{k}$, we have
\begin{equation*}
    M(u_k)=A-\frac{1}{k}, \|u_k\|_{L^\frac{2(n+2)}{n}}\to \infty
\end{equation*}

On a subsequence, 
\begin{equation*}
    u_k(0)\to u(0) \text{ in } L^2
\end{equation*}
This should mean that, if you have a convergence subsequence,
\begin{equation*}
    \|u\|_{L^\frac{2(n+2)}{n}}=\infty
\end{equation*}
There are two problems:
\begin{enumerate}
    \item The convergence of the subsequence is hard, i.e. compactness.
    \item The information that $\|u\|_{L^\frac{2(n+2)}{n}}$ is insufficient.
\end{enumerate}

But if all of this work, then we call for the solution $u$ the minimal enemy (it has exactly this critical mass, and yet it blows up in the norm).

Note that $u_k$ is global solutions, and there should be local stability, and this $u$ exists at least locally. Yet, there is no way of knowing this is a global solution.
\begin{equation*}
    u_k\to u
\end{equation*}
in intervals of existence for $u$.

Next time, we will start with the sequence and how to obtain compactness/convergence.
\begin{note}
    To get convergence, we need to apply some rotation/symmetry, such that
    \begin{equation*}
        G^ku_k(0)\to u(0)\text{ in } L^2
    \end{equation*}
\end{note}


\section{Lecture Oct 31}
We will talk about minimal blow-up solutions, or in other words, the minimal enemies. (The strichartz norm is $\infty$, but they themselves do not necessarily blow up).

\begin{enumerate}
    \item Mass critical NLS
    \item Minimal blow-up mass $A$.
    \begin{equation*}
        \|u_0\|\leq A\cdot\epsilon
    \end{equation*}
    This implies global solution with 
    \begin{equation*}
        \|u\|_S\leq F_\epsilon
    \end{equation*}
    \item Limiting sequence $\{u_n\}$ such that
    \begin{equation*}
        \|u_{n_0}\|_{L^2}\to A, \|u_n\|_{L^p}\to\infty
    \end{equation*}
\end{enumerate}
Look for a limit 
\begin{equation*}
    u=\lim u_n
\end{equation*}
\begin{note}
    This limit is modulo symmetries  (you could apply symmetric transformations)
\end{note}

Our profile decomposition for $u_n$: (we've only done it for the linear case) $u_{n_0}$. 
\begin{equation*}
    u_{n_0}\to u_n^{lim}
\end{equation*}
And we do profile decomposition for $u_{n_0}$, 
\begin{equation*}
    u_n^{lim}=\sum_{j=1}^J G_n^j\phi_j+r_n
\end{equation*}
Now we have two scenarios, if $J$ is fixed, and 
\begin{equation*}
    \|r_n\|_{L^p}\to 0
\end{equation*}
Or $J$ could be arbitrary large, then
\begin{equation*}
    \lim_{J\to\infty}\limsup_{n\to\infty}\|r_n\|_{L^p}=0
\end{equation*}
\begin{note}
    We do not expect to have any sort of convergence.
\end{note}

Compactness modulo symmetries. 
Note that compactness would have a single profile $\phi_1$, and we would like to let it have all the mass. Moreover,
\begin{equation*}
    M(\phi_1)=A, \|r_n(0)\|_{L^2}\to 0
\end{equation*}

\begin{remark}
    We know that $\sum_{j=1}^J\|\phi_j\|_{L^2}^2\leq A$, since the group of symmetries allow the profiles to be decomposed in an almost orthogonal fashion.
\end{remark}
And note that this is not arbitrary, since $A$ is exactly the minimum blow-up mass.
\begin{proposition}
    The above holds.
\end{proposition}
\begin{proof}
    We shall do this via contradiction. Assume either two or more profiles $\phi_1, \phi_2, ...$, or we assume there exists one profile $\phi$ but this profile does not have maximal mass.

    Because of orthogonality, we have
    \begin{equation*}
        \sup_j\|\phi_j\|_{L^2}^2<A
    \end{equation*}
    And note that this $\phi_j(0)$ generates a global solution to NLS.

    Now we ask the question, can we put these together for our original NLS to get a new solution? 
    \begin{note}
        We will contradict the fact that $\|u_n\|_{L^p}\to\infty$. 
    \end{note}
    We have that
    \begin{equation*}
        \|\phi_j^{lim}\|_S\leq C
    \end{equation*}
    We try an approximate solution, $u^{ap}$, 
    \begin{equation*}
        u^{ap}\approx G_n^j\phi_j+r+n
    \end{equation*}
    The first term would be a nonlinear wave, and $r_n$ a linear wave with a small Strichartz norm. 
    \begin{problem}
        Now if we add this up, do we get a good approximate solution?
    \end{problem}
    The answer is indeed yes. We have $\|\phi_j\|_{L^p}\leq C$, And
    \begin{equation*}
        \|\phi_j\phi_k\|_{L^{p/2}}\leq C
    \end{equation*}
    \begin{equation*}
        \|G_n^j\phi_jG_n^k\phi_k\|_{L^{p/2}}\to 0
    \end{equation*}
    The reason the above would tend to 0 is because the profiles are separated. Let's first think about the group of translations. For example, you apply translation on $\phi_2$ which would result in $\phi_1, \phi_2$ being further away from each other, hence their products have small norm.    

    \begin{equation*}
        (i\partial_t+\Delta)u^{ap}-u^{ap}|u^{ap}|^p=\sum(i\partial_t+\Delta)G^j\phi_j-G^j\phi_j|G^\phi_j|^p+ \text{ mixed terms }+ (i\partial_t+\Delta)r-r|r|^p
    \end{equation*}
    We note that $\sum(i\partial_t+\Delta)G^j\phi_j-G^j\phi_j|G^\phi_j|^p$ and $(i\partial_t+\Delta)r$ both vanish, and hence it remains to bound the mixed terms, and $r|r|^p$ error term. For the mixed terms, we use separation, and $r|r|^p$, we use smallness

    We have the following:
    \begin{equation*}
        u^{ap}(0)=\sum G^j\phi_j(0)+r(0)
    \end{equation*}
    We would like to have the following:
    \begin{equation*}
        u(0)=\sum G^j\phi_j^{lim}(0)+r(0)
    \end{equation*}
    \textbf{Difficulty:} We have a mismatch between linear and nonlinear flows of $\phi$, and  a mistmatch between the initial data $u(0), u^{ap}(0)$.

    We separate the group of transformations, as being $T_t$, a time translation, and everything that is not a time translation $g_0$.
    \begin{equation*}
        G=G_0T_t=T_{\tilde{t}}G_0
    \end{equation*}

    \begin{equation*}
        u_n=\sum_j G_{n_0}^jT_{t_{nj}}\phi_j+r_n
    \end{equation*}
    Either we have $t_{nj}\to t_j$, or $t_{nj}\to+\infty$, and $t_{nj}\to -\infty$. For the first case, We can replace $\phi_j$ by $T_{t_j}\phi_j$, and we end up with $t_j=0$. This is $0_\phi=0_u$, hence this case is done.

    If $t_{nj}\to-\infty$, then $\phi_j^{nlim}$ represents the solution to the NLS such that
    \begin{equation*}
        \lim_{t\to-\infty}\phi_j^{nlim}(t)-\phi_j^{lim}(t)=0
    \end{equation*}
    This implies that $\phi_j(0)$ serves as scattering data for $\phi_j^{nlim}$. 

    Similarly, if $t_{nj}\to+\infty$, we have
    \begin{equation*}
        \lim_{t\to\infty}\phi_j^{nlim}-\phi_j^{lim}(t)=0
    \end{equation*}
    Eventually, we have solutions $\phi_j^{nlin}$ and the approximate solution $u^{ap}$, 
    \begin{equation*}
        u_n^{ap}=\sum_jG_n^j\phi_j^{nlin}+r^{lin}
    \end{equation*}
    with the property such that $u_n^{ap}$ is an approximate solution, and 
    \begin{equation*}
        \|(i\partial_t+\Delta)u_n^{ap}-u_n^{ap}|u_n^{ap}|^p\|_{S^1}\leq\epsilon
    \end{equation*}
    And also 
    \begin{equation*}
        \|u_n^{ap}(0)-u(0)\|_{L^2}\lesssim\epsilon
    \end{equation*}
    And another piece of information:
    \begin{equation*}
        \|u_n^{ap}\|_{L^p}\lesssim C
    \end{equation*}
    where $C$ is some universal constant, independent of $n$. $\epsilon$ can be made arbitrarily small.

    \begin{proposition}
        Near the approximate solution $u^p$ which satisfies the above three properties, there exists an exact solution, with initial data $u_0$, and is global and satisfies $\|u_n\|\leq 2C$. (This is perturbation theory).
    \end{proposition}
    \begin{proof}
        Let $v=u_n-u^{ap}$, we shall write down an equation for $v$:
        \begin{equation*}
            (i\partial_t+\Delta)v=(i\partial_t+\Delta)(u-u_n)=u|u|^p-u_n|u_n|^p+(\text{ source term }<\epsilon)
        \end{equation*}
        We have $\|v(0)\|_{L^2}\leq\epsilon$. Now we write $u=u^{ap}+v$.

        The above difference gives
        \begin{equation*}
            v|u^{ap}|^p+O(v^2)
        \end{equation*}
        and the second term is small (perturbative). Note $v$ is about $\epsilon$, but $|u^{ap}|^p$ does not have to be small. We fix this incrementally. (If you have a time interval such that the overall $L^p$ norm is small, then you could dissect them into intervals such that on each of the interval, they are small).

        Let $R=\bigcup_j I_j$, and for $\delta$ sufficiently small
        \begin{equation*}
            \|u^{ap}\|_{L^p(I_j\times\R^n)}\leq\delta
        \end{equation*}
        In each of the $I_j$, we have $v\cdot|u^{ap}|^p$ is small.
        \begin{equation*}
            t_0=0, t=t_1, \|v(t_1)\|\leq 2\|v(t_0)\|
        \end{equation*}
        Luckily, we only have to do this finitely many times, say $u_n^{ap}\|_{L^p}\leq C$, then you break them into $C/\delta$ intervals. 
        \begin{equation*}
            \|v\|_s\leq \epsilon 2^{C/\delta} 
        \end{equation*}
    \end{proof}
    \qed
    Note that our solution has Strichartz estimate $\|u_n\|\leq 2C$, and it does not tend to $\infty$, as it should, hence contradiction.
\end{proof}
\qed

Thus, we obtain compactness. This implies:
On a subsequence, we have $\phi$
\begin{equation*}
    \phi(0)=\lim_{n\to\infty}G^n u_n \text{ strongly in } L^2
\end{equation*}
This implies that 
\begin{equation*}
    \|\phi(0)\|_{L^2}^2=A
\end{equation*}
The next claim we will make is that
\begin{equation*}
    \|\phi^{nlin}\|_{L^p}=\infty
\end{equation*}
We know for $u_n$, $\|u_n\|_{L^p}\to\infty$, however, we can argue backwards. If $\|\phi^{nlin}\|_{L^p}=\infty$, then we can construct $u^n$ perturbatively, with
\begin{equation*}
    \|u_n\|_{L^p}\leq C
\end{equation*}

We look at $u(0)$, the initial data, and treat $u(t)$ as initial data at time $t$, and 
\begin{equation*}
    u(t_n+t)
\end{equation*}
would play the role of $u^n$. And we do profile decomposition on this sequence. Note that this sequence $u(t_n+t)$ will converge after some translation by $g$. On a subsequence, 
\begin{equation*}
    G_0(u(t_n))\to v \text{ in } L^2
\end{equation*}
This implies for each sequence $t_n$, there exists $G_0^n$ such that 
\begin{equation*}
    G_0^nu(t_n)\to\phi \text{ in } L^2 \text{ on a subsequence}
\end{equation*}
This implies that 
\begin{equation*}
    \{u(t): t\in I_u\} \text{ is compact modulo symmetries } g_0
\end{equation*}
This is the same as saying that there exists some group of transformations $G_0^n(t)$ such that 
\begin{equation*}
    G_0^n(t)u(t) \text{ is compact in } L^2
\end{equation*}
This implies if we look at $G_0^n(t)$, this takes a compact set in $L^2$, translates in the physical, Fourier space, and scales it. Now if we pull $G_0^n(t)$, center $x(t)$, we can pull frequency center $\xi(t)$, given by Galilean transform, and the scale $N(t)=\delta\xi(t)$, which is the frequency scale. Now, the scale in frequency and spatial are opposite, hence $N^{-1}(t)$ represents the spatial scale.

From compactness, we get for all $\epsilon>0$, there exists some $R_\epsilon$ such that 
\begin{equation*}
    \|u(t)\|_{L^2(\R^n\setminus B(x(t),R_\epsilon N^{-1}(t)))}\leq\epsilon
\end{equation*}
\begin{equation*}
    \|\hat{u}(t)\|_{L^2(\R^n\setminus B(x(t), R_\epsilon N(t)))}\leq\epsilon
\end{equation*}
This implies compactness and is gained also from compactness.

This is an equivalent formulation of compactness.


\section{Lecture Nov 2}
Let $A$ be the critical mass, and $u$ be the minimal enemy, and 
\begin{equation*}
    M(u)=A
\end{equation*}
And
\begin{equation*}
    \|u\|_{L^\frac{2(n+2)}{n}}=\infty
\end{equation*}
and $\{u(t),t\in I\}$.
For all $t$, there exists $x(t), \xi(t), N(t)$, with
\begin{equation*}
    \delta x=N(t)^{-1}, \delta\xi=N(t)
\end{equation*}
\begin{equation*}
    \|u(t)\|_{L^2(B(x(t), R_\epsilon N^{-1}))}\leq\epsilon
\end{equation*}
and 
\begin{equation*}
    \|\hat{u}(t)\|_{L^2(B(\xi, R_cN)^c)}\leq\epsilon
\end{equation*}

Recall our NLS:
\begin{equation*}
    i\partial_t+\Delta u=\pm u|u|^p
\end{equation*}
Now we ask the question how fast can $x(t), \xi(t), N(t)$ change? Fix some $t_0=0$, we can set 
\begin{equation*}
    x(0)-0, \xi(0)=0, N(0)=1
\end{equation*}
$u_0$ localized around 0 in position, and frequency on the unit scale.
\begin{equation*}
    u_0=u_{01}+u_{02}
\end{equation*}
We apply $e^{it\Delta}$. There exists a solution $u$ in $[0,T]$ for $T\ll 1$.

\begin{equation*}
    u=e^{it\Delta}u_{01}+O(\epsilon)
\end{equation*}
For $t\in [0,T]$, and we can still take
\begin{equation*}
    x(t)=O(1), \xi(t)=O(1), N(t)=1+o(1)
\end{equation*}
And we have
\begin{equation*}
    \xi(t)=\xi(0)+O(N), N(t)=N(0)(1+o(1)), x(t)=x(0)+2t\xi(0)+O(N^{-1})
\end{equation*}
for $t\in [0,N^{-2}]$.
\begin{equation*}
    \left|\frac{d}{dt}N(t)\right|\leq N(t)\cdot N^2(t)=N^3(t)
\end{equation*}
and note 
\begin{equation*}
    \left|\frac{d}{dt}\xi(t)\right|\lesssim N(t)\cdot N^2(t)=N^3(t)
\end{equation*}
And finally for $x(t)$,
\begin{equation*}
    \left|\frac{d}{dt}x(t)-2\xi(t)\right|\leq N^{-1}(t)\cdot N^2(t)=N(t)
\end{equation*}
For $\widehat{u}(t)$, we choose $r$ such that
\begin{equation*}
    \sup_{B\in B_r}\|\widehat{u}(t)\|_{L^2(B_r)}^2=\frac{1}{2}\|\widehat{u}\|_{L^2}
\end{equation*}
We have
\begin{equation*}
    \|u\|_{S(I_j)}\approx 1, \|N(u)\|_{N(I_j)}\approx 1, \|u\|_{L^p(J)}^p\leq\int_JN(t)^2dt
\end{equation*}
And assume this converges to some $\tilde{u}(t)$,
\begin{equation*}
    G_0(t_n)(u(t+t_n))\to \tilde{u}(t)
\end{equation*}
We ask the question: can we choose $t_n$ such that in the limit as $t\to\infty$, we get another minimal enemy $\tilde{u}$ with more control over the behavior of $N(t)$.
\begin{note}
    We will use two simpler cases.
\end{note}
\begin{problem}
    What should $N$ do such our problem blows up?
\end{problem}
Blow up if and only if $N(t)\to\infty$, and is when the frequency scale is large, and when the spatial scale is tiny, and that blows up.

We look at $N(t)$ around $t_0$. We know that 
\begin{equation*}
    N(t)\approx N(t_0) \text{ if } |t-t_0|\ll N(t_0)^{-2}
\end{equation*}
We rescale it so $t_0=0$, and $N(t_0)=1$, and we would get 
\begin{equation*}
    N(t)\approx N(0), |t|\leq R
\end{equation*}
Fix $R$, we define the oscillation of $N$,
\begin{equation*}
    osc_R(N)=\frac{\int\{N(t), |t-t_0|\leq RN(t_0)^{-2}\}}{\sup \{N(t), |t-t_0|\leq RN(t_0)^{-2}\}}
\end{equation*}
Now we have two scenarios.

\textbf{Scenario 1}
\begin{equation*}
    \lim_{R\to\infty}osc_R(N)>0 \Rightarrow N(t)\approx 1
\end{equation*}
We have reduced to the case where $osc_R(N)\to 0$ as $R\to\infty$. For each $t_0$, look at
\begin{equation*}
    \inf_{t_0}\alpha(t_0)=\frac{\inf\{N(t), t<t_0\}+\inf\{N(t), t>t_0\}}{N(t_0)}
\end{equation*}
If $\inf_{t_0}\alpha(t_0)=0$.

\textbf{Scenario 2}
We have $N(0)=1, N(t)\to 0$ at $\pm\infty$. Remaining scenario:
\begin{equation*}
    osc(R)\to\infty \text{ as } R\to\infty
\end{equation*}
And 
\begin{equation*}
    \alpha(t_0)\geq c>0, \forall t_0
\end{equation*}
The bad case is that
\begin{equation*}
    N(t)\geq cN(t^{-}), t>t^{-1}, N(t)\geq cN(t^+), t<t^+
\end{equation*}
This gives that
\begin{equation*}
    N(t^-)\approx N(t^{-1})
\end{equation*}
This tells us we can assume from here on that $t^-$ selects the left as $t^-\to t_{min}$, and we do not know yet where $t_{min}$ is finite or $-\infty$. And we look only at such $t^-$.

Suppose $N(1)=1$, and for $t<t_0<1$, we have 
\begin{equation*}
    N(t)\geq cN(t_0)
\end{equation*}
and this gives $N$ is ``almost '' decreasing.

We choose $R$ large enough such that $osc(R)>2 c^{-1}$. And there exists $t_1$ such that 
\begin{equation*}
    N(t_1)\geq 2N(t_0)
\end{equation*}
and $|t_1-t_0|\leq 2RN(t_0)^{-2}$.
And 
\begin{equation*}
    N(t_{k+1})2N(t_k)\Rightarrow N(t_k)=2^k
\end{equation*}
and 
\begin{equation*}
    |t_{k+1}-t_k|\leq RN(t_k)^{-2}, t_k\rightarrow T_{min}
\end{equation*}
And 
\begin{equation*}
    |t_k-t_{min}|\leq R2^{-2k}\Rightarrow |N(t_k)|\lesssim |t_k-t_{min}|^{-1/2}
\end{equation*}
We arrive at 
\begin{equation*}
    N(t)\approx t^{-1/2}, t\in [0,1]
\end{equation*}
And $t=0$ is the blow up. But we would like to cover all of $T$, and hence we reseacle to $[0,N]$, and letting $N\to\infty$.

\textbf{Scenario 3}
For $t\in [0,\infty]$, and 
\begin{equation*}
    N(t)\approx t^{-1/2}
\end{equation*}
Scenario 1+2=Scenario 1': gives $N$ not necessarily constant, but decays just a little.
\begin{equation*}
    \int_0^\infty N^3(t)=\infty
\end{equation*}
And Scenario 2':
\begin{equation*}
    \int_0^\infty N^3(t)<\infty
\end{equation*}

\section{Lecture Nov 7}
We will take the first three scenarios, and we will look at the self-similar case: $I=[0,\infty)$, and $N(t)=t^{-1/2}$.
We saw that 
\begin{equation*}
    |N'(t)|\leq N^3(t), |\xi'(t)|\leq N^3(t)\approx t^{-3/2}
\end{equation*}
where $N^3(t)\approx t^{-3/2}$. This suffices that $\xi^\infty=\lim_{t\to\infty}\xi(t)$.
\begin{equation*}
    |\xi(t)-\xi^\infty|\leq\int_t^\infty|\xi'(t)|\leq\int t^{-3/2}=t^{-1/2}
\end{equation*}
By Gallilean invariance, we set the limit $\xi^\infty=0$. Let's see what if $N(t)=t^{-1/2}$, this gives that $\xi(t)=0$.

Once we fix this frequency. We look at mass critical NLS. 
\begin{enumerate}
    \item Locally well-posed in $L^2$
    \item Locally well-posed in $H^1$.
\end{enumerate}
\begin{note}
    We care about $H^1$ because we have a conserved energy.
    \begin{equation*}
        E(u)=\int \frac{1}{2}|\nabla|^2\pm\frac{1}{p+1}|u|^{p+1}dx
    \end{equation*}
\end{note}
in the defocusing case, $E$ is coercive. Then if the problem is locally wel-posed in $H^1$, we also get global well-posedness in $H^1$.
Showing that in $H^1$ would suffice, because that would imply the solution cannot blow up, but it in fact does.

In the focusing case. If we have 
\begin{equation*}
    M(u)<M(Q)\Rightarrow \|u\|_{H^1}^2\lesssim E(u)
\end{equation*}
The conclusion now is, it would suffice to show that $u\in L^\infty H^1$. Then we are done.

As $t\to\infty$, we have $N(t)\to 0$, so maybe $u$ is localized at a very low frequency. However, one trick that we can do is that we can do some rescaling. We want the solution to be very small here.

Given $N(t)=t^{-1/2}, \delta t=N^{-2}$. And on the graph of $N(t)$-y, and $t$-x, we decompose the intervals into dyadic intervals.
\begin{comment}
    We will do a scaling. And push the control at infinity. We would like to magic this from a qualitative to a quantitative way.
\end{comment}
For $k\gg 1$, $k$ being the dyadic frequency, look at $u$ such that $>N\cdot 2^k$, and $I_j=[2^j, 2^{j+2}]$. Now we claim that 
\begin{proposition}
    \begin{equation*}
        \|u_{>N\cdot 2^k}\|_{L^2(I_j)}\leq 2^{-k(1+\frac{4}{d})}+\epsilon
    \end{equation*}
    uniformly in $j$. (note the exponent $p=\frac{4}{d}$).
\end{proposition}
We would like to show $u\in H^1$, which implies that 
\begin{equation*}
    \|u_{>2^k}\|_{L^2}\leq 2^{-k}
\end{equation*}
If we do a little better, 
\begin{equation*}
    \|u_{>2^k}\|_{L^2}\leq 2^{-k(1+)}
\end{equation*}
It remains to prove this proposition. Let $M_k=\sup_j\|u_{>2^kN}\|_{L^\infty L^2(I_j)}$, and this is the high frequency portion.
\begin{equation*}
    \mathcal{S}_k=\sup_j\|u_{>2^kN}\|_{S(I_j)}
\end{equation*}
Moreover,
\begin{equation*}
    N_k=\sup_j\|F(u)_{>2^kN}\|_{N(I_j)}=\sup_j\|F(u)_{>2^kN}\|_{S'}
\end{equation*}
Note that 
\begin{equation*}
    \mathcal{S}_k\leq M_k+N_k
\end{equation*}
We will try to measure $N_k$, how far is it from a Schrondinger solution. And eventually, we would like to control 
\begin{equation*}
    A_k=M_k+N_k+\mathcal{S}_k
\end{equation*}
\textbf{Easier part: $N_K$} $j$ is not important, we can scale it to be any dyadic interval, so we take $j=1$, and $N=1$.
\begin{equation*}
    F(u)>2^kN
\end{equation*}
and this gives 
\begin{equation*}
    F(u)_{>2^k}=(F(u)_{>2^k})_{>2^k}+(F(u)_{>2^k})_{>2^k}+O(|u|_{>2^k}, |u_{<2^k}|^{4/d})
\end{equation*}
We have 
\begin{equation*}
    \|(F(u)_{>2^k}){>2^k}\|_{L^{q'}}\leq \|F(u_{>2^k})\|_{L^{q'}}\leq \|u_{\geq 2^k}\|_{L^q}^{1+p}\leq A_k^{1+p}
\end{equation*}
\begin{equation*}
    \|u_{>k}(u_{<k})^p\|_{L^{q'}}\leq \|u_{>2^k}\|_{L^q}\|u_{<k}\|_{L^q}^q\leq A_k\cdot A_{<k}
\end{equation*}
Then 
\begin{equation*}
    u_{<k}=u_{<\beta k}+u_{[\beta k, k)}
\end{equation*}
And the second term corresponds to 
\begin{equation*}
    \|u_{>2^k}\|_{L^q}\cdot\|u_{[\beta k, k)}\|_{L^q}^p\leq A_k\sum_{{\beta k\leq l\leq k}}A_l^q
\end{equation*}
For unbalanced frequencies, we use the better bilinear estimate.

Hence except for the low frequency term, we have
\begin{equation*}
    N_k\leq ...+ A_k\cdot 2^\frac{(1-\beta)k}{2}\cdot A_{<k}
\end{equation*}
We have a lot of low frequencies, and we cannot discard the localization now.
\begin{equation*}
    \|P_{>2^k}F(u_{<2^k})\|_N\leq 2^{-sk}\||D|^sF(u_{<2^k})\|_{L^{p'}}\leq 2^{-sk}2^{sk_1}\|u_{k_1}\|_{L^q}\|u_{<k_1}\|_{L^q}^{4/d}
\end{equation*}
where $s$ is an integer, $s_1+..+s_j=s$.
\begin{equation*}
    \partial^{s_1}u_{<k}\cdot...\cdot\delta^{s_j}u_{<k}F^{(j)}(u_{<k})
\end{equation*}
But all other guys, except for $k_1$, could still have low frequency. Combining, we have 
\begin{equation*}
    M(k)\leq ...+\sum_{k_1}A(k_1)2^{-s(k-k_1)}
\end{equation*}
We can differentiate only $s$ times, hence $s<1+4/d$. If $s$ is an integer, and $s<1+4/d$, then we get the above bound for $M(k)$. Then we take a leap of faith, and claim that it works for $s$ noninteger as well.

Now we have
\begin{equation*}
    N_k\leq A_k^{1+4/n}+A_k\cdot 2^\frac{(1-\beta)k}{2}A_{<k}+\sum_{k_1<k}2^{(k_1-k)s}A_{k_1}
\end{equation*}

All sources have $A_k$ in them, since they already have the bounded contribution. Now we go to the \textbf{harder part}, i.e. we estimate $M_k$, we do this via Duhamel formula.
\begin{equation*}
    u(1)=e^{-i(T-1)\Delta}u(T)-\int_1^t e^{-i(T-t)}F(u(t))dt
\end{equation*}
In this formula, we would like to let $t\to\infty$. Now we need to address what happens ot the first term.
\begin{equation*}
    u(1)=\int_1^\infty e^{i(T-t)}F(u(t))dt
\end{equation*}
And we have 
\begin{equation*}
    \|u(1)_{>k}\|_{L^2}\leq\sum_{k_1>k}N_{k_1}
\end{equation*}
This is comparable to $N_k$ if we have some $k^\epsilon$ decay. 
\begin{equation*}
    u(1)=\int_1^\infty e^{itD^2}F(u(t))dt, u(1)=\int_0^1 e^{itD^2}F(u(t))dt
\end{equation*}
And 
\begin{equation*}
    \|u(1)_{>k}\|_{L^2}^2=\int_0^1\int_1^\infty e^{isD^2}F(u(s))F(u(t))e^{-itD^2}dsdt
\end{equation*}
And $F(u(s))\cdot e^{-i(t-s)D^2}F(u(t))dsdt$. This is a bounded operator from $L^2\to L^2$, and $L^1\to L^\infty$, with $O(t^{-n/2})$.

If we separate the first integral
\begin{equation*}
    u(1)=\int_1^T +\int_T^\infty=A+B
\end{equation*}
Hence this gives us 
\begin{equation*}
    \|u(t)\|_{L^2}\leq A^2+A_1B
\end{equation*}
Now $A^2$ is just like the $N_k$ previously, hence the outcome is that we get a similar estimate for $M_k$ as $N_k$.

Hence roughly we get 
\begin{equation*}
    A_k=M_k+N_k+\mathcal{S}_k\leq A_k^{1+4/n}+\sum_{k_1<k}2^{(k_1-k)s}A_{k_1}
\end{equation*}
Now you have a sequence that satisfies this reoccurence relation, also you have $A_k\to 0$. Hence the conclusion is 
\begin{equation*}
    A_k\leq c 2^{-ks}
\end{equation*}
The decaying factor in the second term drives the decay. This you prove by induction. You would like start $k$ large enough, such that $A_k^{1+4/n}$ is already small.


    \begin{note}
        One could get fancy and use what's called the ``frequency pocket''.
    \end{note}



\section{Lecture Nov 9}
We would like to show that $N(t)\leq 1$, and we've separated this into two cases:
\begin{equation*}
    \begin{cases}
        \int N^3(t)dt<\infty\\
        \int N^3(t)dt=\infty\\
    \end{cases}
\end{equation*}
And 
\begin{equation*}
    \left|\frac{d}{dt}\xi(t)\right|\leq N^3(t)
\end{equation*}
And the first case above implies that 
\begin{equation*}
    \lim_{t\to\pm\infty}\xi(t)=\xi^{\pm\infty}
\end{equation*}
And in the second case above, is that $N(t)$ stays close to 1.

The most important case $N(t)\approx 1$, and we refer to this one as the soliton case, where the solution is given by 
\begin{equation*}
    Q=\varphi(x-ct)e^{i\omega t}
\end{equation*}
Before we speak any of that, we introduce some historical perspective.

Bourgain looked at the radial, defocusing case. This impiles that $x(t)=0$, and $\xi(t)=0$. If we depict a mechanic particle and its distance to the origin, we can graph the distance $d(x(t), 0)$, and graphing it with respect to time would look like a convex function.

If we want to measure the distance between the origin, the following quantity should capture the notion of distance with the weight $|x|$,
\begin{equation*}
    \int |x||u(x)|^2dx
\end{equation*}
Morally speaking, we should expect this function to be convex. 
\begin{equation*}
    M(t)=\int a(x)|u(x)|^2dx
\end{equation*}
We are in $\R^n$, but for simplicity, we can make $a(x)$ spherically symmetric. We evaluate $M(t)$ at every time, and we expect it to be convex.

\begin{equation*}
    \frac{d}{dt}M(t)=\int a(x)
\end{equation*}
Recall mass density $m(u)=|u|^2, M=\int |u|^2$, and 
\begin{equation*}
    \partial_tm(u)=2Re(u_t\cdot\overline{u})=2Im(\Delta u\pm u|u|^p)\cdot\overline{u}=2\nabla(\nabla u\cdot\overline{u})
\end{equation*}
Note that 
\begin{equation*}
    \partial_tm(u)=\delta_jp_j(u), p_j(u)=2Im(u\partial_j\overline{u})
\end{equation*}
This gives 
\begin{equation*}
    \frac{d^2}{dt^2}M(t)=-\frac{d}{dt}\int a_jp_j(u)dx
\end{equation*}
And given $p_j=2Im(u\partial_j\overline{u}), \partial_tm=\partial_jp_j$. We use $\Delta=\partial_k\partial_k$,
\begin{align*}
    \partial_tp_j&=2Im(u_t\cdot\partial_j\overline{u}+u\partial_j\overline{u}_t)\\
    &=2Re(\Delta u\pm u|u|^p)\partial_j\overline{u}-u\partial_j(\Delta\overline{u}\pm\overline{u}|u|^p)\\
    &=2Re\partial_k(\partial_k u\partial_j\overline{u}-u\partial_k\partial_j\overline{u})\pm\frac{2}{p+2}\partial_j|u|^{p+2}\\
    &=4 Re\partial_k(\partial_k\partial_j\overline{u})-2\Delta\partial_j|u|^2\pm\frac{2}{p+2}\partial_j|u|^{p+2}
\end{align*}
If we denote 
\begin{equation*}
    \partial_tp_j=\partial_kF_{jk}, \text{ where }F_{jk}=4Re(\partial_ju\partial_k\overline{u})-2I 
\end{equation*}
where $I=\Delta|u|^2\pm |u|^{p+2}$.
Then 
\begin{align*}
    \partial_tp_j&=\partial_kF_{jk}\\
    &=\int a_{kj}Re(\partial_j u\partial_k\overline{u})+a_{kk}(-\Delta|u|^2\pm |u|^{p+2})\\
    &=\int a_{kj}Re(\partial_j u\partial_k\overline{u})+\Delta^2 a|u|^2+\Delta a|u|^{p+2}
\end{align*}
and $a(x)=|x|$, where 
\begin{equation*}
    \partial^2a=\frac{1}{|x|}(I-\frac{x}{|x|}\times\frac{x}{|x|})
\end{equation*}
where $\Delta a=\frac{1}{|x|}$, and $\Delta^2a=\frac{1}{|x|^3}$, and $n\geq 4$, and $\delta_0, n=3$. Rewriting what we have 
\begin{equation*}
    M_t=\int a_jp_j
\end{equation*}
and for $n\geq 4$,
\begin{equation*}
    M_{tt}\geq\int\frac{|u|^2}{|x|^3}+\frac{1}{|x|}|u|^{p+2}dx
\end{equation*}
And $n=3$ gives 
\begin{equation*}
    M_{tt}\geq|u(0)|^2+\int\frac{1}{|x|}|u|^{p+2}dx
\end{equation*}
This gives 
\begin{equation*}
    M_t(t_2)-M_t(t_1)\geq\int_{t_1}^{t_2}\frac{|u|^2}{|x|^3}+\frac{1}{|x|}u^{p+2}dx
\end{equation*}
And 
\begin{equation*}
    M_t\leq \|u\|_{L^2}\|\partial u\|_{L^2}
\end{equation*}
This is known as Morawetz inequality,
\begin{equation*}
    N(t)=1, |M_t|\lesssim 1
\end{equation*}
For $n=1,2$, we attempt to make $a$ more convex, $a=x^2$,
\begin{equation*}
    \frac{d}{dt}M_t=\int|\nabla u|^2+u^{p+2}dx
\end{equation*}
We can choose a ``japanese bracket'' for $x$ in a sense. In the focusing case, we would like to know that 
\begin{equation*}
    M_{tt}\geq 0
\end{equation*}
provided that $\|u\|_{L^2}<\|Q\|_{L^2}$. 

We now talk about Interaction Mozawetz inequality.
\begin{equation*}
    M(t)=\int a(x-y)m(u)(x)m(u(y))dxdy
\end{equation*}
We expect $M_{tt}\geq 0$. The above $M_t$ is used for intuition, but we do not expect to use it for anything.
\begin{equation*}
    \frac{d}{dt}M(t)=\int a(x-y)\partial_j p_j(u(x))m(v(y))+m(u(x))\partial_ip_j(v(y))dxdy
\end{equation*}
And we further define
\begin{equation*}
    I(u,v)(t)=M_t(t)=-\int a_j(x-y)(p_j(u)m(v)-m(u)p_j(v))dxdy
\end{equation*}
And we interpret this quantity $I(u,v)$ as the ``interaction potential.''
\begin{equation*}
    \frac{d}{dt}I(u,v)(t)=\int a_{jk}(x-y)(F_{kj}(u)m(v)+F_{kj}(v)m(u)-2p_j(u)p_k(v))
\end{equation*}
Now 
\begin{equation*}
    \int a_{jk}(x-y)(Re(\partial_j u\partial_k\overline{u}))+Re(\partial_jv\partial_k\overline{v}|u|^2-8Im(u\partial_j\overline{u})(v\partial_k\overline{v}))+
\end{equation*}
And by Cauchy-Schwartz, we get that the quantity is $\geq 0$. And the remaining contribution is the $I$ part of $F_{jk}$, 
\begin{equation*}
    \int\Delta^2(a)m(u)m(v)+(|u|^2|v|^{p+2}\pm|v|^2|u|^{p+2})\Delta a(x-y)
\end{equation*}
where in the place of $\pm$, you have $+$ as the defocusing case, and $-$ as the focusing case.

And $a=|x|$, where 
\begin{equation*}
    \int\frac{1}{|x-y|^3}m(u)(x)m(v)(y)dxdy
\end{equation*}
where we can interpret this in the Fourier analysis terms, 
\begin{equation*}
    \int |D|^{3-u}|u|^2|v|^2dx
\end{equation*}
If we have $u=v$, for $n\geq 4$, 
\begin{equation*}
    \frac{d}{dt}I\geq\||D|^\frac{3-n}{2}|u|^2\|_{L^2}^2
\end{equation*}
And $I=\int a_jm(u)p_j(v)$, and 
\begin{equation*}
    |I(t)|\leq\|u\|_[L^2]^2\|u\|_{L^2}\|\nabla u\|_{L^2}
\end{equation*}
\begin{note}
    The above does not have Galilean invariance.
\end{note}
If you apply the Galilean transform, 
\begin{equation*}
    \|(\nabla _i\xi_0)u\|_{L^2}
\end{equation*}
This happens at fixed time. If $N(t)\approx 1$. And 
\begin{equation*}
    N(t)\approx 1, (\nabla +i\xi_0)u\in L^2
\end{equation*}


\section{Lecture Nov. 16}
The dispersive PDE
\begin{equation*}
    \begin{cases*}
        i\partial_t+A(D)u=N(u)\\
        u(0)=u_0
    \end{cases*}
\end{equation*}
We ask for local well-posedness, and global well-posedness and scattering.

LWP. We look for a solution $u_0\in H^s$, and ask for the range of $s$. In GWP, we consider scattering, and the linear 
\begin{equation*}
    u(t)=e^{-itA(0)}u_0
\end{equation*}
We ask for group velocity, and disprsive:
\begin{equation*}
    \nabla^2a(\xi)
\end{equation*}
We ask the Hessian to be nondegenerate. And for nonlinear, there exists $u_0^\infty$ such that 
\begin{equation*}
    \lim_{t\to\infty}\|u(t)-e^{-itA(0)u_0^\infty}\|_{H^s}\to 0
\end{equation*}
And 
\begin{equation*}
    \lim_{t\to\infty}e^{itA(D)}u(t)=u_0^\infty \text{ in } H^s
\end{equation*}

The heuristic discussion is as follows:
\begin{equation*}
    (i\partial_t-A(D))u=u|u|^{p-1}
\end{equation*}
What are the worst nonlinear interactions? And we look at wave packet solutions, i.e. approximate solutions.
\begin{equation*}
    u(x,t)\approx A(t, x-x_0-vt)e^{i\phi(x,t)}
\end{equation*}
where $\phi(x,t)$ is linear in $t$.

For the \textbf{linear} Schrondinger equation, where $\delta\xi=N$, and the dual scale $\delta x=N^{-1}$, and the time scale $\delta t=N^{-2}$. The relationships in scaling come from the parabolic relationships. The scaling relationships are true for NLS, but also true for dispersive equations provided that $N\ll 1$.

We would like to \textbf{compare the strength} of linear and nonlinear interactions for a wave packet. The linear interactions $\delta t=N^{-2}$, and the solution stays concentrated for $t\leq N^{-2}$, and begins to disperse after that. If $u$ is around frequency $\xi_0$, then the solutions around group velocity $\nabla a(\xi)$.

Nonlinear: where $D=\frac{1}{i}\partial$
\begin{equation*}
    i\partial_t-a(\xi_0)-\nabla a(\xi_0)(D-\xi_0)-O(\nabla^2a(\xi_0)D^2)=u|u|^{p-1}
\end{equation*}
Let's start with $a(\xi_0)$, it is a phase shift, and $\nabla a(\xi_0)(D-\xi_0)$ is a transport term. The phase shift would good into $e^{i\phi(x,t)}$ in the exponent, and and the transport term would go into the velocity. And $\xi_0$ corresponds to the phase shift.

\begin{equation*}
    \phi=t(a(\xi_0)-\xi_-\nabla a(\xi_0))
\end{equation*}
The higher order terms is what gives the linear effects, and the $u|u|^{p-1}$ gives the nonlinear effects. If we take the wave packet scale,

\textbf{linear effect}: $O(N^2)$, where it acts on the $N^{-2}$ time scale. 
\begin{equation*}
    u|u|^{p-1}\approx A^p
\end{equation*}
And it acts on the scale $A\approx A^p\delta t$.
\begin{equation*}
    \delta t_{nonlinear}\approx A^{1-p}
\end{equation*}
if the linear is shorter, then the linear effect dominates; and vice versa.

We have two scenarios:
\textbf{Large $N$}:
$N\gtrsim 1$. We can think of a large $N$, if we consider a frequency box around it, it would contain a high frequency box. And note that our $A$ depends on $s$. This means that this could affect our index $s$, and nonlinear< linear, if we have large $s$; and nonlinear effect>linear if we have small $s$.
\begin{note}
This is important for local well-posedness.
\end{note}
\textbf{Small $N$}
In other words, $N\ll 1$, and $N=\delta\xi$, and take $\xi_0=O(1)$, and where $s$ is not so important.
\begin{note}
    If we want to look at global well-posedness, we can sort of take $s$ out of the picture.
\end{note}
We look at the size of $A$ if $\xi_0=O(1)$, and $N\ll 1$.
\begin{equation*}
    \|u\|_{L^2}=AN^{-n/2}\leq 1
\end{equation*}
This gives that
\begin{equation*}
    A\leq N^\frac{n}{2}
\end{equation*}
In other words, the amplitude will be a small number. This implies that our time scale $\delta t_{nonlinear}\geq N^{(1-p)\cdot\frac{n}{2}}$. And we would like to compare with 
\begin{equation*}
    \delta t_{linear}=N^{-2}
\end{equation*}
\begin{corollary}
    Linear effect is stronger than the nonlinear effect if $p>1+\frac{4}{n}$.
\end{corollary}
\begin{proof}
    \begin{equation*}
        N^{-2}\leq N^{(1-p)\frac{n}{2}}
    \end{equation*}
\end{proof}
And in this case, we expect linear scattering, if the linear effect dominates the nonlinear effect. Where $p<1+\frac{4}{n}$, we call this case is mass supercritical, and we get that there can't be linear scattering.

\begin{equation*}
    \delta t_{nonlinear}\approx A^{1-p}
\end{equation*}
And the smaller $n$, the problem will be harder since we will have weaker dispersion. And where $n=1$, $p<5$, we call this case polynomial nonlinearity, which is where we take $p=3$.

We look at the model problem:
\begin{equation*}
    (i\partial_t-A(D))u=C(u,u,u)+ \text{ higher order }
\end{equation*}
but the cubic term $C(u,u,u)$ gives the most effect, and the higher order is the weaker effect.

We want to start with frequency $\xi_0$
\begin{equation*}
    \xi_0+\xi_0+\xi_0=3\xi_0
\end{equation*}
However, we would like to get 
\begin{equation*}
    \xi_0-\xi_0+\xi_0=\xi_0
\end{equation*}
Hence we modify our $C(u,u,u)$ to $C(u,\overline{u}, u)$. We want to take the smooth, but not complex analytic, and we end up with the first case. Hence we would like to think of this as real analytic.

We do some algebraic assumption:
\begin{equation*}
    u\to u^{i\theta}\Rightarrow C\to Ce^{i\theta}
\end{equation*}
And we can ask the same question for the full equation, and apply ``phase rotation symmetry.''

And invariant with respect to translations, where 
\begin{equation*}
    u\to u(\cdot+h)\Rightarrow C(u)\Rightarrow C(u)(\cdot+h)
\end{equation*}
And 
\begin{equation*}
    C(u,\overline{v},w)\to \text{ symbol } C(\xi_1, \xi_2, \xi_3)
\end{equation*}
And $u$ is at frequency $\xi_1$, and $v$ at $\xi_2$, and $w$ at $\xi_3$, we then have 
\begin{equation*}
    C(u,v,w)=c(\xi_1,\xi_2,\xi_3)
\end{equation*}
And 
\begin{equation*}
    C(e^{ix\xi_1}, e^{ix\xi_2}, e^{ix\xi_3} )=c(\xi_1, \xi_2,\xi_3)e^{ix(\xi_1-\xi_2+\xi_3)}
\end{equation*}
And we have 
\begin{equation*}
    \widehat{c(u,v,w)}(\xi)=\int_{\xi_1-\xi_2+\xi_3=\xi}c(\xi_1,\xi_2,\xi_3)\widehat{u}(\xi_1)\overline{\hat{u}}(\xi_2) w(\xi_3)dA
\end{equation*}
where the requirement is two dimensional subspace. We further have 
\begin{equation*}
    c(u,v,w)(x)=\int u(x+x_1)\overline{v}(x+x_2)w(x+x_3)K(x_1, x_2, x_3)dx_1dx_2dx_3
\end{equation*}
Recall our amplitude is $A=N^{n/2}$, and $n=1$ implies $A=N^{1/2}$.  And we would get 
\begin{equation*}
    O(N)u|u|^2, O(N^2)
\end{equation*}
And is exactly the last $O(N^2)$ term in the nonlinear Schrodinger case.

\begin{equation*}
    u=Ae^{i\phi}
\end{equation*}
And the following is what we call the nonlinear amplitude equation: (this is an ODE)
\begin{equation*}
    i\partial_t A=c(\xi_0,\xi_0, \xi_0)A|A|^2
\end{equation*}
where $A=A(t,x)$, and $\delta x=N^{-1}$. At $t=0$, you have a bump function of size $N^{-1}$, and each point evolves according to their own ODE. The ODE dynamics: When $c$ is purely imaginary, $c=i\sigma$, and $\partial_tA=\sigma A^3$. This gives us that we have finite time blow up.

When $\xi\in\R$, then $\partial_tA$  is proportional to $iA$, which is perpendicular to $A$. This implies that $|A|$ is conserved. If $\xi$ is not real nor purely imaginary, then it has a nontrivial imaginary part, and by what we discussed, it blows up in finite time. If $Im(\sigma)>0$, then you expect blow up forward in time. And $Im(\sigma)<0$, then you expect blow up backwards in time.
\begin{problem}
    What is this blow-up time?
\end{problem}
Answer: $\delta t=N^{-1}$.

\begin{definition}
    A cubic ODE is conservative, if $C(\xi,\xi,\xi)\in\R$, and if $\nabla_\xi c(\xi_1,\xi_2,\xi_3)\vert_{\xi_1=\xi_2=\xi_3}$.
\end{definition}
We have 
\begin{equation*}
    A(x,t)=A(x,0)e^{-itc(\xi_0,\xi_0,\xi_0)A(x,0)^2}
\end{equation*}
And note $A(x,0)$ depends on $x$, and at $t\sim N^{-1}$, frequencies in the nonlinear ansatz begin to move (they break the $N$ barrier). The moment rotates faster and faster as you go further in time, and start shooting waves in all diretions, which is why the solutions are dispersive.

The conjecture:
1-d dispersive: assume phase rotation, and conservative, and defocusing ( the waves are going outward instead of inward), then the conjecture states that the small data implies the global solution.


\section{Lecture Nov 30}
We ask the question how to aplit the set $[\xi]=(\xi_1, \xi_2, \xi_3, \xi_4)$. And let $\Omega_0=\{\delta\xi^{hi}\lesssim 1\}$.

We want to figure out how to do divisions in each of these settings. 
\begin{equation*}
    \eta_1=\xi_1-\xi_2=\xi_3-\xi_4
\end{equation*}
And 
\begin{equation*}
    \eta_2=\xi_1+\xi_2-\xi_3-\xi_4
\end{equation*}
Finally,
\begin{equation*}
    \eta_3=\xi_1-\xi_2-\xi_3+\xi_4
\end{equation*}
And $\xi=\xi_{avg}$, And $c_m^4=c_m^4(\xi, \eta_1, \xi_2, \xi_3)$, and $c_m^4$ vanishes of some order at $\eta_1=\eta_2=\eta_3=0$. Note $\xi_2^2=(\xi_1+\xi_2-\xi_3-\xi_4)^2=\eta_1()+(\xi_2-\xi_3)(\xi_1-\xi_4)$.

Note that $u=\sum_{k\in\mathbb{Z}}u_k$, we define $u_k\to m_k(u)=|u_k|^2$, can think about this as a bilinear form. You can think of $p_k(\xi_1)p_k(\xi_2)$, we want to take the localized mass and correct it.
\begin{equation*}
    \partial_tM_k(u)=\partial_x(P_k(u)+R_{m,k}^n)+R_{m,k+C_{m,k}}
\end{equation*} 
where $B_m^4, R_m^4$ have at least one entry at frequency $k$. Notice for the energy estimate, we have 
\begin{equation*}
    M_k(u)\leq\xi^2c_k^2
\end{equation*}
Integrate in time in $(DF)_m$ in $[0,T]$. 
\begin{equation*}
    \int M_k*dxdt(0,T)=\int R_{m,k}^6+C_{m,k}^{4, tn}dxdt
\end{equation*}
Since we do not have $M_k$ in the LHS, we need to make sure that 
\begin{equation*}
    \|B_{m,k}^4\|_{L^1}\leq \xi^2c_k^2
\end{equation*}
for fixed time.
\textbf{Bootstrap assumptions}
\begin{equation*}
    \|u_k\|_{L^\infty L^2}\leq\epsilon c_k
\end{equation*}
And 
\begin{equation*}
    \|u_k\|_{L^6}\leq\epsilon^{2/3}c_k^{2/3}
\end{equation*}
\begin{equation*}
    \|\partial(u_k\overline{u_j})\leq\epsilon^2c_kc_j\langle j-k\rangle^{1/2}
\end{equation*}
and we can add translations of $u_j$ in the above expression as well.

The $B_{m,k}^4$ bound, and use only bootstrap for energy.
\begin{equation*}
    B_{m,k}^k(u)=\sum_{k_1, ..., k_n}B_{m,k}^4(u_{k_1}, \overline{u_{k_2}} u_{k_3} \overline{u_{k_4}})
\end{equation*}
how to transform multilinear form into products, $B_{mk}^4(u_{k_1}, ..., u_{k_4})=\int K(\eta_1, ..., \eta_n)u_{k+1(x+y_1)}...\overline{u_{k_n}}(x+y_k)$, and this $K$ is a Schwartz function in all variables.

Now that we've interpreted as a product, we need $u_{k_1}, ... u_{k_4}$ as being in $L^2, L^2, L^\infty, L^\infty$. 
\begin{equation*}
    \|B_{m,k}^4(n)\|_{L^1}\leq C^4\epsilon^n \sum_{[k]}\frac{1}{\delta\xi^{med}\delta\xi^m}c_{k_1}c_{k_2}c_{k_3}c_{k_4}
\end{equation*}
and there is more $\epsilon$, hence taking it small we can eliminate bounding $C$.
\begin{equation*}
    \sum_{k\in[k]}\frac{1}{\delta\xi^{hi}\delta\xi^{med}}c_{k_1}c_{k_2}c_{k_3}c_{k_4}\leq c_k^2
\end{equation*}
Galilean invariance allows us to set $k=0$, and $\delta\xi^{med}=n_1, \delta\xi^{hi}=n_2$, and $k_1=k=0$, $|k_2|\lesssim n_1$ with $|k_3-k_4|\lesssim n_1$, and $|k_3||k_4|\approx n_2$.
\begin{equation*}
    \sum_{n_1, n_2}\sum_{k_2, k_3, k_4}\frac{1}{n_1n_2}c_{k_2}c_{k_3}c_{k_4}\leq c_0
\end{equation*}
You are computing an average by taking $\frac{1}{n_1n_2}$, this is the maximal function.
\begin{equation*}
    \delta\xi^{hi}=n_2\sum c_{k_2}\leq n_1c_0\leq\sum_{n_1, n_2}\sum_{k_4}\frac{n_1}{n_2}c_{k_4}^2\leq\sum_{n_2}\sum c_{k_4}^2=1
\end{equation*}
Now we discuss $R^6$. If $k_0=k_1=k_2$, we will use the $L^6$ bound. Then our strategy becomes $k_0=k_1=k_2=...$, and use $L^6\to \epsilon^4C^6$. For $\delta k^{hi}=\max|k_j-k_e|$,  and 
\begin{equation*}
    R_6(u_{k_1}, ..., \overline{u_{k_6}})
\end{equation*}
where the 1-2, 3-4 are in $L^2$, and 5,6 are in $L^\infty$. We look at $C^4(u, \overline{u}, u, \overline{u})$, and 
\begin{equation*}
    \frac{1}{(\delta\xi^m)^2}(\xi_1-\xi_2)(\xi_3-\xi_4)
\end{equation*}
Then we consider $\xi_1-\xi_2$, where $\xi_1$ is like a derivative on $u$, where $\xi_2$ is a derivative on $\overline{v}$.

Hence we get 
\begin{equation*}
    \xi_1-\xi_2\to\partial u\cdot\overline{v}+u\partial\overline{v}=\partial(u\overline{v})
\end{equation*}
And we will use this to show that 
\begin{equation*}
    L(\partial(L(u_{k_1})L(U_{k_3}\overline{u}_{k_n})))
\end{equation*}
where each term can be shown to be in $L^2$.

Suppose you have two nonlinear Schrodinger solutions $u,v$, and we want to look at how they intersect.
\begin{equation*}
    I(u,v)=\int_{x<y}M(u)(x)P(v)(y)-P(u(x))M(v)(y)
\end{equation*}
This interaction measures how $u,v$ cross.
\begin{equation*}
    \frac{d}{dt}I(u,v)=\int_{x<y}\partial_xM(u)P(v)+M(u)\partial_yE(v)-\partial_xE(u)M(v)-P(u)\partial_xE(v)
\end{equation*}
when we integrate by parts, we get 
\begin{equation*}
    \int M(u)E(v)+M(v)E(u)-2P(u)P(v)dx
\end{equation*}
this has four frequencies in it. $u$ has frequency $\xi_1, \xi_2$, and $v$ has frequency $\xi_3, \xi_4$. Rather than doing IBP, we do this at a symbol level.
\begin{equation*}
    (\xi_1+\xi_2)^2+(\xi_3+\xi_4)^2-(\xi_1+\xi_2)(\xi_3+\xi_4)
\end{equation*}
where $(\xi_1+\xi_2-\xi_3-\xi_4)^2$, where $\Delta^4\xi=0$. If we add and subtract $(\xi_1-\xi_4)(\xi_2-\xi_3)$, then we have 
\begin{equation*}
    \int \partial_x(u\overline{v})\partial_x(\overline{u}v)=\int|\partial_x(u\overline{v})|^2dx
\end{equation*}
This is by Planchan-Vega. Next time: multilinear forms.



\section{Last lecture}
\begin{theorem}[I-T]
    LWP holds for $s>1$.
\end{theorem}
Quasilinear Schrodinger 1-$d$. We ask the questions:
\begin{enumerate}
    \item For what $s$ is (QNLS) LWP?
    \item For what $s$ is (QNLS) globally well-posed for small data?
    \item cubic equation
\end{enumerate}
For global result, we need extra assumption.
\begin{enumerate}
    \item Phase rotation symmetry. $u\mapsto ue^{i\theta}$ is still a solution.
    \item conservative: 
    \begin{equation*}
        i\partial_tu+\partial_x^2u=c^3(u,\overline{u}, u)+c^{\geq 5}(u, \overline{u}, u)
    \end{equation*}
    and $\nabla_\xi C^3, c^3(\xi, \xi, \xi)\in\R$. 
    \item Defocusing. 
    \begin{equation*}
        c(\xi, \xi, \xi)\geq(1+\xi^2)
    \end{equation*}
\end{enumerate}
We have a total of three assumptions above.
\begin{theorem}[Global well-posedness]
    Assume 1-3, then for $\|u_0\|_{H^s}\leq\epsilon$, and for $s>1$, there exists a unique global solution $u$ satisfying
    \begin{enumerate}
        \item uniform energy bounds
        \item $L^6$ Strichartz
        \item Bilinear $L^2$ estimates
    \end{enumerate}
\end{theorem} 
Frequency decomposition of $u$. $\delta\xi=$ dyadic scale, because of how the waves are moving.

\begin{equation*}
    u_0=\sum_{k\geq 0}u_{0k}
\end{equation*}
at frequency $2^k$, and $\|u_{ok}\|_{H^s}\leq\epsilon c_k$. And $\sum c_k^2\approx 1$. And $c_k/c_j\leq 2^{\delta|k-j|}$. 
And note
\begin{equation*}
    \|u_k\|_{L^\infty L^2}\lesssim\epsilon c_k 2^{-sk}
\end{equation*}
Then the $L^6$ Strichartz $\|u_k\|_{L^6}\lesssim (\epsilon c_k)^{2/3}2^{-(s-1/6)k}$.
For the bilinear $L^2$ estimate, 
\begin{equation*}
    \|\partial(u_k\overline{u}_j)\|_{L^2}\lesssim\epsilon^2 c_kc_j
\end{equation*}
$k=j$ means $k=j+o(1)$. And to the above argument, we include a bootstrapping scheme, so we replace the right side of the inequality with $C$.

If we write $iu_{kt}+g(u_{<k})\partial_x^2 u_k$. 
\begin{equation*}
    iu_t+g(u)\partial_x^2u=N(u, \partial u)
\end{equation*}
And 
\begin{equation*}
    iv_{kt}+g(u_{<k})v_k=f_1
\end{equation*}
where it is linear paradiff flow.
\begin{equation*}
    iu_{kt}+g(u_{<k})\partial_x^2u_k=C(u_k, \overline{u}_k, u_k)+R^{trasv}
\end{equation*}
where $R^{trasv}$ is the perturbative term.
The $C$ term on the right hand side, we treat as if it is sublinear parallel, and the LHS is the paradiff part.

Density flux relations. Suppose we have 
\begin{equation*}
    \partial_t|u_k|^2=\partial_x\left( g(u_{<k})P_k(u)\right)+C_m^n(u, \overline{u}, u, \overline{u})+R
\end{equation*}
where $M_k(u)$, and $P$ is the momentum., and $g=1+$ quasilinear. And we get 
And we have 
\begin{equation*}
    \partial_t P_k(u)=\partial_x\left( g(u_{<k})E_k(u)\right)+C_m^n(u, \overline{u}, u, \overline{u})+R
\end{equation*}
We get division with $g=1$ on the $C_p$ term. We look at the translated twist:
\begin{equation*}
    g(u_{<k}), u_{<k}^n
\end{equation*}
This leads to the loss in the RHS here.
\begin{note}
    There is a loss of derivatives in the Strichartz estimate. 
\end{note}
The Strichartz estimate comes from when $k=j$ with no translations. Then we get the $L^6$Strichartz estimate.


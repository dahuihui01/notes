\chapter{Fourier Series and Integrals}

We will go through the book's notes in this document.
Chapter 1 is organized as follows:
\begin{enumerate}
    \item Fourier coefficients and Series
    \item Criteria for pointwise convergence
    \item Convergence in norm
    \item summability methods
    \item The fourier transform of $L^1$ functions
    \item Schwartz class and tempered distributions
    \item Fourier transform on $L^p$, for $1<p\leq 2$
    \item Convergence and summability of Fourier Integrals
    \item Further results
\end{enumerate}

\textbf{Some Notations}
The Lebesgue measure in $\R^n$ will be denoted using $dx$, and on the unit sphere $S^{n-1}$ will be $d\sigma$.

Let $a=(a_1, ..., a_n)\in\mathbb{N}^n$ be a multiindex, and $f:\R^n\to\C$, then
\begin{equation*}
    D^af=\frac{\partial^{|a|}f}{\partial_{x_1}^{a_1}...\partial_{x_n}^{a_n}}
\end{equation*}
where $|a|=a_1+...+a_n$.


\begin{theorem}[Minkowski's integral inequality.]
    Given $(X,\mu), (Y,\nu)$ as $\sigma$-finite measure spaces, we have the following inequality
    \begin{equation*}
        \left(\int_X\left|\int_Yf(x,y)d\nu(y) \right|^pd\mu(x) \right)^{1/p}\leq\int_Y \left(\int_X|f(x,y)^pd\mu(x) \right)^{1/p}d\nu(y)
    \end{equation*}
\end{theorem}

Taking $\nu$ to be the counting measure over a two point set $S={1,2}$ gives the usual Minkowski inequality
\begin{equation*}
    \|f_1+f_2\|_{L^p}\leq\|f_!\|_{L^p}+\|f_2\|_{L^p}
\end{equation*}

We will use $\mathcal{D}$ to denote the space of test functions, i.e. $C_c^\infty$, and $\mathcal{S}$ to denote the space of Schwartz functions. Recall the dual of $\mathcal{D}$, denoted as $\mathcal{D}'$ is the space of distrubitons, and $\mathcal{S}'$ is the space of temperate distributions.

\begin{definition}[Convolution of distribution]
    Let $T\in\mathcal{D}'$, and $f\in\mathcal{D}$, then we define
    \begin{equation*}
        T\ast f(x)=\langle T, \tau_x\tilde{f}\rangle
    \end{equation*}
    where $\tilde{f}(y)=f(-y)$, and $\tau_xf(y)=f(x+y)$. Hence it can be read as $T\ast f(x)=\langle T, f(x-y)\rangle$
\end{definition}
\begin{comment}
The theory of distribution will come in when we need meaningful differentiation but derivatives don't exist in the classical sense.
\end{comment}
\begin{comment}
    Tradionally, functions are thought of as sending points to points, but distributions are linear functions that act on a test function and send it to a point. In other words, distributions send functions to points using $\phi\mapsto\int u\phi dx$.
\end{comment}

\subsection{1.1 Review of definitions}
We now do some math.
If $f$ is a trigonometric series, of the form
\begin{equation*}
    f(x)=\sum_{n=-\infty}^\infty c_ne^{2\pi inx}
\end{equation*}
Then we find $c_n$ for any fixed $n$ by multiplying $f(x)$ by $e^{-2\pi inx}$, and integrate. Namely, we have
\begin{equation*}
    \int_0^1\sum_nc_ne^{2\pi inx}\cdot e^{-2\pi inx}=\int_0^1 c_n=c_n
\end{equation*}

We denote the additive group of $\R/\mathbb{Z}$ by $\T$, which gives $[0,1)$, and naturally identifies with $S^1$. Hence, saying a function $f$ defined on $\T$ is the same as saying $f$ is defined on $\R$ with period 1.

\begin{definition}[Fourier coefficients]
    Fix $f\in L^1(\T)$, we associate the sequence $\{\hat{f}(n)\}$ of $f$ defined by
    \begin{equation*}
        \hat{f}(k)=\int_0^1f(x)e^{-2\pi inx}dx
    \end{equation*}
    And its Fourier series defined as
    \begin{equation*}
        \sum_{n=-\infty}^\infty \hat{f}(n)e^{2\pi inx}
    \end{equation*}
\end{definition}


\subsection{1.2 Critera for pointwise convergence}
Define the $N$-th partial sum in the natural way. For pointwise convergence, the first result is due to Dirichlet, which states that if $f$ is bounded and has a finite number of maxima and minima, and pointwise continuous, then the limit of $S_N(f)(x)$ exists and is equal to $\frac{1}{2}(f(x+)+f(x-))$. As we saw in class, one can express $S_N(f)(x)$ as a convolution
\begin{equation*}
    S_N(f)(x)=D_N(f)\ast f(x)
\end{equation*}
where $D_N(t)=\sum_{n=-N}^Ne^{2\pi int}$. And for any $\delta>0$, we have
\begin{equation*}
    \int_0^1D_n(t)dt=1, |D_N(t)|\leq\frac{1}{|\sin(\pi t)}, \delta\leq |t|\leq\frac{1}{2}
\end{equation*}

To prove Dini's and Jordan's criterion, we first do some prep work.
\begin{definition}[bounded variation]
    The total variation of $f:I\to\C$ is defined by
    \begin{equation*}
        V(f,I)=\sup_N\sup_{x_0\leq...\leq x_N}\sum_{j=1}^N|f(x_j)-f(x_{j-1})|
    \end{equation*}
    And $f$ is of bounded variation if $V(f,I)<\infty$.
\end{definition}

Now we introduce the Riemann Localization principle, which states if two functions agree on a small neighborhood of a fixed point $x$, then their Fourier coefficients also agree at $x$. If we recall how Fourier coefficients are computed.
\begin{equation*}
    \hat{f}(n)=\int_0^1f(x)e^{2\pi inx}
\end{equation*} 
If we change $f$ in other places, not in the neighborhood of $x$, it seems like the integral would change as well. But we will show now, this is not the case.

\begin{theorem}[Riemann Localization Principle]
    If $f=0$ in $(x-\delta, x+\delta)$, then we have
    \begin{equation*}
        \lim_{N\to\infty}S_N(f)(x)=0
    \end{equation*}
\end{theorem}
\begin{proof}
    This is purely computational and it is done by writing out $S_N(f)(x)$ as a convolution and realizing $S_N(f)(x)$ is a sum of the Fourier coefficnets of two integral functions, hence its Fourier coefficients decay to 0, making $S_N(f)$ decay to 0 as well.
\end{proof}

One ingredient in the proof was the Riemann Lebesgue lemma, which states that the Fourier coefficent of integrable functions decays to 0. This 
\begin{lemma}[Riemann-Lebesgue]
    If $f\in L^1(\T)$, then we have
    \begin{equation*}
        \lim_{|n|\to\infty}\hat{f}(n)=0
    \end{equation*}
\end{lemma}
\begin{proof}
    One could either approximate $f$ with continuous functions or simple functions, either would work. If suffices to show $\hat{f}(n)\to 0$ for $f$ continuous, and it's pure arithmatic manipulation, and for $f$ simple functions, we can use integration by parts. Then we would recover that the Fourier transform decays as $|n|\to\infty$.
\end{proof}

We now state two local pointwise results, using the theorems we proved above.

\begin{theorem}[Dini's Criterion]
    Let $f$ be such that for a fixed $x$,
    \begin{equation*}
        \int_{|t|\leq\delta}\left|\frac{f(x+t)-f(x)}{t} \right|dt<\infty
    \end{equation*}
    Then we have
    \begin{equation*}
        \lim S_N(f)(x)=f(x)
    \end{equation*}
\end{theorem}
\begin{proof}
    We would want to show that 
    \begin{equation*}
        S_N(f)-f(x)\to 0
    \end{equation*}
    This means
    \begin{align*}
        \int_{|t|\leq1/2}(f(x-t)-f(x))\frac{\sin((2N+1)\pi t)}{\sin(\pi t)}&=\int_{|t|\leq\delta}(f(x-t)-f(x))\frac{\sin((2N+1)\pi t)}{\sin(\pi t)}\\
        &+\int_{\delta\leq t\leq1/2}(f(x-t)-f(x))\frac{\sin((2N+1)\pi t)}{\sin(\pi t)}
    \end{align*}
    Hence if we write $\sin((2N+1)\pi t)$ as $(e^{(2N+1)\pi t}-e^{-(2N+1)\pi t})/2$ again, we can write the above two integrals as the Fourier coefficient of two integrable functions, and by the Riemann Lebesgue lemma, we conclude as $N\to\infty$, $S_N(f)(x)\to f(x)$.
\end{proof}
\qed

\begin{remark}
    In the proof of Dini's theorem and Riemann Localization principle, we both first write out the partial sum $S_N(f)$ as the convolution again $\frac{\sin((2N+1)\pi t)}{\sin(\pi t)}$, and to finish up, we transformed this back to a Fourier coefficient by expanding out $\sin((2N+1)\pi t)$, and used Riemann Lebesgue lemma.
\end{remark}

\begin{theorem}[Jordan's Criterion]
    If $f$ is of bounded variation in a neighborhood of $x$, then we have
    \begin{equation*}
        \lim_{N\to\infty}S_N(f)(x)=\frac{1}{2}[f(x+)+f(x-)]
    \end{equation*}
\end{theorem}
\begin{proof}
    If $f$ is of bounded varation in $(x-\delta, x+\delta)$, then we have $f=f^+-f^-$, where both $f^+, f^-$ are monotonic. Hence we can assume $f$ is monotonic in a nbhd of $x$. (Justification: if we can prove $S_N(f^+)=\frac{1}{2}(f^+(x+)+f^+(x-))$, and similarly for $f^-$, then we can add up and recover $f$.)

    Assuming $f$ is monotonic, we have
    \begin{equation*}
        S_N(f)(x)=\int_{|t|\leq1/2}f(x-t)D_N(t)dt=\int_0^{1/2}\left(f(x-t)+f(x+t) \right)D_N(t)dt
    \end{equation*}
    And thus assuming $x=0$, it suffices to prove
    \begin{equation*}
        \int_0^{1/2}f(t)D_N(t)dt\to\frac{1}{2}f(0^+)
    \end{equation*}
    Moving terms, and noting $D_n(t)=\frac{\sin((2N+1)\pi t)}{\sin(\pi t)}$ is an even function, we get $\frac{1}{2}f(0^+)=f(0^+)\int_0^{1/2}D_N(t)$. Hence it suffices to show the following integral tends to 0.
    \begin{equation*}
        \int_0^{1/2}(f(t)-f(0^+))D_N(t)dt=\int_0^\delta(f(t)-f(0^+))D_N(t)dt+\int_\delta^{1/2}(f(t)-f(0^+))D_N(t)dt
    \end{equation*}
    By the same arguemnt, the second integral tends to 0. To treat the first integral, we apply the second mean value theorem for integrals, which states for continuous $\varphi$, and monotonic $h$, there exists $c$, $a<c<b$, 
    \begin{equation*}
        \int_a^b h\varphi=h(a+)\int\varphi+h(b-)\int\varphi
    \end{equation*}
    This deals with the bad $t$ around 0, and we are left with good, integrable terms,
    \begin{equation*}
        \int_0^\delta(f(t)-f(0^+))D_N(t)dt=\int_c^\delta(f(t)-f(0^+))D_N(t)dt
    \end{equation*}
    Again, we have an integrable function, writing it as a Fourier coefficient, we have $\int_0^{1/2}f(t)D_N(t)\to\frac{1}{2}f(0^+)$.
\end{proof}
\qed

\subsection{1.3 Fourier series of continuous functions}

\section{1.5}

We will now begin the next portion of the book, which we introduce summability methods. The first one we will talk about is the Cesaro sum.

Our motivating example begins like this:
\begin{example}
    Define a sequence $\{1, -1, 1, -1, ...\}$, we now ask what is the partial sum of first $N$ terms as $N$ gets large. It is easy to check that if $N$ is odd, we get $S_N=1$, and when $N$ is even, we get $S_N=0$. And this partial sum seems very badly beahved. But this is not the case. We can think of the true partial sum as oscilatting between 1 and 0, hence $1/2$ would be a reasonable number to ``capture the reality.'' This aligns with the notation of Cesaro sum.
\end{example}

\begin{definition}[Cesaro sum]
    Let a sequence $\{s_n\}$ be fixed, and define the $N$-th Cesaro sum as the average of first $N$ partial sums:
    \begin{equation*}
        \sigma_N(s_n)=\frac{1}{N+1}\sum_{k=0}^{N}S_k(s_n)
    \end{equation*} 
    Of course, we can interpret this in terms of Fourier series. Given a function $f$, we let $S_N$ denotes its $N$-th Fourier series, and the $N$-th Cesaro sum would be
    \begin{equation*}
        \sigma_N(f)(x)=\frac{1}{N+1}\sum_{k=0}^NS_k(f)
    \end{equation*}
\end{definition}

We will show this notation of average sum ensures convergence to $f$ in the $L^p$ norm.

Just like how we wrote $S_N(f)(x)=D_n\ast f(x)$, we can write $\sigma(f)$ as a convolution.
\begin{proposition}
    For $f\in L^p, 1\leq p<\infty$, we have
    \begin{equation*}
        \sigma(f)(x)=F_N\ast f(x)
    \end{equation*}
    where $F_N(t)=\frac{1}{N+1}\left(\frac{\sin((N+1)\pi t}{\sin(\pi t)} \right)^2$ is the Fejer kernel.
\end{proposition}
\begin{proof}
    \begin{align*}
        \sigma(f)(x)&=\frac{1}{N+1}\sum_{k=0}^NS_k(f)\\
        &= \frac{1}{N+1}\sum_{k=0}^N\int_0^1D_N(x-t)f(t)dt\\
        &=\int_0^1f(t)\frac{1}{N+1}\sum_{k=0}^ND_N(x-t)dt\\
    \end{align*}
    We then let $F_N(t)=\frac{1}{N+1}\sum_{k=0}^ND_N(t)$. And remember we define $D_N(t)=\sum_{n=-N}^Ne^{2\pi int}$, hence via arithmatic manipulation, we can show that 
    \begin{equation*}
        F_N(t)=\frac{1}{N+1}\left(\frac{\sin((N+1)\pi t)}{\sin(\pi t)}\right)^2
    \end{equation*}
\end{proof}
\qed

\begin{remark}
    This gives several good properties for $F_N(t)$, namely since the RHS is squared
    \begin{enumerate}
        \item $F_N(t)\geq 0$
        \item $\int_0^1F_n(t)=1$, hence we can again think of it as distributing mass
        \item For all $\delta>0$,
         \begin{equation*}
            \lim_{N\to\infty}\int_{\delta\leq|t|\leq1/2}F_N(t)=0
        \end{equation*}
        This means that $F_N$ does a really good job concentrating all mass at the origin, and behaving like the dirac function, which is the convolution identity.
    \end{enumerate}

    This gives us good intuition on why $\sigma_N(f)=F_N\ast f\to f$, because as $N\to\infty$, we are better at approximating $f$.
\end{remark}

\begin{remark}
    Another advantage of Fejer kernerl is that when we integrate 
    \begin{equation*}
        \int_{0\leq|t|\leq\delta}|F_N(t)|dt
    \end{equation*}
    This quantity is bounded by the fact that $F_N(t)$ is nonnegative. We cannot apply the same bound on $D_N(t)$ like
    \begin{equation*}
        \int_{0\leq |t|\leq\delta}|D_N(t)|dt
    \end{equation*}
    Because $D_N(t)$ oscillates and taking the absolute value would make this quantity blow up. (Hence we require stronger criterion like Dini's criterion).
\end{remark}

\begin{theorem}[The $p=\infty$ case]
    For $p=\infty$, if $f$ is conitnuous, then we have
    \begin{equation*}
        \lim_{N\to\infty}\|\sigma_N(f)-f\|_{L^\infty}=0
    \end{equation*}
\end{theorem}
\begin{proof}
    It suffices to show that for each $x\in\T$, we have
    \begin{equation*}
        |F_N\ast f(x)-f(x)|\to 0, N\to\infty
    \end{equation*}
    \begin{align*}
        |F_N(t)\ast f(x)-f(x)|&=\left|\int_{0\leq t\leq 1/2}F_N(t)(f(x-t)-f(t))dt \right|\\
        &\leq \int_{0\leq t\leq\delta}F_N(t)|f(x-t)-f(t)|dt +\int_{\delta\leq|t|\leq 1/2}F_N(t)|f(x-t)-f(t)|dt\\
        &\leq\epsilon\int_{0\leq |t|\leq\delta}F_N(t)dt+2\|f\|_{L^\infty}\int_{\delta\leq|t|\leq 1/2}F_N(t)dt\\
        &<\epsilon
    \end{align*}
\end{proof}
\qed

We next show a very similar proof for the rest of $p$.
\begin{theorem}
    Let $1\leq p<\infty$, then if $f\in L^p$, then we have
    \begin{equation*}
        \lim_{N\to\infty}\|\sigma_N(f)-f\|_{L^p}=0
    \end{equation*}
\end{theorem}
\begin{proof}
    By Minkowski's inequality for integrals, we can exchange the order of the integral, i.e.
    \begin{equation*}
        \|\sigma_N(f)-f\|_{L^p}\leq \int_{|t|\leq1/2} F_N(t)\|f(x-t)-f(x)\|_{L^p}dt
    \end{equation*}
    We agree break this integral up into two.
    \begin{equation*}
        \|\sigma_N(f)-f\|_{L^p}\leq \int_{|t|\leq\delta}F_N(t)\|f(x-t)-f(t)\|_{L^p}dt+\int_{\delta\leq t\leq1/2}F_N(t)\|f(x-t)-f(t)\|_{L^p}dt
    \end{equation*}
    The first integral tends to 0 since as $t\to 0$, we have
    \begin{equation*}
        \|f(x-t)-f(t)\|_{L^p}\to 0
    \end{equation*}
    And the second integral tends to 0 as it is bounded by $2\|f\|_{L^p}\int_{\delta\leq t\leq 1/2}F_N(t)dt$. Hence tends to 0 by the property of $F_N(t)$.
\end{proof}
\qed

\begin{corollary}[Trig polynomials are dense in $L^p$]
    By the above approximations, we know $\sigma_N(f)$ is an average of $S_K$'s, which are trigonometric polynomials, hence $\sigma_N$ itself is also a trig polynomial. For each $f\in L^p$, there exists a $\sigma_N(f)$ a trig polynomial, such that 
    \begin{equation*}
        \|\sigma_N(f)-f\|_{L^p}\to 0
    \end{equation*}
    Hence trig polynomials are dense in $L^p$, $1\leq p\leq\infty$.
\end{corollary}

\begin{corollary}
    If $f$ is integrable, (assume it's defined everywhere, same works if it's only defined almost everywhere), then if $\hat{f}(n)=0$ for all $n$, then $f=0$ identically.
\end{corollary}
\begin{proof}
    If $\hat{f}(n)=0$ for all $n$, then $S_k(f)=0$ for all $k$, hence $\sigma_N(f)=0$ for all $N$. We also have
    \begin{equation*}
        \|\sigma_N(f)-f\|_{L^1}=0\Rightarrow \int|f|=0
    \end{equation*} 
    Hence $f=0$ identically,
\end{proof}
\qed

Next we will introduce Abel summation, another summability method that guarantees convergence of Fourier partial sums.
\begin{definition}[Abel summation]
    Given a sequqence $a_n$, we define its $N$-th partial sum as $S_N$. And its $N$-th Abel sum is defined as
    \begin{equation*}
        A_r(a_n)=\sum_{n=0}^\infty r^na_n
    \end{equation*}
    And if $A_r$ converges as $r\to 1$, then the series is called Abel summable.
\end{definition}
\begin{example}
    Let's consider the following sequence: 
    \begin{equation*}
        \{1, -2, 3, -4, ...\}
    \end{equation*}
    We can write $a_{n+1}=(-1)^n(n+1)$, then the Abel sum would be
    \begin{equation*}
        A_r(a_n)=\sum_{n=0}^\infty(-1)^nr^n(n+1)
    \end{equation*}
    We note that
    \begin{equation*}
        \sum_{n=0}^\infty(-r)^n(n+1)=\sum_{n=0}^\infty(-r)^n+\sum_{n=0}^\infty n(-r)^n
    \end{equation*}
    The first term is a geometric series, and the second term is computed by differentiating the sum of the first term. And we have
    \begin{equation*}
        A_r(a_n)=\frac{1}{(1+r^2)}
    \end{equation*}
    Hence the series is Abel summable.
\end{example}
However, this sequence does not converge in the usual sense, nor is it Cesaro summable.

We now 